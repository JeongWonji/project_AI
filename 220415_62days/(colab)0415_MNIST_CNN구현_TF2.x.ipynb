{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(colab)0415_MNIST_CNN구현_TF2.x.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1bLN_5eQDdffaO9QIHXmBWk0tHlRvk_mg","authorship_tag":"ABX9TyMisAh/x0Erp/Ou6pJZfwKT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"LKYsiLqqkCIB","executionInfo":{"status":"ok","timestamp":1649999038381,"user_tz":-540,"elapsed":3580,"user":{"displayName":"문성훈","userId":"17340983977521415755"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Flatten, Dense\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Raw Data Loading\n","df = pd.read_csv('/content/drive/MyDrive/Colab임시폴더/mnist/train.csv')\n","display(df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"id":"K3AuxVzmoF21","executionInfo":{"status":"ok","timestamp":1649999046629,"user_tz":-540,"elapsed":3306,"user":{"displayName":"문성훈","userId":"17340983977521415755"}},"outputId":"1c5d0e3e-e7b0-47f4-b5e9-582bcc3f5881"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n","0      1       0       0       0       0       0       0       0       0   \n","1      0       0       0       0       0       0       0       0       0   \n","2      1       0       0       0       0       0       0       0       0   \n","3      4       0       0       0       0       0       0       0       0   \n","4      0       0       0       0       0       0       0       0       0   \n","\n","   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n","0       0  ...         0         0         0         0         0         0   \n","1       0  ...         0         0         0         0         0         0   \n","2       0  ...         0         0         0         0         0         0   \n","3       0  ...         0         0         0         0         0         0   \n","4       0  ...         0         0         0         0         0         0   \n","\n","   pixel780  pixel781  pixel782  pixel783  \n","0         0         0         0         0  \n","1         0         0         0         0  \n","2         0         0         0         0  \n","3         0         0         0         0  \n","4         0         0         0         0  \n","\n","[5 rows x 785 columns]"],"text/html":["\n","  <div id=\"df-ea88a048-c52d-49c5-a987-9ffa375ad696\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel0</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>...</th>\n","      <th>pixel774</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 785 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea88a048-c52d-49c5-a987-9ffa375ad696')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ea88a048-c52d-49c5-a987-9ffa375ad696 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ea88a048-c52d-49c5-a987-9ffa375ad696');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"code","source":["# 데이터 전처리\n","# 결측치, 이상치, 정규화, feature engineering\n","\n","# 우리예제는 결측치, 이상치가 없어요!\n","# 대신 정규화는 필요해요!\n","\n","# train data와 test data를 분리할 필요가 있어요!\n","# 학습을 하기 위한 train data\n","# 이 train data는 학습을 위한 train data와 validation data로 분리\n","\n","# 마지막 평가를 하기 위해 딱 1번 사용되는 test data\n","# 이 두개로 분리해야 해요!\n","train_x_data, test_x_data, train_t_data, test_t_data = \\\n","train_test_split(df.drop('label', axis=1, inplace=False),\n","                 df['label'],\n","                 test_size=0.3,\n","                 random_state=1,\n","                 stratify=df['label'])\n","\n","scaler = MinMaxScaler()\n","scaler.fit(train_x_data)\n","norm_train_x_data = scaler.transform(train_x_data)\n","norm_test_x_data = scaler.transform(test_x_data)\n","\n","# t_data에 대한 one-hot encoding처리는 하지 않아도 되요! (keras설정을 잡아서 이용)\n"],"metadata":{"id":"O2joVR-OonEV","executionInfo":{"status":"ok","timestamp":1649999051504,"user_tz":-540,"elapsed":483,"user":{"displayName":"문성훈","userId":"17340983977521415755"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Keras 구현\n","# model 구현\n","model = Sequential()\n","\n","model.add(Conv2D(filters=32,\n","                 kernel_size=(3,3),\n","                 activation='relu',\n","                 input_shape=(28,28,1),\n","                 padding='valid',\n","                 strides=(1,1)))\n","\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(filters=64,\n","                 kernel_size=(3,3),\n","                 activation='relu',\n","                 padding='valid',\n","                 strides=(1,1)))\n","\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(filters=64,\n","                 kernel_size=(3,3),\n","                 activation='relu',\n","                 padding='valid',\n","                 strides=(1,1)))\n","\n","model.add(Flatten())\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(units=256,\n","                activation='relu'))\n","\n","model.add(Dense(units=10,\n","                activation='softmax'))\n","\n","print(model.summary())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uKDksFS4wafh","executionInfo":{"status":"ok","timestamp":1649999056646,"user_tz":-540,"elapsed":1185,"user":{"displayName":"문성훈","userId":"17340983977521415755"}},"outputId":"c8105b89-e28a-4f46-edd8-d79cfe49b1a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 26, 26, 32)        320       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n","                                                                 \n"," flatten (Flatten)           (None, 576)               0         \n","                                                                 \n"," dropout (Dropout)           (None, 576)               0         \n","                                                                 \n"," dense (Dense)               (None, 256)               147712    \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                2570      \n","                                                                 \n","=================================================================\n","Total params: 206,026\n","Trainable params: 206,026\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["#  model 실행 옵션\n","model.compile(optimizer=Adam(learning_rate=1e-3),\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"Bx3TADxjBbDW","executionInfo":{"status":"ok","timestamp":1649999062639,"user_tz":-540,"elapsed":266,"user":{"displayName":"문성훈","userId":"17340983977521415755"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# model 학습\n","\n","# norm_train_x_data 이 학습 데이터의 일부를 validation data로 활용해서\n","# 학습이 진행될 때(epoch마다) 평가를 같이 진행!\n","# 평가는 train data에 대한 loss, accuracy, valid data에 대한 loss, accuracy\n","history = model.fit(norm_train_x_data.reshape(-1,28,28,1),\n","                    train_t_data,\n","                    epochs=200,\n","                    batch_size=100,\n","                    verbose=1,\n","                    validation_split=0.3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JSNb-mE3CvK-","executionInfo":{"status":"ok","timestamp":1649999291031,"user_tz":-540,"elapsed":187766,"user":{"displayName":"문성훈","userId":"17340983977521415755"}},"outputId":"1695037d-6ddf-4657-cf2d-862f72b78265"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","206/206 [==============================] - 3s 6ms/step - loss: 0.4748 - accuracy: 0.8514 - val_loss: 0.1348 - val_accuracy: 0.9593\n","Epoch 2/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9583 - val_loss: 0.0842 - val_accuracy: 0.9730\n","Epoch 3/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0951 - accuracy: 0.9700 - val_loss: 0.0657 - val_accuracy: 0.9796\n","Epoch 4/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9743 - val_loss: 0.0601 - val_accuracy: 0.9804\n","Epoch 5/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0643 - accuracy: 0.9792 - val_loss: 0.0553 - val_accuracy: 0.9827\n","Epoch 6/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 0.0483 - val_accuracy: 0.9861\n","Epoch 7/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9841 - val_loss: 0.0472 - val_accuracy: 0.9861\n","Epoch 8/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.0508 - val_accuracy: 0.9853\n","Epoch 9/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.0428 - val_accuracy: 0.9873\n","Epoch 10/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9879 - val_loss: 0.0446 - val_accuracy: 0.9865\n","Epoch 11/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9892 - val_loss: 0.0475 - val_accuracy: 0.9867\n","Epoch 12/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 0.0457 - val_accuracy: 0.9879\n","Epoch 13/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9900 - val_loss: 0.0458 - val_accuracy: 0.9864\n","Epoch 14/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.0393 - val_accuracy: 0.9889\n","Epoch 15/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0476 - val_accuracy: 0.9879\n","Epoch 16/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9921 - val_loss: 0.0424 - val_accuracy: 0.9884\n","Epoch 17/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.0380 - val_accuracy: 0.9898\n","Epoch 18/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0468 - val_accuracy: 0.9883\n","Epoch 19/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0446 - val_accuracy: 0.9883\n","Epoch 20/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0503 - val_accuracy: 0.9875\n","Epoch 21/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 0.0443 - val_accuracy: 0.9896\n","Epoch 22/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.0407 - val_accuracy: 0.9900\n","Epoch 23/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.0494 - val_accuracy: 0.9883\n","Epoch 24/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0478 - val_accuracy: 0.9885\n","Epoch 25/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9935 - val_loss: 0.0454 - val_accuracy: 0.9883\n","Epoch 26/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0430 - val_accuracy: 0.9899\n","Epoch 27/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 0.0513 - val_accuracy: 0.9896\n","Epoch 28/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.0464 - val_accuracy: 0.9879\n","Epoch 29/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0488 - val_accuracy: 0.9885\n","Epoch 30/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0520 - val_accuracy: 0.9891\n","Epoch 31/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0566 - val_accuracy: 0.9871\n","Epoch 32/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0552 - val_accuracy: 0.9870\n","Epoch 33/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.0466 - val_accuracy: 0.9889\n","Epoch 34/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.0465 - val_accuracy: 0.9897\n","Epoch 35/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9970 - val_loss: 0.0469 - val_accuracy: 0.9902\n","Epoch 36/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9961 - val_loss: 0.0535 - val_accuracy: 0.9893\n","Epoch 37/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0545 - val_accuracy: 0.9896\n","Epoch 38/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.0446 - val_accuracy: 0.9908\n","Epoch 39/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0446 - val_accuracy: 0.9910\n","Epoch 40/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.0471 - val_accuracy: 0.9901\n","Epoch 41/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0509 - val_accuracy: 0.9897\n","Epoch 42/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0476 - val_accuracy: 0.9900\n","Epoch 43/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.0559 - val_accuracy: 0.9887\n","Epoch 44/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 0.0513 - val_accuracy: 0.9902\n","Epoch 45/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0496 - val_accuracy: 0.9889\n","Epoch 46/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0413 - val_accuracy: 0.9913\n","Epoch 47/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0448 - val_accuracy: 0.9891\n","Epoch 48/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0482 - val_accuracy: 0.9897\n","Epoch 49/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.0569 - val_accuracy: 0.9895\n","Epoch 50/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0585 - val_accuracy: 0.9898\n","Epoch 51/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0562 - val_accuracy: 0.9889\n","Epoch 52/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0447 - val_accuracy: 0.9907\n","Epoch 53/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0652 - val_accuracy: 0.9881\n","Epoch 54/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0493 - val_accuracy: 0.9904\n","Epoch 55/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0536 - val_accuracy: 0.9905\n","Epoch 56/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0491 - val_accuracy: 0.9905\n","Epoch 57/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0573 - val_accuracy: 0.9893\n","Epoch 58/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0513 - val_accuracy: 0.9896\n","Epoch 59/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0575 - val_accuracy: 0.9897\n","Epoch 60/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0536 - val_accuracy: 0.9905\n","Epoch 61/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.0539 - val_accuracy: 0.9908\n","Epoch 62/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0594 - val_accuracy: 0.9901\n","Epoch 63/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0570 - val_accuracy: 0.9908\n","Epoch 64/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 0.0634 - val_accuracy: 0.9901\n","Epoch 65/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.0519 - val_accuracy: 0.9902\n","Epoch 66/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.0502 - val_accuracy: 0.9910\n","Epoch 67/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0736 - val_accuracy: 0.9876\n","Epoch 68/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0560 - val_accuracy: 0.9912\n","Epoch 69/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0645 - val_accuracy: 0.9893\n","Epoch 70/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9979 - val_loss: 0.0644 - val_accuracy: 0.9902\n","Epoch 71/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0615 - val_accuracy: 0.9905\n","Epoch 72/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.0582 - val_accuracy: 0.9909\n","Epoch 73/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.0475 - val_accuracy: 0.9921\n","Epoch 74/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0599 - val_accuracy: 0.9896\n","Epoch 75/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0514 - val_accuracy: 0.9912\n","Epoch 76/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 0.0557 - val_accuracy: 0.9914\n","Epoch 77/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0561 - val_accuracy: 0.9901\n","Epoch 78/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 0.0510 - val_accuracy: 0.9910\n","Epoch 79/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0562 - val_accuracy: 0.9899\n","Epoch 80/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0634 - val_accuracy: 0.9905\n","Epoch 81/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0549 - val_accuracy: 0.9913\n","Epoch 82/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0548 - val_accuracy: 0.9912\n","Epoch 83/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0552 - val_accuracy: 0.9908\n","Epoch 84/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0630 - val_accuracy: 0.9899\n","Epoch 85/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0610 - val_accuracy: 0.9891\n","Epoch 86/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.0557 - val_accuracy: 0.9910\n","Epoch 87/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0594 - val_accuracy: 0.9909\n","Epoch 88/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0540 - val_accuracy: 0.9904\n","Epoch 89/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0536 - val_accuracy: 0.9910\n","Epoch 90/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.0634 - val_accuracy: 0.9895\n","Epoch 91/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0588 - val_accuracy: 0.9914\n","Epoch 92/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.0735 - val_accuracy: 0.9896\n","Epoch 93/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0730 - val_accuracy: 0.9892\n","Epoch 94/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0682 - val_accuracy: 0.9902\n","Epoch 95/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0560 - val_accuracy: 0.9906\n","Epoch 96/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0677 - val_accuracy: 0.9904\n","Epoch 97/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0594 - val_accuracy: 0.9898\n","Epoch 98/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0543 - val_accuracy: 0.9906\n","Epoch 99/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0619 - val_accuracy: 0.9898\n","Epoch 100/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0598 - val_accuracy: 0.9912\n","Epoch 101/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0591 - val_accuracy: 0.9908\n","Epoch 102/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0635 - val_accuracy: 0.9906\n","Epoch 103/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0621 - val_accuracy: 0.9909\n","Epoch 104/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.0592 - val_accuracy: 0.9907\n","Epoch 105/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0550 - val_accuracy: 0.9912\n","Epoch 106/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0578 - val_accuracy: 0.9909\n","Epoch 107/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 0.0644 - val_accuracy: 0.9906\n","Epoch 108/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0662 - val_accuracy: 0.9907\n","Epoch 109/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0619 - val_accuracy: 0.9910\n","Epoch 110/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0638 - val_accuracy: 0.9901\n","Epoch 111/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0731 - val_accuracy: 0.9897\n","Epoch 112/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0667 - val_accuracy: 0.9908\n","Epoch 113/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0649 - val_accuracy: 0.9902\n","Epoch 114/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0708 - val_accuracy: 0.9902\n","Epoch 115/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0705 - val_accuracy: 0.9906\n","Epoch 116/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0657 - val_accuracy: 0.9909\n","Epoch 117/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.0760 - val_accuracy: 0.9897\n","Epoch 118/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0764 - val_accuracy: 0.9900\n","Epoch 119/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0704 - val_accuracy: 0.9906\n","Epoch 120/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0670 - val_accuracy: 0.9900\n","Epoch 121/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0830 - val_accuracy: 0.9896\n","Epoch 122/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0712 - val_accuracy: 0.9902\n","Epoch 123/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0688 - val_accuracy: 0.9906\n","Epoch 124/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0817 - val_accuracy: 0.9905\n","Epoch 125/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.0755 - val_accuracy: 0.9909\n","Epoch 126/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1058 - val_accuracy: 0.9884\n","Epoch 127/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 0.0763 - val_accuracy: 0.9912\n","Epoch 128/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0809 - val_accuracy: 0.9900\n","Epoch 129/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0895 - val_accuracy: 0.9895\n","Epoch 130/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0727 - val_accuracy: 0.9899\n","Epoch 131/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0723 - val_accuracy: 0.9904\n","Epoch 132/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0764 - val_accuracy: 0.9904\n","Epoch 133/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0887 - val_accuracy: 0.9892\n","Epoch 134/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.0841 - val_accuracy: 0.9883\n","Epoch 135/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0854 - val_accuracy: 0.9905\n","Epoch 136/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0750 - val_accuracy: 0.9909\n","Epoch 137/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.0788 - val_accuracy: 0.9897\n","Epoch 138/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9989 - val_loss: 0.0951 - val_accuracy: 0.9896\n","Epoch 139/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0771 - val_accuracy: 0.9913\n","Epoch 140/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0771 - val_accuracy: 0.9910\n","Epoch 141/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.0784 - val_accuracy: 0.9904\n","Epoch 142/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0737 - val_accuracy: 0.9901\n","Epoch 143/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0576 - val_accuracy: 0.9918\n","Epoch 144/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.0626 - val_accuracy: 0.9909\n","Epoch 145/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0735 - val_accuracy: 0.9896\n","Epoch 146/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0669 - val_accuracy: 0.9915\n","Epoch 147/200\n","206/206 [==============================] - 1s 4ms/step - loss: 9.1562e-04 - accuracy: 0.9998 - val_loss: 0.0711 - val_accuracy: 0.9910\n","Epoch 148/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0757 - val_accuracy: 0.9910\n","Epoch 149/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0705 - val_accuracy: 0.9913\n","Epoch 150/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0679 - val_accuracy: 0.9913\n","Epoch 151/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0865 - val_accuracy: 0.9900\n","Epoch 152/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0784 - val_accuracy: 0.9913\n","Epoch 153/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0837 - val_accuracy: 0.9902\n","Epoch 154/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0771 - val_accuracy: 0.9914\n","Epoch 155/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0708 - val_accuracy: 0.9909\n","Epoch 156/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0670 - val_accuracy: 0.9921\n","Epoch 157/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0812 - val_accuracy: 0.9907\n","Epoch 158/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 0.9990 - val_loss: 0.0794 - val_accuracy: 0.9910\n","Epoch 159/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0821 - val_accuracy: 0.9912\n","Epoch 160/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.1047 - val_accuracy: 0.9896\n","Epoch 161/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0773 - val_accuracy: 0.9913\n","Epoch 162/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0803 - val_accuracy: 0.9902\n","Epoch 163/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0822 - val_accuracy: 0.9897\n","Epoch 164/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0747 - val_accuracy: 0.9913\n","Epoch 165/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0634 - val_accuracy: 0.9920\n","Epoch 166/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.0719 - val_accuracy: 0.9915\n","Epoch 167/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0858 - val_accuracy: 0.9905\n","Epoch 168/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0723 - val_accuracy: 0.9899\n","Epoch 169/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.0710 - val_accuracy: 0.9910\n","Epoch 170/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0805 - val_accuracy: 0.9909\n","Epoch 171/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0743 - val_accuracy: 0.9909\n","Epoch 172/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 0.0845 - val_accuracy: 0.9901\n","Epoch 173/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.0843 - val_accuracy: 0.9899\n","Epoch 174/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0832 - val_accuracy: 0.9895\n","Epoch 175/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0756 - val_accuracy: 0.9905\n","Epoch 176/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0756 - val_accuracy: 0.9909\n","Epoch 177/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0886 - val_accuracy: 0.9895\n","Epoch 178/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0938 - val_accuracy: 0.9896\n","Epoch 179/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0746 - val_accuracy: 0.9914\n","Epoch 180/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0836 - val_accuracy: 0.9906\n","Epoch 181/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0733 - val_accuracy: 0.9913\n","Epoch 182/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0856 - val_accuracy: 0.9897\n","Epoch 183/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.0810 - val_accuracy: 0.9908\n","Epoch 184/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0842 - val_accuracy: 0.9899\n","Epoch 185/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0805 - val_accuracy: 0.9897\n","Epoch 186/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0833 - val_accuracy: 0.9908\n","Epoch 187/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.1018 - val_accuracy: 0.9890\n","Epoch 188/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0991 - val_accuracy: 0.9902\n","Epoch 189/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0828 - val_accuracy: 0.9908\n","Epoch 190/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0774 - val_accuracy: 0.9913\n","Epoch 191/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0902 - val_accuracy: 0.9895\n","Epoch 192/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0831 - val_accuracy: 0.9909\n","Epoch 193/200\n","206/206 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0955 - val_accuracy: 0.9891\n","Epoch 194/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0724 - val_accuracy: 0.9898\n","Epoch 195/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0791 - val_accuracy: 0.9902\n","Epoch 196/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.0790 - val_accuracy: 0.9918\n","Epoch 197/200\n","206/206 [==============================] - 1s 4ms/step - loss: 9.4877e-04 - accuracy: 0.9996 - val_loss: 0.0869 - val_accuracy: 0.9909\n","Epoch 198/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0838 - val_accuracy: 0.9907\n","Epoch 199/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0661 - val_accuracy: 0.9910\n","Epoch 200/200\n","206/206 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0703 - val_accuracy: 0.9909\n"]}]},{"cell_type":"code","source":["print(type(history))   # <class 'keras.callbacks.History'>\n","print(history.history.keys())  # dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n","\n","plt.plot(history.history['accuracy'], color='r')\n","plt.plot(history.history['val_accuracy'], color='b')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"4sQ3lhpUnzXE","executionInfo":{"status":"ok","timestamp":1649999809120,"user_tz":-540,"elapsed":481,"user":{"displayName":"문성훈","userId":"17340983977521415755"}},"outputId":"7ad1be07-54d2-42ed-8ae2-47c052907525"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'keras.callbacks.History'>\n","dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# 이렇게 학습된 model 자체를 저장할 수 있어요!\n","# 모델의 구조 + 계산된 모든 weight, bias를 하나의 파일에 저장할 수 있어요!\n","# 확장자는 .h5 (HDF5) 형식\n","\n","model.save('/content/drive/MyDrive/Colab임시폴더/mnist_model_save/my_mnist_model.h5')"],"metadata":{"id":"8Miqd88_Z2je","executionInfo":{"status":"ok","timestamp":1649995841111,"user_tz":-540,"elapsed":328,"user":{"displayName":"문성훈","userId":"17340983977521415755"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# model을 이용한 evaluation(평가)\n","model.evaluate(norm_test_x_data.reshape(-1,28,28,1), test_t_data)\n","#        loss                 accuracy \n","# [0.09250600636005402, 0.9903967976570129]"],"metadata":{"id":"Idef33Gya-14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 저장된 모델을 불러와서 \n","# 성능평가를 진행해보아요!\n","from tensorflow.keras.models import load_model\n","\n","new_model = load_model('/content/drive/MyDrive/Colab임시폴더/mnist_model_save/my_mnist_model.h5')\n","\n","# model을 이용한 evaluation(평가)\n","new_model.evaluate(norm_test_x_data.reshape(-1,28,28,1), test_t_data)\n","#        loss                 accuracy \n","# [0.09250600636005402, 0.9903967976570129]\n"],"metadata":{"id":"b4gAYvcRcCSY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model 학습(ckpt, earlyStopping callback 포함)\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","# checkpoint 설정\n","checkpoint_path = '/content/drive/MyDrive/Colab임시폴더/mnist_model_save/cp-{epoch:04d}.ckpt'\n","cp_callback = ModelCheckpoint(checkpoint_path,\n","                              save_weights_only=True,\n","                              period=5,\n","                              verbose=1)\n","\n","# earlyStopping\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0.001,   # 생략하면 값이 떨어지면 유효한것을 판단.\n","                   patience=5,\n","                   verbose=1,\n","                   mode='auto',\n","                   restore_best_weights=True)\n","\n","# norm_train_x_data 이 학습 데이터의 일부를 validation data로 활용해서\n","# 학습이 진행될 때(epoch마다) 평가를 같이 진행!\n","# 평가는 train data에 대한 loss, accuracy, valid data에 대한 loss, accuracy\n","history = model.fit(norm_train_x_data.reshape(-1,28,28,1),\n","                    train_t_data,\n","                    epochs=50,\n","                    batch_size=100,\n","                    verbose=1,\n","                    validation_split=0.3,\n","                    callbacks=[cp_callback, es])"],"metadata":{"id":"BWEcf-vAdt7E"},"execution_count":null,"outputs":[]}]}