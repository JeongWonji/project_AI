{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27dbc818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Tue_Mar__8_18:36:24_Pacific_Standard_Time_2022\n",
      "Cuda compilation tools, release 11.6, V11.6.124\n",
      "Build cuda_11.6.r11.6/compiler.31057947_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c0a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7d260",
   "metadata": {},
   "source": [
    "- RegNet040 5Fold ensemble\n",
    "- Pseudo labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fd7ad",
   "metadata": {},
   "source": [
    "- Train Dastset이 많지 않기 때문에 Test Dataset에 대해 Pseudo labeling을 진행 후, Train Dataset에 추가하여 모델을 Training시켰습니다.\n",
    "- 총 6번의 Pseudo labeling을 진행 하였습니다.\n",
    "- 첫 Pseudo labeling은 최적화 과정을 거친 regnet 5fold ensemble(Public Score : 0.989)을 이용했습니다.\n",
    "- 이후 동일한 Model config에서 총 5번의 Pseudo label set update를 진행하였습니다.\n",
    "- 최종적으로 총 5번의 update가 된 Pseudo label set + Train Dataset에 대해 Training한 regnet 5fold ensemble을 제출 하였고 Private Score기준 1등을 달성했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef3c71",
   "metadata": {},
   "source": [
    "#### Pseudo label set sampling\n",
    "- Pseudo label set의 신뢰성을 위해, 5fold ensembel logic에 대한 softmax결과값이 0.9보다 큰 sample로 한정했습니다.\n",
    "- Pseudo label set에서 비율이 많은 0번 class는 random sampling(n=500)했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f2f83",
   "metadata": {},
   "source": [
    "#### Pseudo label set업데이트에 따른 Regnet 5fold ensemble Public Score\n",
    "- 0step(Only Trainset) : 0.989\n",
    "- 1step : 0.996\n",
    "- 4step : 0.998\n",
    "- 6step(Submission) : 0.999 / Private : 0.99885"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4479e2",
   "metadata": {},
   "source": [
    "- Ubuntu 18.04, Cuda 11\n",
    "- opencv-python\n",
    "- numpy\n",
    "- pandas\n",
    "- timm\n",
    "- torch==1.8.0 torchvision 0.9.0 with cuda 11.1\n",
    "- natsort\n",
    "- scikit-learn\n",
    "- pillow\n",
    "- torch_optimizer\n",
    "- tqdm\n",
    "- ptflops\n",
    "- easydict\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38e7b2",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c90d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import logging  # 로그 출력\n",
    "import easydict  # 속성으로 dict 값에 access할 수 있음\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # process bar\n",
    "from os.path import join as opj\n",
    "from ptflops import get_model_complexity_info\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, grad_scaler\n",
    "from torchvision import transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c90e8a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff47ae",
   "metadata": {},
   "source": [
    "Hyper-parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d4e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {'exp_num':'0',\n",
    "     \n",
    "     # Path settings\n",
    "     'data_path':'./data',\n",
    "     'Kfold':5,\n",
    "     'model_path':'results/',\n",
    "\n",
    "     # Model parameter settings\n",
    "     'encoder_name':'regnety_040',\n",
    "     'drop_path_rate':0.2,\n",
    "     \n",
    "     # Training parameter settings\n",
    "     ## Base Parameter\n",
    "     'img_size':256,\n",
    "     'batch_size':16,\n",
    "     'epochs':100,\n",
    "     'optimizer':'Lamb',\n",
    "     'initial_lr':5e-6,\n",
    "     'weight_decay':1e-3,\n",
    "\n",
    "     ## Augmentation\n",
    "     'aug_ver':2,\n",
    "\n",
    "     ## Scheduler (OnecycleLR)\n",
    "     'scheduler':'cycle',\n",
    "     'warm_epoch':5,\n",
    "     'max_lr':1e-3,\n",
    "\n",
    "     ### Cosine Annealing\n",
    "     'min_lr':5e-6,\n",
    "     'tmax':145,\n",
    "\n",
    "     ## etc.\n",
    "     'patience':15,\n",
    "     'clipping':None,\n",
    "\n",
    "     # Hardware settings\n",
    "     'amp':True,\n",
    "     'multi_gpu':False,\n",
    "     'logging':False,\n",
    "     'num_workers':0,  # RuntimeError: DataLoader worker 오류 발생으로 0으로 설정\n",
    "     'seed':42\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf0e95",
   "metadata": {},
   "source": [
    "# Utils for training and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d74a4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimizer(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        \n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
    "\n",
    "# Logging\n",
    "def get_root_logger(logger_name='basicsr',\n",
    "                    log_level=logging.INFO,\n",
    "                    log_file=None):\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # if the logger has been initialized, just return it\n",
    "    if logger.hasHandlers():\n",
    "        return logger\n",
    "\n",
    "    format_str = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(format=format_str, level=log_level)\n",
    "\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(log_file, 'w')\n",
    "        file_handler.setFormatter(logging.Formatter(format_str))\n",
    "        file_handler.setLevel(log_level)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AvgMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.losses.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c91ef",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- 원본 이미지 사이즈가 큰 점을 감안해 (256,256)로 resize하여 데이터를 새롭게 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58036821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/train_df.csv')\n",
    "\n",
    "# # Resize Train Images\n",
    "# save_path = './data/train_256'  # 새로 저장할 폴더 경로\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "# for img in tqdm(df['file_name']):  # train_df의 'file_name' 컬럼을 참고하여\n",
    "#     name = os.path.basename(img)\n",
    "#     img = cv2.imread(opj('./data/train/', img))  # 해당 경로에 있는 png 이미지 읽어서\n",
    "#     img = cv2.resize(img, dsize=(256, 256))  # resize한 후\n",
    "#     img = cv2.imwrite(opj(save_path, name), img)  # 새 폴더에 저장\n",
    "\n",
    "# # Resize Test Images\n",
    "# df = pd.read_csv('./data/test_df.csv')\n",
    "# save_path = './data/test_256'\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "# for img in tqdm(df['file_name']):\n",
    "#     name = os.path.basename(img)\n",
    "#     img = cv2.imread(opj('./data/test/', img))\n",
    "#     img = cv2.resize(img, dsize=(256, 256))\n",
    "#     img = cv2.imwrite(opj(save_path, name), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb9c5b",
   "metadata": {},
   "source": [
    "# Dataset & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16ad6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_name = df['file_name'].values\n",
    "        # 각 label을 str->index로 변환\n",
    "        labels = ['bottle-broken_large', 'bottle-broken_small', 'bottle-contamination', 'bottle-good', 'cable-bent_wire', 'cable-cable_swap', 'cable-combined', 'cable-cut_inner_insulation', 'cable-cut_outer_insulation', 'cable-good', 'cable-missing_cable', 'cable-missing_wire', 'cable-poke_insulation', 'capsule-crack', 'capsule-faulty_imprint', 'capsule-good', 'capsule-poke', 'capsule-scratch', 'capsule-squeeze', 'carpet-color', 'carpet-cut', 'carpet-good', 'carpet-hole', 'carpet-metal_contamination', 'carpet-thread', 'grid-bent', 'grid-broken', 'grid-glue', 'grid-good', 'grid-metal_contamination', 'grid-thread', 'hazelnut-crack', 'hazelnut-cut', 'hazelnut-good', 'hazelnut-hole', 'hazelnut-print', 'leather-color', 'leather-cut', 'leather-fold', 'leather-glue', 'leather-good', 'leather-poke', 'metal_nut-bent', 'metal_nut-color', 'metal_nut-flip', 'metal_nut-good', 'metal_nut-scratch', 'pill-color', 'pill-combined', 'pill-contamination', 'pill-crack', 'pill-faulty_imprint', 'pill-good', 'pill-pill_type', 'pill-scratch', 'screw-good', 'screw-manipulated_front', 'screw-scratch_head', 'screw-scratch_neck', 'screw-thread_side', 'screw-thread_top', 'tile-crack', 'tile-glue_strip', 'tile-good', 'tile-gray_stroke', 'tile-oil', 'tile-rough', 'toothbrush-defective', 'toothbrush-good', 'transistor-bent_lead', 'transistor-cut_lead', 'transistor-damaged_case', 'transistor-good', 'transistor-misplaced', 'wood-color', 'wood-combined', 'wood-good', 'wood-hole', 'wood-liquid', 'wood-scratch', 'zipper-broken_teeth', 'zipper-combined', 'zipper-fabric_border', 'zipper-fabric_interior', 'zipper-good', 'zipper-rough', 'zipper-split_teeth', 'zipper-squeezed_teeth']\n",
    "        new = dict(zip(range(len(labels)),labels))\n",
    "        label_decoder = {val:key for key, val in new.items()}\n",
    "        df['label'] = df['label'].replace(label_decoder)\n",
    "\n",
    "        self.target = df['label'].values  # 목표는 label\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Dataset size:{len(self.file_name)}')\n",
    "\n",
    "    def __getitem__(self, idx):  # train 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "        image = cv2.imread(opj('./data/train_256/', self.file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "        target = self.target[idx]\n",
    "#         print(f'target:{target}')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_name)\n",
    "\n",
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.test_file_name = df['file_name'].values\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Test Dataset size:{len(self.test_file_name)}')\n",
    "\n",
    "    def __getitem__(self, idx): # test 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "        image = cv2.imread(opj('./data/test_256/', self.test_file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_file_name)\n",
    "\n",
    "def get_loader(df, phase: str, batch_size, shuffle,\n",
    "               num_workers, transform):\n",
    "    if phase == 'test':\n",
    "        dataset = Test_dataset(df, transform)  \n",
    "        # num_workers : 데이터 로딩에 사용하는 subprocess 개수\n",
    "        # pin_memory : True - 데이터로더가 Tensor를 CUDA 고정 메모리에 올림\n",
    "        # drop_last : batch의 크기에 따른 의존도 높은 함수를 사용할 때 우려되는 경우 마지막 batch를 사용하지 않을 수 있음\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    else:\n",
    "        dataset = Train_Dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True,\n",
    "                                 drop_last=False)\n",
    "    return data_loader\n",
    "\n",
    "def get_train_augmentation(img_size, ver):\n",
    "    if ver == 1: # for validset\n",
    "        transform = transforms.Compose([\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                ])\n",
    "\n",
    "    if ver == 2:\n",
    "        transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),  # 추가\n",
    "                transforms.RandomAffine((20)),  # x, y축으로 이미지 늘림\n",
    "                transforms.RandomRotation(90),\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    \n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a3605",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98c73038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        # 사전 학습된 모델 사용하기\n",
    "        self.encoder = timm.create_model(args.encoder_name, pretrained=True,\n",
    "                                    drop_path_rate=args.drop_path_rate,\n",
    "                                    )\n",
    "        num_head = self.encoder.head.fc.in_features  # Number of parallel attention heads\n",
    "        self.encoder.head.fc = nn.Linear(num_head, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class Network_test(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(encoder_name, pretrained=True,\n",
    "                                    drop_path_rate=0,\n",
    "                                    )\n",
    "        \n",
    "        num_head = self.encoder.head.fc.in_features\n",
    "        self.encoder.head.fc = nn.Linear(num_head, 88)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574592ec",
   "metadata": {},
   "source": [
    "# Trainer for Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3456802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, args, save_path):\n",
    "        '''\n",
    "        args: arguments\n",
    "        save_path: Model 가중치 저장 경로\n",
    "        '''\n",
    "        super(Trainer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Logging\n",
    "        log_file = os.path.join(save_path, 'log_0504_1_ep100.log')\n",
    "        self.logger = get_root_logger(logger_name='IR', log_level=logging.INFO, log_file=log_file)\n",
    "        self.logger.info(args)\n",
    "        # self.logger.info(args.tag)\n",
    "\n",
    "        # Train, Valid Set load\n",
    "        ############################################################################\n",
    "        if args.step == 0 :\n",
    "            df_train = pd.read_csv(opj(args.data_path, 'train_df.csv'))\n",
    "        else :\n",
    "            df_train = pd.read_csv(opj(args.data_path, f'0504_1_train_{args.step}step.csv'))\n",
    "\n",
    "#         if args.image_type is not None:\n",
    "#             df_train['file_name'] = df_train['file_name'].apply(lambda x:x.replace('train_imgs', args.image_type))\n",
    "#             df_train['file_name'] = df_train['file_name'].apply(lambda x:x.replace('test_imgs', 'test_512'))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=args.Kfold, shuffle=True, random_state=args.seed)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(df_train)), y=df_train['label'])):\n",
    "            df_train.loc[val_idx, 'fold'] = fold\n",
    "        val_idx = list(df_train[df_train['fold'] == int(args.fold)].index)\n",
    "\n",
    "        df_val = df_train[df_train['fold'] == args.fold].reset_index(drop=True)\n",
    "        df_train = df_train[df_train['fold'] != args.fold].reset_index(drop=True)\n",
    "\n",
    "        # Augmentation\n",
    "        self.train_transform = get_train_augmentation(img_size=args.img_size, ver=args.aug_ver)\n",
    "        self.test_transform = get_train_augmentation(img_size=args.img_size, ver=1)\n",
    "\n",
    "        # TrainLoader\n",
    "        self.train_loader = get_loader(df_train, phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, transform=self.train_transform)\n",
    "        self.val_loader = get_loader(df_val, phase='train', batch_size=args.batch_size, shuffle=False,\n",
    "                                       num_workers=args.num_workers, transform=self.test_transform)\n",
    "\n",
    "        # Network\n",
    "        self.model = Network(args).to(self.device)\n",
    "        macs, params = get_model_complexity_info(self.model, (3, args.img_size, args.img_size), as_strings=True,\n",
    "                                                 print_per_layer_stat=False, verbose=False)\n",
    "        self.logger.info('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "        self.logger.info('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer & Scheduler\n",
    "        self.optimizer = optim.Lamb(self.model.parameters(), lr=args.initial_lr, weight_decay=args.weight_decay)\n",
    "        \n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        self.warmup_scheduler = WarmUpLR(self.optimizer, iter_per_epoch * args.warm_epoch)\n",
    "\n",
    "        if args.scheduler == 'step':\n",
    "            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=args.milestone, gamma=args.lr_factor, verbose=True)\n",
    "        elif args.scheduler == 'cos':\n",
    "            tmax = args.tmax # half-cycle \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = tmax, eta_min=args.min_lr, verbose=True)\n",
    "        elif args.scheduler == 'cycle':\n",
    "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs)\n",
    "\n",
    "        if args.multi_gpu:\n",
    "            self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        # Train / Validate\n",
    "        best_loss = np.inf\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stopping = 0\n",
    "        start = time.time()\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            if args.scheduler == 'cos':\n",
    "                if epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Training\n",
    "            train_loss, train_acc, train_f1 = self.training(args)\n",
    "\n",
    "            # Model weight in Multi_GPU or Single GPU\n",
    "            state_dict= self.model.module.state_dict() if args.multi_gpu else self.model.state_dict()\n",
    "\n",
    "            # Validation\n",
    "            val_loss, val_acc, val_f1 = self.validate(args, phase='val')\n",
    "\n",
    "            # Save models\n",
    "            if val_loss < best_loss:\n",
    "                early_stopping = 0\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_acc = val_acc\n",
    "                best_f1 = val_f1\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'scheduler': self.scheduler.state_dict(),\n",
    "                    }, os.path.join(save_path, 'best_model_0504_1_ep100.pth'))\n",
    "                self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if early_stopping == args.patience:\n",
    "                break\n",
    "\n",
    "        self.logger.info(f'\\nBest Val Epoch:{best_epoch} | Val Loss:{best_loss:.4f} | Val Acc:{best_acc:.4f} | Val F1:{best_f1:.4f}')\n",
    "        end = time.time()\n",
    "        self.logger.info(f'Total Process time:{(end - start) / 60:.3f}Minute')\n",
    "\n",
    "    # Training\n",
    "    def training(self, args):\n",
    "        self.model.train()\n",
    "        train_loss = AvgMeter()\n",
    "        train_acc = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "        for i, (images, targets) in enumerate(tqdm(self.train_loader)):\n",
    "            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "            # ValueError: too many dimensions 'str'\n",
    "#             targets = torch.tensor(int(targets), device=self.device, dtype=torch.long)\n",
    "            targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if self.epoch <= args.warm_epoch:\n",
    "                self.warmup_scheduler.step()\n",
    "\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            if args.amp:\n",
    "                with autocast():\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, targets)\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Gradient Clipping\n",
    "                if args.clipping is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if args.scheduler == 'cycle':\n",
    "                if self.epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Metric\n",
    "            train_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "            targets_list.extend(targets.cpu().detach().numpy())\n",
    "            # log\n",
    "            train_loss.update(loss.item(), n=images.size(0))\n",
    "\n",
    "        train_acc /= len(self.train_loader.dataset)\n",
    "        train_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "        self.logger.info(f'Epoch:[{self.epoch:03d}/{args.epochs:03d}]')\n",
    "        self.logger.info(f'Train Loss:{train_loss.avg:.3f} | Acc:{train_acc:.4f} | F1:{train_f1:.4f}')\n",
    "        return train_loss.avg, train_acc, train_f1\n",
    "            \n",
    "    # Validation or Dev\n",
    "    def validate(self, args, phase='val'):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = AvgMeter()\n",
    "            val_acc = 0\n",
    "            preds_list = []\n",
    "            targets_list = []\n",
    "\n",
    "            for i, (images, targets) in enumerate(self.val_loader):\n",
    "                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "                targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                # Metric\n",
    "                val_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "                preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "                targets_list.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "                # log\n",
    "                val_loss.update(loss.item(), n=images.size(0))\n",
    "            val_acc /= len(self.val_loader.dataset)\n",
    "            val_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "            self.logger.info(f'{phase} Loss:{val_loss.avg:.3f} | Acc:{val_acc:.4f} | F1:{val_f1:.4f}')\n",
    "        return val_loss.avg, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66f503",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54d2a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print('<---- Training Params ---->')\n",
    "    \n",
    "    # Random Seed\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    save_path = os.path.join(args.model_path, (args.exp_num).zfill(3))\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    Trainer(args, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5763bf",
   "metadata": {},
   "source": [
    "# Inference & Make pseudo label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0beb201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_name, test_loader, device, model_path):\n",
    "    model = Network_test(encoder_name).to(device)\n",
    "    model.load_state_dict(torch.load(opj(model_path, 'best_model_0504_1_ep100.pth'))['state_dict'])\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = torch.as_tensor(images, device=device, dtype=torch.float32)\n",
    "            preds = model(images)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            preds_list.extend(preds.cpu().tolist())\n",
    "\n",
    "    return np.array(preds_list)\n",
    "\n",
    "def ensemble_5fold(model_path_list, test_loader, device):\n",
    "    predict_list = []\n",
    "    for model_path in model_path_list:\n",
    "        prediction = predict(encoder_name= 'regnety_040', test_loader = test_loader, device = device, model_path = model_path)\n",
    "        predict_list.append(prediction)\n",
    "    ensemble = (predict_list[0] + predict_list[1] + predict_list[2] + predict_list[3] + predict_list[4])/len(predict_list)\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "def make_pseudo_df(train_df, test_df, ensemble, step, threshold = 0.9, z_sample = 500): \n",
    "    train_df_copy = train_df.copy()\n",
    "    test_df_copy = test_df.copy()\n",
    "\n",
    "#     test_df_copy['disease'] = np.nan\n",
    "    test_df_copy['label'] = ensemble.argmax(axis=1)\n",
    "    pseudo_test_df = test_df_copy.iloc[np.where(ensemble > threshold)[0]].reset_index(drop=True)\n",
    "    z_idx  = pseudo_test_df[pseudo_test_df['label'] == 0].sample(n=z_sample, random_state=42).index.tolist()\n",
    "    ot_idx = pseudo_test_df[pseudo_test_df['label'].isin([*range(1,88)])].index.tolist()\n",
    "    pseudo_test_df = pseudo_test_df.iloc[z_idx + ot_idx]\n",
    "\n",
    "    train_df_copy = train_df_copy.append(pseudo_test_df, ignore_index=True).reset_index(drop=True) # reset_index\n",
    "    # print(f'Make train_{step}step.csv')\n",
    "    train_df_copy.to_csv(f'./data/0504_1_train_{step}step.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8c70a",
   "metadata": {},
   "source": [
    "# Train & Inference\n",
    "- 5fold Training -> Inference & Ensemble -> Make or Update Pseudo label set -> Add Dataset(Trainset + Pseudo label set)\n",
    "다음과 과정을 반복하기 때문에 Training과 Inference를 동시에 진행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866d58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "df_train = pd.read_csv('./data/train_df.csv')\n",
    "df_test = pd.read_csv('./data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94941098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 07:08:01,457 INFO: {'exp_num': '0', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_040', 'drop_path_rate': 0.2, 'img_size': 256, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'step': 0, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset size:2154\n",
      "<---- Training Params ---->\n",
      "Dataset size:3421\n",
      "Dataset size:856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 07:08:01,696 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_040-f0d569f9.pth)\n",
      "2022-05-04 07:08:05,942 INFO: Computational complexity:       5.2 GMac\n",
      "2022-05-04 07:08:05,942 INFO: Number of parameters:           19.65 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:47<00:00,  1.27it/s]\n",
      "2022-05-04 07:10:53,853 INFO: Epoch:[001/100]\n",
      "2022-05-04 07:10:53,854 INFO: Train Loss:4.578 | Acc:0.0114 | F1:0.0059\n",
      "2022-05-04 07:11:07,096 INFO: val Loss:4.445 | Acc:0.0047 | F1:0.0009\n",
      "2022-05-04 07:11:07,577 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 07:12:43,310 INFO: Epoch:[002/100]\n",
      "2022-05-04 07:12:43,311 INFO: Train Loss:4.559 | Acc:0.0120 | F1:0.0038\n",
      "2022-05-04 07:12:48,813 INFO: val Loss:4.410 | Acc:0.0093 | F1:0.0019\n",
      "2022-05-04 07:12:49,376 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 07:14:27,791 INFO: Epoch:[003/100]\n",
      "2022-05-04 07:14:27,791 INFO: Train Loss:4.527 | Acc:0.0140 | F1:0.0040\n",
      "2022-05-04 07:14:36,287 INFO: val Loss:4.369 | Acc:0.0093 | F1:0.0018\n",
      "2022-05-04 07:14:36,814 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:47<00:00,  1.99it/s]\n",
      "2022-05-04 07:16:24,436 INFO: Epoch:[004/100]\n",
      "2022-05-04 07:16:24,436 INFO: Train Loss:4.478 | Acc:0.0266 | F1:0.0067\n",
      "2022-05-04 07:16:29,876 INFO: val Loss:4.304 | Acc:0.0339 | F1:0.0066\n",
      "2022-05-04 07:16:30,385 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:18:06,515 INFO: Epoch:[005/100]\n",
      "2022-05-04 07:18:06,515 INFO: Train Loss:4.402 | Acc:0.0427 | F1:0.0105\n",
      "2022-05-04 07:18:12,018 INFO: val Loss:4.236 | Acc:0.0900 | F1:0.0182\n",
      "2022-05-04 07:18:12,535 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:19:48,625 INFO: Epoch:[006/100]\n",
      "2022-05-04 07:19:48,626 INFO: Train Loss:4.058 | Acc:0.1847 | F1:0.0395\n",
      "2022-05-04 07:19:54,166 INFO: val Loss:3.604 | Acc:0.4661 | F1:0.0821\n",
      "2022-05-04 07:19:54,679 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:21:30,840 INFO: Epoch:[007/100]\n",
      "2022-05-04 07:21:30,841 INFO: Train Loss:3.395 | Acc:0.5457 | F1:0.0998\n",
      "2022-05-04 07:21:36,361 INFO: val Loss:2.924 | Acc:0.7465 | F1:0.1266\n",
      "2022-05-04 07:21:36,880 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:23:12,685 INFO: Epoch:[008/100]\n",
      "2022-05-04 07:23:12,685 INFO: Train Loss:2.717 | Acc:0.7232 | F1:0.1253\n",
      "2022-05-04 07:23:18,174 INFO: val Loss:2.053 | Acc:0.8318 | F1:0.1441\n",
      "2022-05-04 07:23:18,753 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:24:54,691 INFO: Epoch:[009/100]\n",
      "2022-05-04 07:24:54,691 INFO: Train Loss:2.212 | Acc:0.7738 | F1:0.1354\n",
      "2022-05-04 07:25:00,214 INFO: val Loss:1.443 | Acc:0.8353 | F1:0.1463\n",
      "2022-05-04 07:25:00,741 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.22it/s]\n",
      "2022-05-04 07:26:37,326 INFO: Epoch:[010/100]\n",
      "2022-05-04 07:26:37,327 INFO: Train Loss:1.810 | Acc:0.8135 | F1:0.1467\n",
      "2022-05-04 07:26:42,843 INFO: val Loss:1.185 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-04 07:26:43,362 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:28:19,338 INFO: Epoch:[011/100]\n",
      "2022-05-04 07:28:19,338 INFO: Train Loss:1.636 | Acc:0.8267 | F1:0.1518\n",
      "2022-05-04 07:28:24,875 INFO: val Loss:1.028 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-04 07:28:25,394 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.22it/s]\n",
      "2022-05-04 07:30:01,657 INFO: Epoch:[012/100]\n",
      "2022-05-04 07:30:01,657 INFO: Train Loss:1.512 | Acc:0.8322 | F1:0.1523\n",
      "2022-05-04 07:30:07,205 INFO: val Loss:0.883 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-04 07:30:07,732 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:31:43,770 INFO: Epoch:[013/100]\n",
      "2022-05-04 07:31:43,770 INFO: Train Loss:1.413 | Acc:0.8384 | F1:0.1542\n",
      "2022-05-04 07:31:49,283 INFO: val Loss:0.811 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-04 07:31:49,872 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:33:25,921 INFO: Epoch:[014/100]\n",
      "2022-05-04 07:33:25,922 INFO: Train Loss:1.318 | Acc:0.8378 | F1:0.1553\n",
      "2022-05-04 07:33:31,422 INFO: val Loss:0.726 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-04 07:33:31,945 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:35:07,898 INFO: Epoch:[015/100]\n",
      "2022-05-04 07:35:07,898 INFO: Train Loss:1.182 | Acc:0.8427 | F1:0.1589\n",
      "2022-05-04 07:35:13,431 INFO: val Loss:0.653 | Acc:0.8505 | F1:0.1676\n",
      "2022-05-04 07:35:13,949 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 07:36:51,334 INFO: Epoch:[016/100]\n",
      "2022-05-04 07:36:51,335 INFO: Train Loss:1.017 | Acc:0.8442 | F1:0.1689\n",
      "2022-05-04 07:36:56,855 INFO: val Loss:0.621 | Acc:0.8551 | F1:0.1807\n",
      "2022-05-04 07:36:57,374 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.22it/s]\n",
      "2022-05-04 07:38:33,689 INFO: Epoch:[017/100]\n",
      "2022-05-04 07:38:33,690 INFO: Train Loss:0.957 | Acc:0.8492 | F1:0.1865\n",
      "2022-05-04 07:38:39,238 INFO: val Loss:0.556 | Acc:0.8621 | F1:0.2048\n",
      "2022-05-04 07:38:39,756 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:40:15,867 INFO: Epoch:[018/100]\n",
      "2022-05-04 07:40:15,867 INFO: Train Loss:0.834 | Acc:0.8541 | F1:0.2042\n",
      "2022-05-04 07:40:21,401 INFO: val Loss:0.504 | Acc:0.8715 | F1:0.2570\n",
      "2022-05-04 07:40:21,979 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:41:58,054 INFO: Epoch:[019/100]\n",
      "2022-05-04 07:41:58,054 INFO: Train Loss:0.778 | Acc:0.8559 | F1:0.2440\n",
      "2022-05-04 07:42:03,594 INFO: val Loss:0.461 | Acc:0.8680 | F1:0.2444\n",
      "2022-05-04 07:42:04,121 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:43:39,980 INFO: Epoch:[020/100]\n",
      "2022-05-04 07:43:39,980 INFO: Train Loss:0.711 | Acc:0.8620 | F1:0.2727\n",
      "2022-05-04 07:43:45,520 INFO: val Loss:0.419 | Acc:0.8762 | F1:0.3041\n",
      "2022-05-04 07:43:46,033 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:45:22,101 INFO: Epoch:[021/100]\n",
      "2022-05-04 07:45:22,102 INFO: Train Loss:0.663 | Acc:0.8623 | F1:0.2798\n",
      "2022-05-04 07:45:27,663 INFO: val Loss:0.427 | Acc:0.8820 | F1:0.3294\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:47:03,671 INFO: Epoch:[022/100]\n",
      "2022-05-04 07:47:03,671 INFO: Train Loss:0.621 | Acc:0.8720 | F1:0.3260\n",
      "2022-05-04 07:47:09,233 INFO: val Loss:0.416 | Acc:0.8843 | F1:0.3318\n",
      "2022-05-04 07:47:09,773 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:48:45,705 INFO: Epoch:[023/100]\n",
      "2022-05-04 07:48:45,705 INFO: Train Loss:0.600 | Acc:0.8705 | F1:0.3199\n",
      "2022-05-04 07:48:51,251 INFO: val Loss:0.545 | Acc:0.8224 | F1:0.3506\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:50:27,163 INFO: Epoch:[024/100]\n",
      "2022-05-04 07:50:27,163 INFO: Train Loss:0.576 | Acc:0.8737 | F1:0.3402\n",
      "2022-05-04 07:50:32,683 INFO: val Loss:0.378 | Acc:0.8949 | F1:0.3960\n",
      "2022-05-04 07:50:33,209 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:52:09,075 INFO: Epoch:[025/100]\n",
      "2022-05-04 07:52:09,075 INFO: Train Loss:0.528 | Acc:0.8802 | F1:0.3770\n",
      "2022-05-04 07:52:14,644 INFO: val Loss:0.348 | Acc:0.9042 | F1:0.4451\n",
      "2022-05-04 07:52:15,318 INFO: -----------------SAVE:25epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:53:51,197 INFO: Epoch:[026/100]\n",
      "2022-05-04 07:53:51,198 INFO: Train Loss:0.531 | Acc:0.8804 | F1:0.3927\n",
      "2022-05-04 07:53:56,700 INFO: val Loss:0.369 | Acc:0.9065 | F1:0.4594\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 07:55:32,777 INFO: Epoch:[027/100]\n",
      "2022-05-04 07:55:32,778 INFO: Train Loss:0.490 | Acc:0.8863 | F1:0.4196\n",
      "2022-05-04 07:55:38,279 INFO: val Loss:0.335 | Acc:0.9054 | F1:0.4831\n",
      "2022-05-04 07:55:38,802 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:57:14,646 INFO: Epoch:[028/100]\n",
      "2022-05-04 07:57:14,647 INFO: Train Loss:0.470 | Acc:0.8860 | F1:0.4400\n",
      "2022-05-04 07:57:20,185 INFO: val Loss:0.373 | Acc:0.8890 | F1:0.4713\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 07:58:56,108 INFO: Epoch:[029/100]\n",
      "2022-05-04 07:58:56,108 INFO: Train Loss:0.441 | Acc:0.8924 | F1:0.4629\n",
      "2022-05-04 07:59:01,692 INFO: val Loss:0.339 | Acc:0.9007 | F1:0.4523\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 08:00:37,347 INFO: Epoch:[030/100]\n",
      "2022-05-04 08:00:37,348 INFO: Train Loss:0.447 | Acc:0.8921 | F1:0.4658\n",
      "2022-05-04 08:00:42,877 INFO: val Loss:0.349 | Acc:0.8984 | F1:0.4247\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:02:18,921 INFO: Epoch:[031/100]\n",
      "2022-05-04 08:02:18,921 INFO: Train Loss:0.403 | Acc:0.9038 | F1:0.5154\n",
      "2022-05-04 08:02:24,459 INFO: val Loss:0.322 | Acc:0.9112 | F1:0.4767\n",
      "2022-05-04 08:02:24,971 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:04:00,910 INFO: Epoch:[032/100]\n",
      "2022-05-04 08:04:00,910 INFO: Train Loss:0.403 | Acc:0.8959 | F1:0.4830\n",
      "2022-05-04 08:04:06,414 INFO: val Loss:0.286 | Acc:0.9229 | F1:0.5582\n",
      "2022-05-04 08:04:06,931 INFO: -----------------SAVE:32epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:05:42,773 INFO: Epoch:[033/100]\n",
      "2022-05-04 08:05:42,773 INFO: Train Loss:0.380 | Acc:0.9035 | F1:0.5193\n",
      "2022-05-04 08:05:48,298 INFO: val Loss:0.280 | Acc:0.9206 | F1:0.5754\n",
      "2022-05-04 08:05:48,825 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:07:24,705 INFO: Epoch:[034/100]\n",
      "2022-05-04 08:07:24,706 INFO: Train Loss:0.370 | Acc:0.9056 | F1:0.5400\n",
      "2022-05-04 08:07:30,226 INFO: val Loss:0.262 | Acc:0.9287 | F1:0.5850\n",
      "2022-05-04 08:07:30,803 INFO: -----------------SAVE:34epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:09:06,640 INFO: Epoch:[035/100]\n",
      "2022-05-04 08:09:06,641 INFO: Train Loss:0.360 | Acc:0.9106 | F1:0.5587\n",
      "2022-05-04 08:09:12,152 INFO: val Loss:0.292 | Acc:0.9077 | F1:0.4803\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:10:48,193 INFO: Epoch:[036/100]\n",
      "2022-05-04 08:10:48,193 INFO: Train Loss:0.351 | Acc:0.9073 | F1:0.5351\n",
      "2022-05-04 08:10:53,712 INFO: val Loss:0.275 | Acc:0.9241 | F1:0.5671\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 08:12:29,370 INFO: Epoch:[037/100]\n",
      "2022-05-04 08:12:29,370 INFO: Train Loss:0.330 | Acc:0.9111 | F1:0.5666\n",
      "2022-05-04 08:12:34,872 INFO: val Loss:0.308 | Acc:0.9124 | F1:0.5139\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:14:10,947 INFO: Epoch:[038/100]\n",
      "2022-05-04 08:14:10,947 INFO: Train Loss:0.331 | Acc:0.9141 | F1:0.5780\n",
      "2022-05-04 08:14:16,511 INFO: val Loss:0.294 | Acc:0.9182 | F1:0.5575\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:15:52,420 INFO: Epoch:[039/100]\n",
      "2022-05-04 08:15:52,421 INFO: Train Loss:0.298 | Acc:0.9179 | F1:0.5924\n",
      "2022-05-04 08:15:58,111 INFO: val Loss:0.241 | Acc:0.9299 | F1:0.6100\n",
      "2022-05-04 08:15:58,629 INFO: -----------------SAVE:39epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:17:34,630 INFO: Epoch:[040/100]\n",
      "2022-05-04 08:17:34,630 INFO: Train Loss:0.297 | Acc:0.9234 | F1:0.6199\n",
      "2022-05-04 08:17:40,142 INFO: val Loss:0.284 | Acc:0.9252 | F1:0.6187\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:19:16,173 INFO: Epoch:[041/100]\n",
      "2022-05-04 08:19:16,174 INFO: Train Loss:0.294 | Acc:0.9246 | F1:0.6328\n",
      "2022-05-04 08:19:21,715 INFO: val Loss:0.267 | Acc:0.9322 | F1:0.6513\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:20:57,848 INFO: Epoch:[042/100]\n",
      "2022-05-04 08:20:57,849 INFO: Train Loss:0.284 | Acc:0.9214 | F1:0.6289\n",
      "2022-05-04 08:21:03,426 INFO: val Loss:0.237 | Acc:0.9369 | F1:0.6504\n",
      "2022-05-04 08:21:03,964 INFO: -----------------SAVE:42epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:22:39,901 INFO: Epoch:[043/100]\n",
      "2022-05-04 08:22:39,902 INFO: Train Loss:0.257 | Acc:0.9298 | F1:0.6685\n",
      "2022-05-04 08:22:45,420 INFO: val Loss:0.249 | Acc:0.9357 | F1:0.6677\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:24:21,251 INFO: Epoch:[044/100]\n",
      "2022-05-04 08:24:21,251 INFO: Train Loss:0.244 | Acc:0.9369 | F1:0.6885\n",
      "2022-05-04 08:24:26,785 INFO: val Loss:0.244 | Acc:0.9322 | F1:0.6237\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:26:02,964 INFO: Epoch:[045/100]\n",
      "2022-05-04 08:26:02,964 INFO: Train Loss:0.258 | Acc:0.9313 | F1:0.6682\n",
      "2022-05-04 08:26:08,481 INFO: val Loss:0.254 | Acc:0.9311 | F1:0.6815\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.22it/s]\n",
      "2022-05-04 08:27:44,708 INFO: Epoch:[046/100]\n",
      "2022-05-04 08:27:44,709 INFO: Train Loss:0.236 | Acc:0.9357 | F1:0.6901\n",
      "2022-05-04 08:27:50,272 INFO: val Loss:0.261 | Acc:0.9322 | F1:0.6455\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 08:29:25,933 INFO: Epoch:[047/100]\n",
      "2022-05-04 08:29:25,933 INFO: Train Loss:0.237 | Acc:0.9322 | F1:0.6774\n",
      "2022-05-04 08:29:31,469 INFO: val Loss:0.241 | Acc:0.9346 | F1:0.6495\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 08:31:07,215 INFO: Epoch:[048/100]\n",
      "2022-05-04 08:31:07,216 INFO: Train Loss:0.226 | Acc:0.9389 | F1:0.6944\n",
      "2022-05-04 08:31:12,763 INFO: val Loss:0.197 | Acc:0.9428 | F1:0.6888\n",
      "2022-05-04 08:31:13,350 INFO: -----------------SAVE:48epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:32:49,161 INFO: Epoch:[049/100]\n",
      "2022-05-04 08:32:49,162 INFO: Train Loss:0.212 | Acc:0.9407 | F1:0.7108\n",
      "2022-05-04 08:32:54,690 INFO: val Loss:0.270 | Acc:0.9264 | F1:0.6508\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:34:30,641 INFO: Epoch:[050/100]\n",
      "2022-05-04 08:34:30,642 INFO: Train Loss:0.210 | Acc:0.9436 | F1:0.7383\n",
      "2022-05-04 08:34:36,198 INFO: val Loss:0.236 | Acc:0.9357 | F1:0.7182\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:36:12,115 INFO: Epoch:[051/100]\n",
      "2022-05-04 08:36:12,115 INFO: Train Loss:0.215 | Acc:0.9395 | F1:0.7125\n",
      "2022-05-04 08:36:17,625 INFO: val Loss:0.206 | Acc:0.9428 | F1:0.6894\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 08:37:53,364 INFO: Epoch:[052/100]\n",
      "2022-05-04 08:37:53,365 INFO: Train Loss:0.202 | Acc:0.9433 | F1:0.7421\n",
      "2022-05-04 08:37:58,883 INFO: val Loss:0.209 | Acc:0.9393 | F1:0.6923\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:39:34,883 INFO: Epoch:[053/100]\n",
      "2022-05-04 08:39:34,883 INFO: Train Loss:0.196 | Acc:0.9486 | F1:0.7659\n",
      "2022-05-04 08:39:40,432 INFO: val Loss:0.218 | Acc:0.9357 | F1:0.7205\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:41:16,536 INFO: Epoch:[054/100]\n",
      "2022-05-04 08:41:16,536 INFO: Train Loss:0.175 | Acc:0.9509 | F1:0.7646\n",
      "2022-05-04 08:41:22,057 INFO: val Loss:0.228 | Acc:0.9311 | F1:0.6581\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:36<00:00,  2.23it/s]\n",
      "2022-05-04 08:42:58,093 INFO: Epoch:[055/100]\n",
      "2022-05-04 08:42:58,094 INFO: Train Loss:0.185 | Acc:0.9483 | F1:0.7643\n",
      "2022-05-04 08:43:03,624 INFO: val Loss:0.175 | Acc:0.9474 | F1:0.7445\n",
      "2022-05-04 08:43:04,148 INFO: -----------------SAVE:55epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.24it/s]\n",
      "2022-05-04 08:44:39,777 INFO: Epoch:[056/100]\n",
      "2022-05-04 08:44:39,778 INFO: Train Loss:0.183 | Acc:0.9526 | F1:0.7829\n",
      "2022-05-04 08:44:45,344 INFO: val Loss:0.212 | Acc:0.9428 | F1:0.7267\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:46:21,159 INFO: Epoch:[057/100]\n",
      "2022-05-04 08:46:21,159 INFO: Train Loss:0.161 | Acc:0.9550 | F1:0.7996\n",
      "2022-05-04 08:46:26,706 INFO: val Loss:0.194 | Acc:0.9428 | F1:0.7150\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:48:02,496 INFO: Epoch:[058/100]\n",
      "2022-05-04 08:48:02,496 INFO: Train Loss:0.165 | Acc:0.9535 | F1:0.7981\n",
      "2022-05-04 08:48:08,019 INFO: val Loss:0.212 | Acc:0.9404 | F1:0.7395\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:49:43,945 INFO: Epoch:[059/100]\n",
      "2022-05-04 08:49:43,945 INFO: Train Loss:0.153 | Acc:0.9573 | F1:0.8092\n",
      "2022-05-04 08:49:49,480 INFO: val Loss:0.216 | Acc:0.9498 | F1:0.7456\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:35<00:00,  2.23it/s]\n",
      "2022-05-04 08:51:25,274 INFO: Epoch:[060/100]\n",
      "2022-05-04 08:51:25,274 INFO: Train Loss:0.150 | Acc:0.9582 | F1:0.8121\n",
      "2022-05-04 08:51:30,832 INFO: val Loss:0.170 | Acc:0.9533 | F1:0.7542\n",
      "2022-05-04 08:51:31,354 INFO: -----------------SAVE:60epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 08:53:09,088 INFO: Epoch:[061/100]\n",
      "2022-05-04 08:53:09,088 INFO: Train Loss:0.143 | Acc:0.9594 | F1:0.8225\n",
      "2022-05-04 08:53:14,718 INFO: val Loss:0.263 | Acc:0.9334 | F1:0.7398\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 08:54:52,770 INFO: Epoch:[062/100]\n",
      "2022-05-04 08:54:52,770 INFO: Train Loss:0.132 | Acc:0.9623 | F1:0.8452\n",
      "2022-05-04 08:54:58,369 INFO: val Loss:0.202 | Acc:0.9568 | F1:0.7887\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.21it/s]\n",
      "2022-05-04 08:56:35,389 INFO: Epoch:[063/100]\n",
      "2022-05-04 08:56:35,389 INFO: Train Loss:0.140 | Acc:0.9632 | F1:0.8337\n",
      "2022-05-04 08:56:41,000 INFO: val Loss:0.425 | Acc:0.8949 | F1:0.7012\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 08:58:20,363 INFO: Epoch:[064/100]\n",
      "2022-05-04 08:58:20,363 INFO: Train Loss:0.140 | Acc:0.9608 | F1:0.8187\n",
      "2022-05-04 08:58:26,328 INFO: val Loss:0.186 | Acc:0.9428 | F1:0.7316\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.12it/s]\n",
      "2022-05-04 09:00:07,443 INFO: Epoch:[065/100]\n",
      "2022-05-04 09:00:07,444 INFO: Train Loss:0.130 | Acc:0.9638 | F1:0.8404\n",
      "2022-05-04 09:00:13,213 INFO: val Loss:0.175 | Acc:0.9556 | F1:0.7614\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.10it/s]\n",
      "2022-05-04 09:01:55,164 INFO: Epoch:[066/100]\n",
      "2022-05-04 09:01:55,164 INFO: Train Loss:0.120 | Acc:0.9661 | F1:0.8524\n",
      "2022-05-04 09:02:01,021 INFO: val Loss:0.199 | Acc:0.9416 | F1:0.7457\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:44<00:00,  2.04it/s]\n",
      "2022-05-04 09:03:45,822 INFO: Epoch:[067/100]\n",
      "2022-05-04 09:03:45,823 INFO: Train Loss:0.111 | Acc:0.9690 | F1:0.8637\n",
      "2022-05-04 09:03:51,742 INFO: val Loss:0.160 | Acc:0.9544 | F1:0.7904\n",
      "2022-05-04 09:03:52,342 INFO: -----------------SAVE:67epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 09:05:33,541 INFO: Epoch:[068/100]\n",
      "2022-05-04 09:05:33,542 INFO: Train Loss:0.108 | Acc:0.9711 | F1:0.8758\n",
      "2022-05-04 09:05:39,411 INFO: val Loss:0.187 | Acc:0.9416 | F1:0.7634\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:43<00:00,  2.08it/s]\n",
      "2022-05-04 09:07:22,475 INFO: Epoch:[069/100]\n",
      "2022-05-04 09:07:22,476 INFO: Train Loss:0.105 | Acc:0.9681 | F1:0.8669\n",
      "2022-05-04 09:07:28,277 INFO: val Loss:0.163 | Acc:0.9544 | F1:0.7737\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 09:09:07,781 INFO: Epoch:[070/100]\n",
      "2022-05-04 09:09:07,781 INFO: Train Loss:0.097 | Acc:0.9731 | F1:0.8928\n",
      "2022-05-04 09:09:13,508 INFO: val Loss:0.161 | Acc:0.9544 | F1:0.7993\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 09:10:53,930 INFO: Epoch:[071/100]\n",
      "2022-05-04 09:10:53,930 INFO: Train Loss:0.120 | Acc:0.9661 | F1:0.8618\n",
      "2022-05-04 09:10:59,606 INFO: val Loss:0.173 | Acc:0.9556 | F1:0.7717\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 09:12:40,879 INFO: Epoch:[072/100]\n",
      "2022-05-04 09:12:40,879 INFO: Train Loss:0.103 | Acc:0.9687 | F1:0.8632\n",
      "2022-05-04 09:12:46,702 INFO: val Loss:0.186 | Acc:0.9568 | F1:0.7945\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.14it/s]\n",
      "2022-05-04 09:14:26,609 INFO: Epoch:[073/100]\n",
      "2022-05-04 09:14:26,609 INFO: Train Loss:0.092 | Acc:0.9728 | F1:0.8902\n",
      "2022-05-04 09:14:32,269 INFO: val Loss:0.190 | Acc:0.9498 | F1:0.7832\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 09:16:10,292 INFO: Epoch:[074/100]\n",
      "2022-05-04 09:16:10,292 INFO: Train Loss:0.089 | Acc:0.9766 | F1:0.9058\n",
      "2022-05-04 09:16:16,075 INFO: val Loss:0.164 | Acc:0.9614 | F1:0.7985\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 09:17:54,352 INFO: Epoch:[075/100]\n",
      "2022-05-04 09:17:54,353 INFO: Train Loss:0.079 | Acc:0.9775 | F1:0.9021\n",
      "2022-05-04 09:17:59,982 INFO: val Loss:0.169 | Acc:0.9591 | F1:0.7924\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.18it/s]\n",
      "2022-05-04 09:19:37,965 INFO: Epoch:[076/100]\n",
      "2022-05-04 09:19:37,965 INFO: Train Loss:0.084 | Acc:0.9772 | F1:0.8998\n",
      "2022-05-04 09:19:43,652 INFO: val Loss:0.197 | Acc:0.9533 | F1:0.7806\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:21:21,339 INFO: Epoch:[077/100]\n",
      "2022-05-04 09:21:21,339 INFO: Train Loss:0.070 | Acc:0.9801 | F1:0.9192\n",
      "2022-05-04 09:21:27,025 INFO: val Loss:0.154 | Acc:0.9603 | F1:0.8029\n",
      "2022-05-04 09:21:27,547 INFO: -----------------SAVE:77epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:23:05,180 INFO: Epoch:[078/100]\n",
      "2022-05-04 09:23:05,180 INFO: Train Loss:0.074 | Acc:0.9790 | F1:0.9196\n",
      "2022-05-04 09:23:10,849 INFO: val Loss:0.187 | Acc:0.9556 | F1:0.8344\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:24:48,549 INFO: Epoch:[079/100]\n",
      "2022-05-04 09:24:48,549 INFO: Train Loss:0.063 | Acc:0.9816 | F1:0.9251\n",
      "2022-05-04 09:24:54,208 INFO: val Loss:0.152 | Acc:0.9591 | F1:0.7924\n",
      "2022-05-04 09:24:54,737 INFO: -----------------SAVE:79epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:26:32,340 INFO: Epoch:[080/100]\n",
      "2022-05-04 09:26:32,341 INFO: Train Loss:0.063 | Acc:0.9813 | F1:0.9267\n",
      "2022-05-04 09:26:37,978 INFO: val Loss:0.164 | Acc:0.9603 | F1:0.8191\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.18it/s]\n",
      "2022-05-04 09:28:15,976 INFO: Epoch:[081/100]\n",
      "2022-05-04 09:28:15,976 INFO: Train Loss:0.065 | Acc:0.9804 | F1:0.9260\n",
      "2022-05-04 09:28:21,638 INFO: val Loss:0.134 | Acc:0.9696 | F1:0.8401\n",
      "2022-05-04 09:28:22,169 INFO: -----------------SAVE:81epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:29:59,694 INFO: Epoch:[082/100]\n",
      "2022-05-04 09:29:59,694 INFO: Train Loss:0.060 | Acc:0.9845 | F1:0.9330\n",
      "2022-05-04 09:30:05,373 INFO: val Loss:0.147 | Acc:0.9661 | F1:0.8393\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:31:42,880 INFO: Epoch:[083/100]\n",
      "2022-05-04 09:31:42,881 INFO: Train Loss:0.056 | Acc:0.9851 | F1:0.9411\n",
      "2022-05-04 09:31:48,497 INFO: val Loss:0.144 | Acc:0.9626 | F1:0.8228\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:33:26,114 INFO: Epoch:[084/100]\n",
      "2022-05-04 09:33:26,114 INFO: Train Loss:0.058 | Acc:0.9848 | F1:0.9394\n",
      "2022-05-04 09:33:31,790 INFO: val Loss:0.164 | Acc:0.9591 | F1:0.7960\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:35:09,313 INFO: Epoch:[085/100]\n",
      "2022-05-04 09:35:09,314 INFO: Train Loss:0.052 | Acc:0.9848 | F1:0.9387\n",
      "2022-05-04 09:35:14,969 INFO: val Loss:0.176 | Acc:0.9579 | F1:0.8094\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:36:52,909 INFO: Epoch:[086/100]\n",
      "2022-05-04 09:36:52,909 INFO: Train Loss:0.044 | Acc:0.9895 | F1:0.9655\n",
      "2022-05-04 09:36:58,571 INFO: val Loss:0.202 | Acc:0.9568 | F1:0.8288\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:38:36,207 INFO: Epoch:[087/100]\n",
      "2022-05-04 09:38:36,208 INFO: Train Loss:0.051 | Acc:0.9877 | F1:0.9487\n",
      "2022-05-04 09:38:41,872 INFO: val Loss:0.166 | Acc:0.9638 | F1:0.8189\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 09:40:19,363 INFO: Epoch:[088/100]\n",
      "2022-05-04 09:40:19,364 INFO: Train Loss:0.058 | Acc:0.9868 | F1:0.9499\n",
      "2022-05-04 09:40:25,009 INFO: val Loss:0.191 | Acc:0.9568 | F1:0.8246\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:42:02,586 INFO: Epoch:[089/100]\n",
      "2022-05-04 09:42:02,587 INFO: Train Loss:0.045 | Acc:0.9880 | F1:0.9544\n",
      "2022-05-04 09:42:08,257 INFO: val Loss:0.165 | Acc:0.9614 | F1:0.8411\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 09:43:45,755 INFO: Epoch:[090/100]\n",
      "2022-05-04 09:43:45,755 INFO: Train Loss:0.041 | Acc:0.9889 | F1:0.9561\n",
      "2022-05-04 09:43:51,432 INFO: val Loss:0.152 | Acc:0.9673 | F1:0.8324\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:45:29,084 INFO: Epoch:[091/100]\n",
      "2022-05-04 09:45:29,085 INFO: Train Loss:0.043 | Acc:0.9898 | F1:0.9585\n",
      "2022-05-04 09:45:34,746 INFO: val Loss:0.149 | Acc:0.9673 | F1:0.8437\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:47:12,255 INFO: Epoch:[092/100]\n",
      "2022-05-04 09:47:12,256 INFO: Train Loss:0.046 | Acc:0.9886 | F1:0.9559\n",
      "2022-05-04 09:47:17,905 INFO: val Loss:0.159 | Acc:0.9650 | F1:0.8233\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:48:55,578 INFO: Epoch:[093/100]\n",
      "2022-05-04 09:48:55,578 INFO: Train Loss:0.036 | Acc:0.9904 | F1:0.9596\n",
      "2022-05-04 09:49:01,247 INFO: val Loss:0.160 | Acc:0.9638 | F1:0.8361\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:50:38,770 INFO: Epoch:[094/100]\n",
      "2022-05-04 09:50:38,770 INFO: Train Loss:0.037 | Acc:0.9898 | F1:0.9618\n",
      "2022-05-04 09:50:44,417 INFO: val Loss:0.156 | Acc:0.9685 | F1:0.8724\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:52:22,106 INFO: Epoch:[095/100]\n",
      "2022-05-04 09:52:22,106 INFO: Train Loss:0.033 | Acc:0.9915 | F1:0.9658\n",
      "2022-05-04 09:52:27,757 INFO: val Loss:0.169 | Acc:0.9579 | F1:0.8521\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 09:54:05,406 INFO: Epoch:[096/100]\n",
      "2022-05-04 09:54:05,407 INFO: Train Loss:0.038 | Acc:0.9909 | F1:0.9652\n",
      "2022-05-04 09:54:11,045 INFO: val Loss:0.153 | Acc:0.9614 | F1:0.8304\n",
      "2022-05-04 09:54:11,045 INFO: \n",
      "Best Val Epoch:81 | Val Loss:0.1345 | Val Acc:0.9696 | Val F1:0.8401\n",
      "2022-05-04 09:54:11,046 INFO: Total Process time:166.085Minute\n",
      "2022-05-04 09:54:11,047 INFO: {'exp_num': '1', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_040', 'drop_path_rate': 0.2, 'img_size': 256, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'step': 0, 'fold': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Dataset size:3421\n",
      "Dataset size:856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 09:54:11,313 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_040-f0d569f9.pth)\n",
      "2022-05-04 09:54:11,512 INFO: Computational complexity:       5.2 GMac\n",
      "2022-05-04 09:54:11,513 INFO: Number of parameters:           19.65 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 09:55:50,051 INFO: Epoch:[001/100]\n",
      "2022-05-04 09:55:50,051 INFO: Train Loss:4.595 | Acc:0.0126 | F1:0.0046\n",
      "2022-05-04 09:55:55,649 INFO: val Loss:4.443 | Acc:0.0035 | F1:0.0009\n",
      "2022-05-04 09:55:56,157 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 09:57:34,729 INFO: Epoch:[002/100]\n",
      "2022-05-04 09:57:34,730 INFO: Train Loss:4.569 | Acc:0.0117 | F1:0.0033\n",
      "2022-05-04 09:57:40,331 INFO: val Loss:4.411 | Acc:0.0023 | F1:0.0008\n",
      "2022-05-04 09:57:40,854 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 09:59:19,495 INFO: Epoch:[003/100]\n",
      "2022-05-04 09:59:19,495 INFO: Train Loss:4.524 | Acc:0.0208 | F1:0.0097\n",
      "2022-05-04 09:59:25,089 INFO: val Loss:4.365 | Acc:0.0093 | F1:0.0024\n",
      "2022-05-04 09:59:25,679 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:01:04,263 INFO: Epoch:[004/100]\n",
      "2022-05-04 10:01:04,264 INFO: Train Loss:4.466 | Acc:0.0298 | F1:0.0072\n",
      "2022-05-04 10:01:09,854 INFO: val Loss:4.321 | Acc:0.0210 | F1:0.0037\n",
      "2022-05-04 10:01:10,376 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:02:49,200 INFO: Epoch:[005/100]\n",
      "2022-05-04 10:02:49,200 INFO: Train Loss:4.407 | Acc:0.0418 | F1:0.0111\n",
      "2022-05-04 10:02:54,817 INFO: val Loss:4.247 | Acc:0.0502 | F1:0.0143\n",
      "2022-05-04 10:02:55,347 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:04:33,893 INFO: Epoch:[006/100]\n",
      "2022-05-04 10:04:33,893 INFO: Train Loss:4.032 | Acc:0.1950 | F1:0.0408\n",
      "2022-05-04 10:04:39,500 INFO: val Loss:3.576 | Acc:0.5058 | F1:0.0891\n",
      "2022-05-04 10:04:40,031 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:06:18,979 INFO: Epoch:[007/100]\n",
      "2022-05-04 10:06:18,979 INFO: Train Loss:3.373 | Acc:0.5525 | F1:0.1002\n",
      "2022-05-04 10:06:24,584 INFO: val Loss:2.831 | Acc:0.7570 | F1:0.1287\n",
      "2022-05-04 10:06:25,128 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:08:04,123 INFO: Epoch:[008/100]\n",
      "2022-05-04 10:08:04,124 INFO: Train Loss:2.710 | Acc:0.7162 | F1:0.1230\n",
      "2022-05-04 10:08:09,737 INFO: val Loss:2.007 | Acc:0.8119 | F1:0.1405\n",
      "2022-05-04 10:08:10,277 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:09:49,211 INFO: Epoch:[009/100]\n",
      "2022-05-04 10:09:49,211 INFO: Train Loss:2.196 | Acc:0.7743 | F1:0.1345\n",
      "2022-05-04 10:09:54,847 INFO: val Loss:1.428 | Acc:0.8376 | F1:0.1482\n",
      "2022-05-04 10:09:55,439 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 10:11:34,538 INFO: Epoch:[010/100]\n",
      "2022-05-04 10:11:34,538 INFO: Train Loss:1.825 | Acc:0.8033 | F1:0.1433\n",
      "2022-05-04 10:11:40,148 INFO: val Loss:1.156 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-04 10:11:40,690 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:13:19,557 INFO: Epoch:[011/100]\n",
      "2022-05-04 10:13:19,557 INFO: Train Loss:1.620 | Acc:0.8270 | F1:0.1505\n",
      "2022-05-04 10:13:25,140 INFO: val Loss:0.997 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-04 10:13:25,681 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:15:04,443 INFO: Epoch:[012/100]\n",
      "2022-05-04 10:15:04,443 INFO: Train Loss:1.521 | Acc:0.8313 | F1:0.1527\n",
      "2022-05-04 10:15:10,029 INFO: val Loss:0.900 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-04 10:15:10,572 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:16:49,249 INFO: Epoch:[013/100]\n",
      "2022-05-04 10:16:49,250 INFO: Train Loss:1.420 | Acc:0.8384 | F1:0.1536\n",
      "2022-05-04 10:16:54,819 INFO: val Loss:0.780 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-04 10:16:55,355 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:18:34,262 INFO: Epoch:[014/100]\n",
      "2022-05-04 10:18:34,262 INFO: Train Loss:1.306 | Acc:0.8354 | F1:0.1532\n",
      "2022-05-04 10:18:39,963 INFO: val Loss:0.732 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-04 10:18:40,549 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:20:19,318 INFO: Epoch:[015/100]\n",
      "2022-05-04 10:20:19,318 INFO: Train Loss:1.156 | Acc:0.8433 | F1:0.1599\n",
      "2022-05-04 10:20:24,939 INFO: val Loss:0.677 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-04 10:20:25,477 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:22:04,312 INFO: Epoch:[016/100]\n",
      "2022-05-04 10:22:04,313 INFO: Train Loss:1.029 | Acc:0.8445 | F1:0.1784\n",
      "2022-05-04 10:22:09,931 INFO: val Loss:0.588 | Acc:0.8586 | F1:0.2050\n",
      "2022-05-04 10:22:10,467 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:23:49,217 INFO: Epoch:[017/100]\n",
      "2022-05-04 10:23:49,217 INFO: Train Loss:0.948 | Acc:0.8483 | F1:0.1909\n",
      "2022-05-04 10:23:54,792 INFO: val Loss:0.542 | Acc:0.8668 | F1:0.2360\n",
      "2022-05-04 10:23:55,324 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:25:34,254 INFO: Epoch:[018/100]\n",
      "2022-05-04 10:25:34,254 INFO: Train Loss:0.835 | Acc:0.8550 | F1:0.2239\n",
      "2022-05-04 10:25:39,869 INFO: val Loss:0.494 | Acc:0.8715 | F1:0.2636\n",
      "2022-05-04 10:25:40,410 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 10:27:19,717 INFO: Epoch:[019/100]\n",
      "2022-05-04 10:27:19,717 INFO: Train Loss:0.775 | Acc:0.8574 | F1:0.2521\n",
      "2022-05-04 10:27:25,345 INFO: val Loss:0.463 | Acc:0.8785 | F1:0.2868\n",
      "2022-05-04 10:27:25,942 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:29:04,704 INFO: Epoch:[020/100]\n",
      "2022-05-04 10:29:04,704 INFO: Train Loss:0.693 | Acc:0.8647 | F1:0.2807\n",
      "2022-05-04 10:29:10,292 INFO: val Loss:0.423 | Acc:0.8902 | F1:0.3440\n",
      "2022-05-04 10:29:10,829 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:30:49,616 INFO: Epoch:[021/100]\n",
      "2022-05-04 10:30:49,616 INFO: Train Loss:0.664 | Acc:0.8667 | F1:0.2994\n",
      "2022-05-04 10:30:55,202 INFO: val Loss:0.433 | Acc:0.8820 | F1:0.3273\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:32:33,699 INFO: Epoch:[022/100]\n",
      "2022-05-04 10:32:33,699 INFO: Train Loss:0.631 | Acc:0.8667 | F1:0.3010\n",
      "2022-05-04 10:32:39,330 INFO: val Loss:0.382 | Acc:0.8925 | F1:0.3861\n",
      "2022-05-04 10:32:39,867 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:34:18,711 INFO: Epoch:[023/100]\n",
      "2022-05-04 10:34:18,711 INFO: Train Loss:0.614 | Acc:0.8688 | F1:0.3152\n",
      "2022-05-04 10:34:24,333 INFO: val Loss:0.359 | Acc:0.8937 | F1:0.3943\n",
      "2022-05-04 10:34:24,863 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:36:03,797 INFO: Epoch:[024/100]\n",
      "2022-05-04 10:36:03,798 INFO: Train Loss:0.574 | Acc:0.8778 | F1:0.3615\n",
      "2022-05-04 10:36:09,405 INFO: val Loss:0.383 | Acc:0.8832 | F1:0.3490\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 10:37:48,276 INFO: Epoch:[025/100]\n",
      "2022-05-04 10:37:48,276 INFO: Train Loss:0.523 | Acc:0.8772 | F1:0.3872\n",
      "2022-05-04 10:37:53,908 INFO: val Loss:0.372 | Acc:0.8995 | F1:0.4304\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:39:32,517 INFO: Epoch:[026/100]\n",
      "2022-05-04 10:39:32,517 INFO: Train Loss:0.506 | Acc:0.8825 | F1:0.3999\n",
      "2022-05-04 10:39:38,114 INFO: val Loss:0.360 | Acc:0.9089 | F1:0.4928\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:41:16,612 INFO: Epoch:[027/100]\n",
      "2022-05-04 10:41:16,613 INFO: Train Loss:0.492 | Acc:0.8837 | F1:0.4179\n",
      "2022-05-04 10:41:22,220 INFO: val Loss:0.376 | Acc:0.8867 | F1:0.4113\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:43:01,011 INFO: Epoch:[028/100]\n",
      "2022-05-04 10:43:01,011 INFO: Train Loss:0.466 | Acc:0.8880 | F1:0.4389\n",
      "2022-05-04 10:43:06,641 INFO: val Loss:0.321 | Acc:0.9194 | F1:0.5327\n",
      "2022-05-04 10:43:07,239 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:44:45,996 INFO: Epoch:[029/100]\n",
      "2022-05-04 10:44:45,997 INFO: Train Loss:0.448 | Acc:0.8878 | F1:0.4568\n",
      "2022-05-04 10:44:51,604 INFO: val Loss:0.307 | Acc:0.9136 | F1:0.5012\n",
      "2022-05-04 10:44:52,150 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:46:30,801 INFO: Epoch:[030/100]\n",
      "2022-05-04 10:46:30,802 INFO: Train Loss:0.432 | Acc:0.8916 | F1:0.4536\n",
      "2022-05-04 10:46:36,441 INFO: val Loss:0.319 | Acc:0.9077 | F1:0.5165\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:48:15,104 INFO: Epoch:[031/100]\n",
      "2022-05-04 10:48:15,104 INFO: Train Loss:0.414 | Acc:0.8930 | F1:0.4702\n",
      "2022-05-04 10:48:20,759 INFO: val Loss:0.300 | Acc:0.9124 | F1:0.5215\n",
      "2022-05-04 10:48:21,296 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:49:59,836 INFO: Epoch:[032/100]\n",
      "2022-05-04 10:49:59,836 INFO: Train Loss:0.398 | Acc:0.8977 | F1:0.5004\n",
      "2022-05-04 10:50:05,500 INFO: val Loss:0.311 | Acc:0.9206 | F1:0.5265\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:51:44,009 INFO: Epoch:[033/100]\n",
      "2022-05-04 10:51:44,009 INFO: Train Loss:0.365 | Acc:0.9056 | F1:0.5390\n",
      "2022-05-04 10:51:49,659 INFO: val Loss:0.289 | Acc:0.9194 | F1:0.5418\n",
      "2022-05-04 10:51:50,194 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:53:28,861 INFO: Epoch:[034/100]\n",
      "2022-05-04 10:53:28,861 INFO: Train Loss:0.362 | Acc:0.9050 | F1:0.5161\n",
      "2022-05-04 10:53:34,533 INFO: val Loss:0.294 | Acc:0.9241 | F1:0.5771\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:55:13,204 INFO: Epoch:[035/100]\n",
      "2022-05-04 10:55:13,205 INFO: Train Loss:0.352 | Acc:0.9076 | F1:0.5383\n",
      "2022-05-04 10:55:18,873 INFO: val Loss:0.319 | Acc:0.9217 | F1:0.5507\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:56:57,600 INFO: Epoch:[036/100]\n",
      "2022-05-04 10:56:57,600 INFO: Train Loss:0.326 | Acc:0.9158 | F1:0.5870\n",
      "2022-05-04 10:57:03,305 INFO: val Loss:0.273 | Acc:0.9287 | F1:0.5882\n",
      "2022-05-04 10:57:03,845 INFO: -----------------SAVE:36epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 10:58:42,565 INFO: Epoch:[037/100]\n",
      "2022-05-04 10:58:42,566 INFO: Train Loss:0.333 | Acc:0.9144 | F1:0.5819\n",
      "2022-05-04 10:58:48,245 INFO: val Loss:0.268 | Acc:0.9264 | F1:0.5906\n",
      "2022-05-04 10:58:48,789 INFO: -----------------SAVE:37epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:00:27,432 INFO: Epoch:[038/100]\n",
      "2022-05-04 11:00:27,433 INFO: Train Loss:0.320 | Acc:0.9132 | F1:0.5784\n",
      "2022-05-04 11:00:33,037 INFO: val Loss:0.430 | Acc:0.8902 | F1:0.5622\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 11:02:12,035 INFO: Epoch:[039/100]\n",
      "2022-05-04 11:02:12,035 INFO: Train Loss:0.295 | Acc:0.9217 | F1:0.6033\n",
      "2022-05-04 11:02:17,688 INFO: val Loss:0.286 | Acc:0.9241 | F1:0.6005\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:03:56,448 INFO: Epoch:[040/100]\n",
      "2022-05-04 11:03:56,449 INFO: Train Loss:0.312 | Acc:0.9182 | F1:0.6169\n",
      "2022-05-04 11:04:02,106 INFO: val Loss:0.249 | Acc:0.9311 | F1:0.6121\n",
      "2022-05-04 11:04:02,630 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 11:05:41,613 INFO: Epoch:[041/100]\n",
      "2022-05-04 11:05:41,613 INFO: Train Loss:0.292 | Acc:0.9187 | F1:0.6195\n",
      "2022-05-04 11:05:47,264 INFO: val Loss:0.258 | Acc:0.9346 | F1:0.6470\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 11:07:26,339 INFO: Epoch:[042/100]\n",
      "2022-05-04 11:07:26,339 INFO: Train Loss:0.284 | Acc:0.9255 | F1:0.6390\n",
      "2022-05-04 11:07:32,010 INFO: val Loss:0.253 | Acc:0.9241 | F1:0.5990\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:09:10,781 INFO: Epoch:[043/100]\n",
      "2022-05-04 11:09:10,782 INFO: Train Loss:0.270 | Acc:0.9214 | F1:0.6211\n",
      "2022-05-04 11:09:16,442 INFO: val Loss:0.247 | Acc:0.9229 | F1:0.5468\n",
      "2022-05-04 11:09:16,975 INFO: -----------------SAVE:43epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 11:10:55,919 INFO: Epoch:[044/100]\n",
      "2022-05-04 11:10:55,920 INFO: Train Loss:0.259 | Acc:0.9269 | F1:0.6497\n",
      "2022-05-04 11:11:01,641 INFO: val Loss:0.233 | Acc:0.9381 | F1:0.6556\n",
      "2022-05-04 11:11:02,185 INFO: -----------------SAVE:44epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:12:40,955 INFO: Epoch:[045/100]\n",
      "2022-05-04 11:12:40,955 INFO: Train Loss:0.264 | Acc:0.9284 | F1:0.6595\n",
      "2022-05-04 11:12:46,593 INFO: val Loss:0.321 | Acc:0.8902 | F1:0.6212\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:14:25,241 INFO: Epoch:[046/100]\n",
      "2022-05-04 11:14:25,242 INFO: Train Loss:0.237 | Acc:0.9319 | F1:0.6781\n",
      "2022-05-04 11:14:30,918 INFO: val Loss:0.215 | Acc:0.9428 | F1:0.6677\n",
      "2022-05-04 11:14:31,472 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:16:10,099 INFO: Epoch:[047/100]\n",
      "2022-05-04 11:16:10,100 INFO: Train Loss:0.223 | Acc:0.9383 | F1:0.7177\n",
      "2022-05-04 11:16:15,746 INFO: val Loss:0.215 | Acc:0.9404 | F1:0.6693\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:17:54,165 INFO: Epoch:[048/100]\n",
      "2022-05-04 11:17:54,166 INFO: Train Loss:0.214 | Acc:0.9410 | F1:0.7207\n",
      "2022-05-04 11:17:59,949 INFO: val Loss:0.187 | Acc:0.9474 | F1:0.7167\n",
      "2022-05-04 11:18:00,513 INFO: -----------------SAVE:48epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 11:19:39,673 INFO: Epoch:[049/100]\n",
      "2022-05-04 11:19:39,674 INFO: Train Loss:0.206 | Acc:0.9401 | F1:0.7330\n",
      "2022-05-04 11:19:45,427 INFO: val Loss:0.191 | Acc:0.9463 | F1:0.6961\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 11:21:23,963 INFO: Epoch:[050/100]\n",
      "2022-05-04 11:21:23,963 INFO: Train Loss:0.205 | Acc:0.9445 | F1:0.7456\n",
      "2022-05-04 11:21:29,609 INFO: val Loss:0.203 | Acc:0.9486 | F1:0.7319\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 11:23:08,633 INFO: Epoch:[051/100]\n",
      "2022-05-04 11:23:08,633 INFO: Train Loss:0.197 | Acc:0.9453 | F1:0.7442\n",
      "2022-05-04 11:23:14,333 INFO: val Loss:0.188 | Acc:0.9474 | F1:0.7097\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 11:24:54,555 INFO: Epoch:[052/100]\n",
      "2022-05-04 11:24:54,556 INFO: Train Loss:0.215 | Acc:0.9374 | F1:0.7143\n",
      "2022-05-04 11:25:00,241 INFO: val Loss:0.182 | Acc:0.9486 | F1:0.7214\n",
      "2022-05-04 11:25:00,791 INFO: -----------------SAVE:52epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:26:38,707 INFO: Epoch:[053/100]\n",
      "2022-05-04 11:26:38,708 INFO: Train Loss:0.203 | Acc:0.9445 | F1:0.7673\n",
      "2022-05-04 11:26:44,277 INFO: val Loss:0.185 | Acc:0.9474 | F1:0.6956\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:28:21,989 INFO: Epoch:[054/100]\n",
      "2022-05-04 11:28:21,989 INFO: Train Loss:0.192 | Acc:0.9439 | F1:0.7504\n",
      "2022-05-04 11:28:27,536 INFO: val Loss:0.215 | Acc:0.9404 | F1:0.6555\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:30:05,036 INFO: Epoch:[055/100]\n",
      "2022-05-04 11:30:05,036 INFO: Train Loss:0.189 | Acc:0.9488 | F1:0.7755\n",
      "2022-05-04 11:30:10,612 INFO: val Loss:0.178 | Acc:0.9474 | F1:0.6998\n",
      "2022-05-04 11:30:11,137 INFO: -----------------SAVE:55epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:31:48,219 INFO: Epoch:[056/100]\n",
      "2022-05-04 11:31:48,219 INFO: Train Loss:0.185 | Acc:0.9488 | F1:0.7745\n",
      "2022-05-04 11:31:53,774 INFO: val Loss:0.181 | Acc:0.9509 | F1:0.7310\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:33:31,009 INFO: Epoch:[057/100]\n",
      "2022-05-04 11:33:31,009 INFO: Train Loss:0.166 | Acc:0.9524 | F1:0.8031\n",
      "2022-05-04 11:33:36,609 INFO: val Loss:0.186 | Acc:0.9521 | F1:0.7340\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:35:13,947 INFO: Epoch:[058/100]\n",
      "2022-05-04 11:35:13,948 INFO: Train Loss:0.168 | Acc:0.9524 | F1:0.7854\n",
      "2022-05-04 11:35:19,545 INFO: val Loss:0.165 | Acc:0.9556 | F1:0.7312\n",
      "2022-05-04 11:35:20,138 INFO: -----------------SAVE:58epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:36:57,639 INFO: Epoch:[059/100]\n",
      "2022-05-04 11:36:57,639 INFO: Train Loss:0.156 | Acc:0.9564 | F1:0.8027\n",
      "2022-05-04 11:37:03,258 INFO: val Loss:0.197 | Acc:0.9439 | F1:0.7190\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:38:40,654 INFO: Epoch:[060/100]\n",
      "2022-05-04 11:38:40,655 INFO: Train Loss:0.151 | Acc:0.9562 | F1:0.8135\n",
      "2022-05-04 11:38:46,256 INFO: val Loss:0.183 | Acc:0.9533 | F1:0.7388\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:40:23,686 INFO: Epoch:[061/100]\n",
      "2022-05-04 11:40:23,687 INFO: Train Loss:0.161 | Acc:0.9524 | F1:0.7947\n",
      "2022-05-04 11:40:29,274 INFO: val Loss:0.212 | Acc:0.9521 | F1:0.7087\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:42:06,705 INFO: Epoch:[062/100]\n",
      "2022-05-04 11:42:06,706 INFO: Train Loss:0.138 | Acc:0.9608 | F1:0.8331\n",
      "2022-05-04 11:42:12,302 INFO: val Loss:0.166 | Acc:0.9556 | F1:0.7683\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:43:49,863 INFO: Epoch:[063/100]\n",
      "2022-05-04 11:43:49,864 INFO: Train Loss:0.138 | Acc:0.9602 | F1:0.8321\n",
      "2022-05-04 11:43:55,467 INFO: val Loss:0.204 | Acc:0.9556 | F1:0.7759\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:45:32,803 INFO: Epoch:[064/100]\n",
      "2022-05-04 11:45:32,803 INFO: Train Loss:0.122 | Acc:0.9643 | F1:0.8480\n",
      "2022-05-04 11:45:38,384 INFO: val Loss:0.176 | Acc:0.9556 | F1:0.7524\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:47:16,058 INFO: Epoch:[065/100]\n",
      "2022-05-04 11:47:16,059 INFO: Train Loss:0.124 | Acc:0.9638 | F1:0.8441\n",
      "2022-05-04 11:47:21,656 INFO: val Loss:0.193 | Acc:0.9521 | F1:0.7531\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:48:58,902 INFO: Epoch:[066/100]\n",
      "2022-05-04 11:48:58,903 INFO: Train Loss:0.137 | Acc:0.9629 | F1:0.8472\n",
      "2022-05-04 11:49:04,528 INFO: val Loss:0.154 | Acc:0.9638 | F1:0.8324\n",
      "2022-05-04 11:49:05,062 INFO: -----------------SAVE:66epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:50:42,560 INFO: Epoch:[067/100]\n",
      "2022-05-04 11:50:42,561 INFO: Train Loss:0.121 | Acc:0.9649 | F1:0.8573\n",
      "2022-05-04 11:50:48,143 INFO: val Loss:0.149 | Acc:0.9614 | F1:0.7981\n",
      "2022-05-04 11:50:48,682 INFO: -----------------SAVE:67epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:52:26,334 INFO: Epoch:[068/100]\n",
      "2022-05-04 11:52:26,334 INFO: Train Loss:0.114 | Acc:0.9687 | F1:0.8696\n",
      "2022-05-04 11:52:31,875 INFO: val Loss:0.156 | Acc:0.9614 | F1:0.7822\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 11:54:09,408 INFO: Epoch:[069/100]\n",
      "2022-05-04 11:54:09,408 INFO: Train Loss:0.107 | Acc:0.9708 | F1:0.8875\n",
      "2022-05-04 11:54:14,954 INFO: val Loss:0.147 | Acc:0.9603 | F1:0.7766\n",
      "2022-05-04 11:54:15,586 INFO: -----------------SAVE:69epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:55:52,871 INFO: Epoch:[070/100]\n",
      "2022-05-04 11:55:52,871 INFO: Train Loss:0.111 | Acc:0.9699 | F1:0.8868\n",
      "2022-05-04 11:55:58,431 INFO: val Loss:0.136 | Acc:0.9661 | F1:0.8089\n",
      "2022-05-04 11:55:59,018 INFO: -----------------SAVE:70epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:57:36,507 INFO: Epoch:[071/100]\n",
      "2022-05-04 11:57:36,508 INFO: Train Loss:0.101 | Acc:0.9725 | F1:0.8881\n",
      "2022-05-04 11:57:42,048 INFO: val Loss:0.179 | Acc:0.9603 | F1:0.8018\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 11:59:19,521 INFO: Epoch:[072/100]\n",
      "2022-05-04 11:59:19,522 INFO: Train Loss:0.098 | Acc:0.9725 | F1:0.8876\n",
      "2022-05-04 11:59:25,075 INFO: val Loss:0.142 | Acc:0.9661 | F1:0.8277\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:01:02,489 INFO: Epoch:[073/100]\n",
      "2022-05-04 12:01:02,489 INFO: Train Loss:0.086 | Acc:0.9728 | F1:0.8879\n",
      "2022-05-04 12:01:08,053 INFO: val Loss:0.160 | Acc:0.9603 | F1:0.8044\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:02:45,433 INFO: Epoch:[074/100]\n",
      "2022-05-04 12:02:45,433 INFO: Train Loss:0.093 | Acc:0.9737 | F1:0.8956\n",
      "2022-05-04 12:02:50,972 INFO: val Loss:0.119 | Acc:0.9696 | F1:0.8103\n",
      "2022-05-04 12:02:51,500 INFO: -----------------SAVE:74epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:04:28,944 INFO: Epoch:[075/100]\n",
      "2022-05-04 12:04:28,945 INFO: Train Loss:0.085 | Acc:0.9743 | F1:0.8940\n",
      "2022-05-04 12:04:34,529 INFO: val Loss:0.117 | Acc:0.9696 | F1:0.8468\n",
      "2022-05-04 12:04:35,057 INFO: -----------------SAVE:75epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:06:12,704 INFO: Epoch:[076/100]\n",
      "2022-05-04 12:06:12,704 INFO: Train Loss:0.094 | Acc:0.9737 | F1:0.8985\n",
      "2022-05-04 12:06:18,277 INFO: val Loss:0.113 | Acc:0.9708 | F1:0.8310\n",
      "2022-05-04 12:06:18,816 INFO: -----------------SAVE:76epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:07:56,429 INFO: Epoch:[077/100]\n",
      "2022-05-04 12:07:56,429 INFO: Train Loss:0.075 | Acc:0.9766 | F1:0.9055\n",
      "2022-05-04 12:08:02,009 INFO: val Loss:0.190 | Acc:0.9498 | F1:0.8342\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:09:39,680 INFO: Epoch:[078/100]\n",
      "2022-05-04 12:09:39,681 INFO: Train Loss:0.079 | Acc:0.9775 | F1:0.9059\n",
      "2022-05-04 12:09:45,262 INFO: val Loss:0.138 | Acc:0.9720 | F1:0.8485\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:11:22,858 INFO: Epoch:[079/100]\n",
      "2022-05-04 12:11:22,858 INFO: Train Loss:0.067 | Acc:0.9819 | F1:0.9242\n",
      "2022-05-04 12:11:28,402 INFO: val Loss:0.130 | Acc:0.9731 | F1:0.8469\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:13:05,947 INFO: Epoch:[080/100]\n",
      "2022-05-04 12:13:05,947 INFO: Train Loss:0.073 | Acc:0.9769 | F1:0.9081\n",
      "2022-05-04 12:13:11,494 INFO: val Loss:0.124 | Acc:0.9743 | F1:0.8578\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:14:49,130 INFO: Epoch:[081/100]\n",
      "2022-05-04 12:14:49,130 INFO: Train Loss:0.070 | Acc:0.9804 | F1:0.9159\n",
      "2022-05-04 12:14:54,671 INFO: val Loss:0.123 | Acc:0.9731 | F1:0.8548\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:16:31,958 INFO: Epoch:[082/100]\n",
      "2022-05-04 12:16:31,958 INFO: Train Loss:0.071 | Acc:0.9822 | F1:0.9340\n",
      "2022-05-04 12:16:37,523 INFO: val Loss:0.118 | Acc:0.9708 | F1:0.8601\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:18:15,220 INFO: Epoch:[083/100]\n",
      "2022-05-04 12:18:15,220 INFO: Train Loss:0.054 | Acc:0.9845 | F1:0.9363\n",
      "2022-05-04 12:18:20,789 INFO: val Loss:0.117 | Acc:0.9755 | F1:0.8451\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:19:58,309 INFO: Epoch:[084/100]\n",
      "2022-05-04 12:19:58,310 INFO: Train Loss:0.054 | Acc:0.9863 | F1:0.9494\n",
      "2022-05-04 12:20:03,908 INFO: val Loss:0.120 | Acc:0.9755 | F1:0.8680\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:21:41,487 INFO: Epoch:[085/100]\n",
      "2022-05-04 12:21:41,487 INFO: Train Loss:0.046 | Acc:0.9866 | F1:0.9459\n",
      "2022-05-04 12:21:47,086 INFO: val Loss:0.105 | Acc:0.9743 | F1:0.8819\n",
      "2022-05-04 12:21:47,711 INFO: -----------------SAVE:85epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:23:25,122 INFO: Epoch:[086/100]\n",
      "2022-05-04 12:23:25,123 INFO: Train Loss:0.054 | Acc:0.9851 | F1:0.9379\n",
      "2022-05-04 12:23:30,704 INFO: val Loss:0.114 | Acc:0.9743 | F1:0.8627\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:25:08,326 INFO: Epoch:[087/100]\n",
      "2022-05-04 12:25:08,326 INFO: Train Loss:0.047 | Acc:0.9871 | F1:0.9506\n",
      "2022-05-04 12:25:13,897 INFO: val Loss:0.111 | Acc:0.9766 | F1:0.8961\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:26:51,526 INFO: Epoch:[088/100]\n",
      "2022-05-04 12:26:51,526 INFO: Train Loss:0.047 | Acc:0.9851 | F1:0.9413\n",
      "2022-05-04 12:26:57,075 INFO: val Loss:0.108 | Acc:0.9778 | F1:0.8773\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.18it/s]\n",
      "2022-05-04 12:28:35,055 INFO: Epoch:[089/100]\n",
      "2022-05-04 12:28:35,055 INFO: Train Loss:0.039 | Acc:0.9906 | F1:0.9712\n",
      "2022-05-04 12:28:40,594 INFO: val Loss:0.111 | Acc:0.9731 | F1:0.8469\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:30:17,990 INFO: Epoch:[090/100]\n",
      "2022-05-04 12:30:17,991 INFO: Train Loss:0.040 | Acc:0.9889 | F1:0.9566\n",
      "2022-05-04 12:30:23,531 INFO: val Loss:0.111 | Acc:0.9766 | F1:0.8638\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:32:01,185 INFO: Epoch:[091/100]\n",
      "2022-05-04 12:32:01,185 INFO: Train Loss:0.041 | Acc:0.9886 | F1:0.9564\n",
      "2022-05-04 12:32:06,745 INFO: val Loss:0.110 | Acc:0.9778 | F1:0.8641\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:33:44,392 INFO: Epoch:[092/100]\n",
      "2022-05-04 12:33:44,392 INFO: Train Loss:0.042 | Acc:0.9880 | F1:0.9500\n",
      "2022-05-04 12:33:49,942 INFO: val Loss:0.123 | Acc:0.9790 | F1:0.8744\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:35:27,424 INFO: Epoch:[093/100]\n",
      "2022-05-04 12:35:27,425 INFO: Train Loss:0.037 | Acc:0.9915 | F1:0.9688\n",
      "2022-05-04 12:35:32,977 INFO: val Loss:0.114 | Acc:0.9766 | F1:0.8611\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:37:10,452 INFO: Epoch:[094/100]\n",
      "2022-05-04 12:37:10,453 INFO: Train Loss:0.035 | Acc:0.9904 | F1:0.9648\n",
      "2022-05-04 12:37:16,015 INFO: val Loss:0.115 | Acc:0.9755 | F1:0.8586\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:38:53,534 INFO: Epoch:[095/100]\n",
      "2022-05-04 12:38:53,535 INFO: Train Loss:0.039 | Acc:0.9901 | F1:0.9605\n",
      "2022-05-04 12:38:59,107 INFO: val Loss:0.111 | Acc:0.9755 | F1:0.8651\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:40:36,415 INFO: Epoch:[096/100]\n",
      "2022-05-04 12:40:36,415 INFO: Train Loss:0.034 | Acc:0.9915 | F1:0.9681\n",
      "2022-05-04 12:40:41,948 INFO: val Loss:0.107 | Acc:0.9778 | F1:0.8717\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:42:19,262 INFO: Epoch:[097/100]\n",
      "2022-05-04 12:42:19,263 INFO: Train Loss:0.037 | Acc:0.9906 | F1:0.9656\n",
      "2022-05-04 12:42:24,793 INFO: val Loss:0.114 | Acc:0.9778 | F1:0.8858\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 12:44:02,361 INFO: Epoch:[098/100]\n",
      "2022-05-04 12:44:02,362 INFO: Train Loss:0.023 | Acc:0.9953 | F1:0.9822\n",
      "2022-05-04 12:44:07,900 INFO: val Loss:0.112 | Acc:0.9778 | F1:0.8816\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:45:45,360 INFO: Epoch:[099/100]\n",
      "2022-05-04 12:45:45,361 INFO: Train Loss:0.034 | Acc:0.9918 | F1:0.9718\n",
      "2022-05-04 12:45:50,915 INFO: val Loss:0.114 | Acc:0.9790 | F1:0.8779\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.20it/s]\n",
      "2022-05-04 12:47:28,305 INFO: Epoch:[100/100]\n",
      "2022-05-04 12:47:28,305 INFO: Train Loss:0.030 | Acc:0.9918 | F1:0.9681\n",
      "2022-05-04 12:47:33,833 INFO: val Loss:0.116 | Acc:0.9766 | F1:0.8737\n",
      "2022-05-04 12:47:33,834 INFO: \n",
      "Best Val Epoch:85 | Val Loss:0.1050 | Val Acc:0.9743 | Val F1:0.8819\n",
      "2022-05-04 12:47:33,834 INFO: Total Process time:173.372Minute\n",
      "2022-05-04 12:47:33,836 INFO: {'exp_num': '2', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_040', 'drop_path_rate': 0.2, 'img_size': 256, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'step': 0, 'fold': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Dataset size:3422\n",
      "Dataset size:855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 12:47:34,109 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_040-f0d569f9.pth)\n",
      "2022-05-04 12:47:34,293 INFO: Computational complexity:       5.2 GMac\n",
      "2022-05-04 12:47:34,294 INFO: Number of parameters:           19.65 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.14it/s]\n",
      "2022-05-04 12:49:14,208 INFO: Epoch:[001/100]\n",
      "2022-05-04 12:49:14,209 INFO: Train Loss:4.582 | Acc:0.0070 | F1:0.0018\n",
      "2022-05-04 12:49:20,375 INFO: val Loss:4.440 | Acc:0.0000 | F1:0.0000\n",
      "2022-05-04 12:49:20,872 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 12:50:58,952 INFO: Epoch:[002/100]\n",
      "2022-05-04 12:50:58,952 INFO: Train Loss:4.578 | Acc:0.0123 | F1:0.0036\n",
      "2022-05-04 12:51:04,655 INFO: val Loss:4.407 | Acc:0.0023 | F1:0.0005\n",
      "2022-05-04 12:51:05,252 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 12:52:43,544 INFO: Epoch:[003/100]\n",
      "2022-05-04 12:52:43,545 INFO: Train Loss:4.533 | Acc:0.0178 | F1:0.0047\n",
      "2022-05-04 12:52:49,194 INFO: val Loss:4.381 | Acc:0.0035 | F1:0.0027\n",
      "2022-05-04 12:52:49,772 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 12:54:28,055 INFO: Epoch:[004/100]\n",
      "2022-05-04 12:54:28,055 INFO: Train Loss:4.474 | Acc:0.0278 | F1:0.0075\n",
      "2022-05-04 12:54:33,716 INFO: val Loss:4.312 | Acc:0.0199 | F1:0.0050\n",
      "2022-05-04 12:54:34,256 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 12:56:12,710 INFO: Epoch:[005/100]\n",
      "2022-05-04 12:56:12,710 INFO: Train Loss:4.402 | Acc:0.0424 | F1:0.0104\n",
      "2022-05-04 12:56:18,325 INFO: val Loss:4.226 | Acc:0.0842 | F1:0.0202\n",
      "2022-05-04 12:56:18,855 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 12:57:57,049 INFO: Epoch:[006/100]\n",
      "2022-05-04 12:57:57,049 INFO: Train Loss:4.030 | Acc:0.1990 | F1:0.0424\n",
      "2022-05-04 12:58:02,662 INFO: val Loss:3.610 | Acc:0.4678 | F1:0.0832\n",
      "2022-05-04 12:58:03,193 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.18it/s]\n",
      "2022-05-04 12:59:41,148 INFO: Epoch:[007/100]\n",
      "2022-05-04 12:59:41,148 INFO: Train Loss:3.387 | Acc:0.5579 | F1:0.1028\n",
      "2022-05-04 12:59:46,786 INFO: val Loss:2.864 | Acc:0.7684 | F1:0.1295\n",
      "2022-05-04 12:59:47,388 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:01:25,639 INFO: Epoch:[008/100]\n",
      "2022-05-04 13:01:25,640 INFO: Train Loss:2.737 | Acc:0.7177 | F1:0.1238\n",
      "2022-05-04 13:01:31,241 INFO: val Loss:2.029 | Acc:0.8316 | F1:0.1441\n",
      "2022-05-04 13:01:31,851 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:03:10,159 INFO: Epoch:[009/100]\n",
      "2022-05-04 13:03:10,159 INFO: Train Loss:2.184 | Acc:0.7800 | F1:0.1350\n",
      "2022-05-04 13:03:15,780 INFO: val Loss:1.410 | Acc:0.8351 | F1:0.1447\n",
      "2022-05-04 13:03:16,315 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:04:54,650 INFO: Epoch:[010/100]\n",
      "2022-05-04 13:04:54,651 INFO: Train Loss:1.817 | Acc:0.8103 | F1:0.1434\n",
      "2022-05-04 13:05:00,250 INFO: val Loss:1.145 | Acc:0.8468 | F1:0.1552\n",
      "2022-05-04 13:05:00,801 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:06:39,452 INFO: Epoch:[011/100]\n",
      "2022-05-04 13:06:39,452 INFO: Train Loss:1.613 | Acc:0.8214 | F1:0.1488\n",
      "2022-05-04 13:06:45,074 INFO: val Loss:1.038 | Acc:0.8491 | F1:0.1561\n",
      "2022-05-04 13:06:45,609 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:08:24,007 INFO: Epoch:[012/100]\n",
      "2022-05-04 13:08:24,007 INFO: Train Loss:1.505 | Acc:0.8340 | F1:0.1529\n",
      "2022-05-04 13:08:29,627 INFO: val Loss:0.879 | Acc:0.8491 | F1:0.1561\n",
      "2022-05-04 13:08:30,166 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:10:08,661 INFO: Epoch:[013/100]\n",
      "2022-05-04 13:10:08,661 INFO: Train Loss:1.400 | Acc:0.8369 | F1:0.1538\n",
      "2022-05-04 13:10:14,268 INFO: val Loss:0.804 | Acc:0.8491 | F1:0.1561\n",
      "2022-05-04 13:10:14,857 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:11:53,289 INFO: Epoch:[014/100]\n",
      "2022-05-04 13:11:53,290 INFO: Train Loss:1.314 | Acc:0.8372 | F1:0.1540\n",
      "2022-05-04 13:11:58,904 INFO: val Loss:0.745 | Acc:0.8491 | F1:0.1562\n",
      "2022-05-04 13:11:59,453 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:13:37,968 INFO: Epoch:[015/100]\n",
      "2022-05-04 13:13:37,968 INFO: Train Loss:1.163 | Acc:0.8419 | F1:0.1584\n",
      "2022-05-04 13:13:43,550 INFO: val Loss:0.665 | Acc:0.8515 | F1:0.1681\n",
      "2022-05-04 13:13:44,090 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:15:22,322 INFO: Epoch:[016/100]\n",
      "2022-05-04 13:15:22,323 INFO: Train Loss:1.029 | Acc:0.8410 | F1:0.1755\n",
      "2022-05-04 13:15:27,929 INFO: val Loss:0.606 | Acc:0.8585 | F1:0.1967\n",
      "2022-05-04 13:15:28,468 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:17:06,602 INFO: Epoch:[017/100]\n",
      "2022-05-04 13:17:06,602 INFO: Train Loss:0.946 | Acc:0.8510 | F1:0.1986\n",
      "2022-05-04 13:17:12,222 INFO: val Loss:0.577 | Acc:0.8713 | F1:0.2588\n",
      "2022-05-04 13:17:12,764 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:18:51,035 INFO: Epoch:[018/100]\n",
      "2022-05-04 13:18:51,036 INFO: Train Loss:0.847 | Acc:0.8521 | F1:0.2068\n",
      "2022-05-04 13:18:56,685 INFO: val Loss:0.518 | Acc:0.8690 | F1:0.2455\n",
      "2022-05-04 13:18:57,282 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:20:35,868 INFO: Epoch:[019/100]\n",
      "2022-05-04 13:20:35,868 INFO: Train Loss:0.791 | Acc:0.8501 | F1:0.2207\n",
      "2022-05-04 13:20:41,576 INFO: val Loss:0.463 | Acc:0.8760 | F1:0.2633\n",
      "2022-05-04 13:20:42,115 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:22:20,333 INFO: Epoch:[020/100]\n",
      "2022-05-04 13:22:20,334 INFO: Train Loss:0.719 | Acc:0.8594 | F1:0.2542\n",
      "2022-05-04 13:22:25,945 INFO: val Loss:0.467 | Acc:0.8819 | F1:0.3056\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:24:04,115 INFO: Epoch:[021/100]\n",
      "2022-05-04 13:24:04,116 INFO: Train Loss:0.675 | Acc:0.8612 | F1:0.2636\n",
      "2022-05-04 13:24:09,752 INFO: val Loss:0.440 | Acc:0.8947 | F1:0.3770\n",
      "2022-05-04 13:24:10,283 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:25:48,667 INFO: Epoch:[022/100]\n",
      "2022-05-04 13:25:48,667 INFO: Train Loss:0.626 | Acc:0.8653 | F1:0.2819\n",
      "2022-05-04 13:25:54,329 INFO: val Loss:0.419 | Acc:0.8912 | F1:0.3767\n",
      "2022-05-04 13:25:54,866 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:27:33,642 INFO: Epoch:[023/100]\n",
      "2022-05-04 13:27:33,642 INFO: Train Loss:0.603 | Acc:0.8714 | F1:0.3310\n",
      "2022-05-04 13:27:39,264 INFO: val Loss:0.410 | Acc:0.8877 | F1:0.3470\n",
      "2022-05-04 13:27:39,808 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:29:18,245 INFO: Epoch:[024/100]\n",
      "2022-05-04 13:29:18,245 INFO: Train Loss:0.575 | Acc:0.8735 | F1:0.3532\n",
      "2022-05-04 13:29:23,889 INFO: val Loss:0.389 | Acc:0.8971 | F1:0.4052\n",
      "2022-05-04 13:29:24,573 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:31:02,892 INFO: Epoch:[025/100]\n",
      "2022-05-04 13:31:02,892 INFO: Train Loss:0.535 | Acc:0.8764 | F1:0.3615\n",
      "2022-05-04 13:31:08,514 INFO: val Loss:0.369 | Acc:0.9006 | F1:0.4205\n",
      "2022-05-04 13:31:09,049 INFO: -----------------SAVE:25epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:32:47,391 INFO: Epoch:[026/100]\n",
      "2022-05-04 13:32:47,391 INFO: Train Loss:0.525 | Acc:0.8814 | F1:0.3985\n",
      "2022-05-04 13:32:53,000 INFO: val Loss:0.354 | Acc:0.9018 | F1:0.4196\n",
      "2022-05-04 13:32:53,542 INFO: -----------------SAVE:26epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:34:31,900 INFO: Epoch:[027/100]\n",
      "2022-05-04 13:34:31,900 INFO: Train Loss:0.506 | Acc:0.8849 | F1:0.4221\n",
      "2022-05-04 13:34:37,502 INFO: val Loss:0.387 | Acc:0.9064 | F1:0.4712\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:36:15,900 INFO: Epoch:[028/100]\n",
      "2022-05-04 13:36:15,900 INFO: Train Loss:0.469 | Acc:0.8863 | F1:0.4260\n",
      "2022-05-04 13:36:21,510 INFO: val Loss:0.344 | Acc:0.9111 | F1:0.4851\n",
      "2022-05-04 13:36:22,046 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:38:00,439 INFO: Epoch:[029/100]\n",
      "2022-05-04 13:38:00,440 INFO: Train Loss:0.448 | Acc:0.8916 | F1:0.4555\n",
      "2022-05-04 13:38:06,103 INFO: val Loss:0.310 | Acc:0.9170 | F1:0.4987\n",
      "2022-05-04 13:38:06,639 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:39:44,901 INFO: Epoch:[030/100]\n",
      "2022-05-04 13:39:44,901 INFO: Train Loss:0.439 | Acc:0.8925 | F1:0.4623\n",
      "2022-05-04 13:39:50,522 INFO: val Loss:0.349 | Acc:0.9053 | F1:0.5208\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:41:28,858 INFO: Epoch:[031/100]\n",
      "2022-05-04 13:41:28,859 INFO: Train Loss:0.414 | Acc:0.8963 | F1:0.4853\n",
      "2022-05-04 13:41:34,494 INFO: val Loss:0.309 | Acc:0.9193 | F1:0.5293\n",
      "2022-05-04 13:41:35,121 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:43:13,172 INFO: Epoch:[032/100]\n",
      "2022-05-04 13:43:13,173 INFO: Train Loss:0.388 | Acc:0.9065 | F1:0.5290\n",
      "2022-05-04 13:43:18,793 INFO: val Loss:0.316 | Acc:0.9170 | F1:0.5299\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:44:57,104 INFO: Epoch:[033/100]\n",
      "2022-05-04 13:44:57,104 INFO: Train Loss:0.383 | Acc:0.9015 | F1:0.5303\n",
      "2022-05-04 13:45:02,735 INFO: val Loss:0.378 | Acc:0.9088 | F1:0.5005\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 13:46:41,136 INFO: Epoch:[034/100]\n",
      "2022-05-04 13:46:41,137 INFO: Train Loss:0.359 | Acc:0.9068 | F1:0.5322\n",
      "2022-05-04 13:46:46,765 INFO: val Loss:0.289 | Acc:0.9240 | F1:0.5671\n",
      "2022-05-04 13:46:47,301 INFO: -----------------SAVE:34epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:48:25,583 INFO: Epoch:[035/100]\n",
      "2022-05-04 13:48:25,583 INFO: Train Loss:0.352 | Acc:0.9053 | F1:0.5421\n",
      "2022-05-04 13:48:31,192 INFO: val Loss:0.303 | Acc:0.9193 | F1:0.5442\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:50:09,517 INFO: Epoch:[036/100]\n",
      "2022-05-04 13:50:09,517 INFO: Train Loss:0.355 | Acc:0.9120 | F1:0.5709\n",
      "2022-05-04 13:50:15,115 INFO: val Loss:0.271 | Acc:0.9275 | F1:0.5939\n",
      "2022-05-04 13:50:15,640 INFO: -----------------SAVE:36epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:51:53,755 INFO: Epoch:[037/100]\n",
      "2022-05-04 13:51:53,755 INFO: Train Loss:0.319 | Acc:0.9138 | F1:0.5825\n",
      "2022-05-04 13:51:59,370 INFO: val Loss:0.310 | Acc:0.9275 | F1:0.5743\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 13:53:37,274 INFO: Epoch:[038/100]\n",
      "2022-05-04 13:53:37,275 INFO: Train Loss:0.317 | Acc:0.9167 | F1:0.5991\n",
      "2022-05-04 13:53:42,912 INFO: val Loss:0.278 | Acc:0.9322 | F1:0.6165\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:55:21,041 INFO: Epoch:[039/100]\n",
      "2022-05-04 13:55:21,041 INFO: Train Loss:0.301 | Acc:0.9211 | F1:0.6154\n",
      "2022-05-04 13:55:26,703 INFO: val Loss:0.298 | Acc:0.9333 | F1:0.6230\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:57:04,850 INFO: Epoch:[040/100]\n",
      "2022-05-04 13:57:04,850 INFO: Train Loss:0.301 | Acc:0.9202 | F1:0.6115\n",
      "2022-05-04 13:57:10,441 INFO: val Loss:0.262 | Acc:0.9298 | F1:0.5871\n",
      "2022-05-04 13:57:10,983 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 13:58:49,110 INFO: Epoch:[041/100]\n",
      "2022-05-04 13:58:49,111 INFO: Train Loss:0.290 | Acc:0.9231 | F1:0.6247\n",
      "2022-05-04 13:58:54,717 INFO: val Loss:0.233 | Acc:0.9345 | F1:0.6253\n",
      "2022-05-04 13:58:55,313 INFO: -----------------SAVE:41epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:00:33,472 INFO: Epoch:[042/100]\n",
      "2022-05-04 14:00:33,473 INFO: Train Loss:0.272 | Acc:0.9220 | F1:0.6189\n",
      "2022-05-04 14:00:39,058 INFO: val Loss:0.236 | Acc:0.9392 | F1:0.6524\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:02:17,244 INFO: Epoch:[043/100]\n",
      "2022-05-04 14:02:17,244 INFO: Train Loss:0.256 | Acc:0.9290 | F1:0.6511\n",
      "2022-05-04 14:02:22,876 INFO: val Loss:0.240 | Acc:0.9415 | F1:0.6636\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:04:01,062 INFO: Epoch:[044/100]\n",
      "2022-05-04 14:04:01,062 INFO: Train Loss:0.250 | Acc:0.9337 | F1:0.6866\n",
      "2022-05-04 14:04:06,679 INFO: val Loss:0.231 | Acc:0.9357 | F1:0.6349\n",
      "2022-05-04 14:04:07,218 INFO: -----------------SAVE:44epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:05:45,365 INFO: Epoch:[045/100]\n",
      "2022-05-04 14:05:45,366 INFO: Train Loss:0.248 | Acc:0.9328 | F1:0.6836\n",
      "2022-05-04 14:05:50,983 INFO: val Loss:0.225 | Acc:0.9345 | F1:0.6414\n",
      "2022-05-04 14:05:51,520 INFO: -----------------SAVE:45epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:07:29,642 INFO: Epoch:[046/100]\n",
      "2022-05-04 14:07:29,642 INFO: Train Loss:0.249 | Acc:0.9325 | F1:0.6736\n",
      "2022-05-04 14:07:35,276 INFO: val Loss:0.218 | Acc:0.9404 | F1:0.6478\n",
      "2022-05-04 14:07:35,895 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:09:14,194 INFO: Epoch:[047/100]\n",
      "2022-05-04 14:09:14,194 INFO: Train Loss:0.229 | Acc:0.9398 | F1:0.7146\n",
      "2022-05-04 14:09:19,850 INFO: val Loss:0.233 | Acc:0.9380 | F1:0.6190\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:10:58,304 INFO: Epoch:[048/100]\n",
      "2022-05-04 14:10:58,304 INFO: Train Loss:0.222 | Acc:0.9354 | F1:0.6963\n",
      "2022-05-04 14:11:03,969 INFO: val Loss:0.234 | Acc:0.9439 | F1:0.6759\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:12:42,266 INFO: Epoch:[049/100]\n",
      "2022-05-04 14:12:42,266 INFO: Train Loss:0.209 | Acc:0.9395 | F1:0.7107\n",
      "2022-05-04 14:12:47,930 INFO: val Loss:0.229 | Acc:0.9357 | F1:0.7192\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:14:26,008 INFO: Epoch:[050/100]\n",
      "2022-05-04 14:14:26,009 INFO: Train Loss:0.202 | Acc:0.9451 | F1:0.7430\n",
      "2022-05-04 14:14:31,645 INFO: val Loss:0.185 | Acc:0.9532 | F1:0.7410\n",
      "2022-05-04 14:14:32,182 INFO: -----------------SAVE:50epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:16:10,513 INFO: Epoch:[051/100]\n",
      "2022-05-04 14:16:10,514 INFO: Train Loss:0.196 | Acc:0.9436 | F1:0.7325\n",
      "2022-05-04 14:16:16,143 INFO: val Loss:0.241 | Acc:0.9462 | F1:0.7058\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:17:54,183 INFO: Epoch:[052/100]\n",
      "2022-05-04 14:17:54,183 INFO: Train Loss:0.203 | Acc:0.9424 | F1:0.7316\n",
      "2022-05-04 14:17:59,819 INFO: val Loss:0.186 | Acc:0.9462 | F1:0.7063\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:19:38,352 INFO: Epoch:[053/100]\n",
      "2022-05-04 14:19:38,353 INFO: Train Loss:0.191 | Acc:0.9465 | F1:0.7532\n",
      "2022-05-04 14:19:44,028 INFO: val Loss:0.209 | Acc:0.9497 | F1:0.7216\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:21:22,777 INFO: Epoch:[054/100]\n",
      "2022-05-04 14:21:22,778 INFO: Train Loss:0.175 | Acc:0.9509 | F1:0.7880\n",
      "2022-05-04 14:21:28,510 INFO: val Loss:0.219 | Acc:0.9404 | F1:0.6970\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:23:06,696 INFO: Epoch:[055/100]\n",
      "2022-05-04 14:23:06,697 INFO: Train Loss:0.189 | Acc:0.9477 | F1:0.7774\n",
      "2022-05-04 14:23:12,327 INFO: val Loss:0.193 | Acc:0.9579 | F1:0.7391\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:24:50,519 INFO: Epoch:[056/100]\n",
      "2022-05-04 14:24:50,520 INFO: Train Loss:0.178 | Acc:0.9497 | F1:0.7720\n",
      "2022-05-04 14:24:56,140 INFO: val Loss:0.220 | Acc:0.9497 | F1:0.7350\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:26:34,337 INFO: Epoch:[057/100]\n",
      "2022-05-04 14:26:34,338 INFO: Train Loss:0.154 | Acc:0.9544 | F1:0.8076\n",
      "2022-05-04 14:26:39,975 INFO: val Loss:0.171 | Acc:0.9591 | F1:0.7765\n",
      "2022-05-04 14:26:40,575 INFO: -----------------SAVE:57epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:28:19,109 INFO: Epoch:[058/100]\n",
      "2022-05-04 14:28:19,109 INFO: Train Loss:0.151 | Acc:0.9582 | F1:0.8315\n",
      "2022-05-04 14:28:24,756 INFO: val Loss:0.185 | Acc:0.9602 | F1:0.7740\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:30:03,244 INFO: Epoch:[059/100]\n",
      "2022-05-04 14:30:03,245 INFO: Train Loss:0.164 | Acc:0.9538 | F1:0.8051\n",
      "2022-05-04 14:30:08,905 INFO: val Loss:0.161 | Acc:0.9556 | F1:0.7658\n",
      "2022-05-04 14:30:09,505 INFO: -----------------SAVE:59epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:31:47,801 INFO: Epoch:[060/100]\n",
      "2022-05-04 14:31:47,802 INFO: Train Loss:0.149 | Acc:0.9591 | F1:0.8236\n",
      "2022-05-04 14:31:53,478 INFO: val Loss:0.181 | Acc:0.9509 | F1:0.7202\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:33:31,699 INFO: Epoch:[061/100]\n",
      "2022-05-04 14:33:31,699 INFO: Train Loss:0.146 | Acc:0.9565 | F1:0.8047\n",
      "2022-05-04 14:33:37,362 INFO: val Loss:0.184 | Acc:0.9579 | F1:0.7363\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:35:15,551 INFO: Epoch:[062/100]\n",
      "2022-05-04 14:35:15,551 INFO: Train Loss:0.135 | Acc:0.9641 | F1:0.8412\n",
      "2022-05-04 14:35:21,198 INFO: val Loss:0.169 | Acc:0.9626 | F1:0.7744\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:36:59,215 INFO: Epoch:[063/100]\n",
      "2022-05-04 14:36:59,216 INFO: Train Loss:0.152 | Acc:0.9603 | F1:0.8412\n",
      "2022-05-04 14:37:04,868 INFO: val Loss:0.131 | Acc:0.9637 | F1:0.7970\n",
      "2022-05-04 14:37:05,410 INFO: -----------------SAVE:63epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:37<00:00,  2.19it/s]\n",
      "2022-05-04 14:38:43,256 INFO: Epoch:[064/100]\n",
      "2022-05-04 14:38:43,256 INFO: Train Loss:0.125 | Acc:0.9623 | F1:0.8398\n",
      "2022-05-04 14:38:48,888 INFO: val Loss:0.151 | Acc:0.9637 | F1:0.7709\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:40:27,334 INFO: Epoch:[065/100]\n",
      "2022-05-04 14:40:27,334 INFO: Train Loss:0.121 | Acc:0.9652 | F1:0.8611\n",
      "2022-05-04 14:40:32,980 INFO: val Loss:0.157 | Acc:0.9602 | F1:0.7915\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.18it/s]\n",
      "2022-05-04 14:42:11,099 INFO: Epoch:[066/100]\n",
      "2022-05-04 14:42:11,100 INFO: Train Loss:0.119 | Acc:0.9635 | F1:0.8378\n",
      "2022-05-04 14:42:16,708 INFO: val Loss:0.195 | Acc:0.9427 | F1:0.7696\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 14:43:56,730 INFO: Epoch:[067/100]\n",
      "2022-05-04 14:43:56,730 INFO: Train Loss:0.117 | Acc:0.9679 | F1:0.8632\n",
      "2022-05-04 14:44:02,451 INFO: val Loss:0.123 | Acc:0.9684 | F1:0.8116\n",
      "2022-05-04 14:44:02,989 INFO: -----------------SAVE:67epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 14:45:42,194 INFO: Epoch:[068/100]\n",
      "2022-05-04 14:45:42,194 INFO: Train Loss:0.119 | Acc:0.9676 | F1:0.8670\n",
      "2022-05-04 14:45:47,897 INFO: val Loss:0.140 | Acc:0.9637 | F1:0.7934\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 14:47:27,111 INFO: Epoch:[069/100]\n",
      "2022-05-04 14:47:27,112 INFO: Train Loss:0.104 | Acc:0.9679 | F1:0.8629\n",
      "2022-05-04 14:47:32,840 INFO: val Loss:0.150 | Acc:0.9626 | F1:0.7977\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 14:49:12,294 INFO: Epoch:[070/100]\n",
      "2022-05-04 14:49:12,294 INFO: Train Loss:0.110 | Acc:0.9684 | F1:0.8682\n",
      "2022-05-04 14:49:17,992 INFO: val Loss:0.129 | Acc:0.9754 | F1:0.8594\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 14:50:56,789 INFO: Epoch:[071/100]\n",
      "2022-05-04 14:50:56,790 INFO: Train Loss:0.092 | Acc:0.9708 | F1:0.8796\n",
      "2022-05-04 14:51:02,524 INFO: val Loss:0.122 | Acc:0.9673 | F1:0.8073\n",
      "2022-05-04 14:51:03,106 INFO: -----------------SAVE:71epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 14:52:42,196 INFO: Epoch:[072/100]\n",
      "2022-05-04 14:52:42,196 INFO: Train Loss:0.096 | Acc:0.9728 | F1:0.8869\n",
      "2022-05-04 14:52:47,865 INFO: val Loss:0.136 | Acc:0.9637 | F1:0.8022\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 14:54:26,813 INFO: Epoch:[073/100]\n",
      "2022-05-04 14:54:26,813 INFO: Train Loss:0.095 | Acc:0.9725 | F1:0.8860\n",
      "2022-05-04 14:54:32,511 INFO: val Loss:0.106 | Acc:0.9743 | F1:0.8438\n",
      "2022-05-04 14:54:33,040 INFO: -----------------SAVE:73epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 14:56:13,921 INFO: Epoch:[074/100]\n",
      "2022-05-04 14:56:13,922 INFO: Train Loss:0.086 | Acc:0.9781 | F1:0.9209\n",
      "2022-05-04 14:56:19,650 INFO: val Loss:0.125 | Acc:0.9673 | F1:0.8298\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.12it/s]\n",
      "2022-05-04 14:58:00,804 INFO: Epoch:[075/100]\n",
      "2022-05-04 14:58:00,804 INFO: Train Loss:0.084 | Acc:0.9755 | F1:0.9104\n",
      "2022-05-04 14:58:06,645 INFO: val Loss:0.121 | Acc:0.9684 | F1:0.8067\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 14:59:47,976 INFO: Epoch:[076/100]\n",
      "2022-05-04 14:59:47,977 INFO: Train Loss:0.070 | Acc:0.9798 | F1:0.9235\n",
      "2022-05-04 14:59:53,635 INFO: val Loss:0.113 | Acc:0.9696 | F1:0.8205\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 15:01:32,925 INFO: Epoch:[077/100]\n",
      "2022-05-04 15:01:32,926 INFO: Train Loss:0.084 | Acc:0.9766 | F1:0.9033\n",
      "2022-05-04 15:01:38,607 INFO: val Loss:0.095 | Acc:0.9743 | F1:0.8556\n",
      "2022-05-04 15:01:39,149 INFO: -----------------SAVE:77epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 15:03:18,268 INFO: Epoch:[078/100]\n",
      "2022-05-04 15:03:18,268 INFO: Train Loss:0.073 | Acc:0.9787 | F1:0.9133\n",
      "2022-05-04 15:03:23,957 INFO: val Loss:0.132 | Acc:0.9626 | F1:0.7985\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 15:05:03,401 INFO: Epoch:[079/100]\n",
      "2022-05-04 15:05:03,401 INFO: Train Loss:0.075 | Acc:0.9772 | F1:0.9085\n",
      "2022-05-04 15:05:09,108 INFO: val Loss:0.122 | Acc:0.9649 | F1:0.7875\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 15:06:50,046 INFO: Epoch:[080/100]\n",
      "2022-05-04 15:06:50,047 INFO: Train Loss:0.076 | Acc:0.9801 | F1:0.9183\n",
      "2022-05-04 15:06:55,866 INFO: val Loss:0.126 | Acc:0.9661 | F1:0.8167\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 15:08:36,829 INFO: Epoch:[081/100]\n",
      "2022-05-04 15:08:36,829 INFO: Train Loss:0.059 | Acc:0.9836 | F1:0.9349\n",
      "2022-05-04 15:08:42,477 INFO: val Loss:0.123 | Acc:0.9708 | F1:0.8299\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 15:10:23,788 INFO: Epoch:[082/100]\n",
      "2022-05-04 15:10:23,788 INFO: Train Loss:0.060 | Acc:0.9813 | F1:0.9299\n",
      "2022-05-04 15:10:29,621 INFO: val Loss:0.121 | Acc:0.9673 | F1:0.7984\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 15:12:12,318 INFO: Epoch:[083/100]\n",
      "2022-05-04 15:12:12,319 INFO: Train Loss:0.061 | Acc:0.9833 | F1:0.9403\n",
      "2022-05-04 15:12:18,080 INFO: val Loss:0.093 | Acc:0.9743 | F1:0.8371\n",
      "2022-05-04 15:12:18,683 INFO: -----------------SAVE:83epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:46<00:00,  2.01it/s]\n",
      "2022-05-04 15:14:04,940 INFO: Epoch:[084/100]\n",
      "2022-05-04 15:14:04,940 INFO: Train Loss:0.059 | Acc:0.9822 | F1:0.9230\n",
      "2022-05-04 15:14:10,882 INFO: val Loss:0.130 | Acc:0.9696 | F1:0.8212\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 15:15:51,592 INFO: Epoch:[085/100]\n",
      "2022-05-04 15:15:51,592 INFO: Train Loss:0.059 | Acc:0.9831 | F1:0.9358\n",
      "2022-05-04 15:15:57,297 INFO: val Loss:0.108 | Acc:0.9696 | F1:0.8177\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 15:17:37,058 INFO: Epoch:[086/100]\n",
      "2022-05-04 15:17:37,058 INFO: Train Loss:0.055 | Acc:0.9854 | F1:0.9454\n",
      "2022-05-04 15:17:42,903 INFO: val Loss:0.092 | Acc:0.9731 | F1:0.8552\n",
      "2022-05-04 15:17:43,459 INFO: -----------------SAVE:86epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:19:25,923 INFO: Epoch:[087/100]\n",
      "2022-05-04 15:19:25,924 INFO: Train Loss:0.055 | Acc:0.9854 | F1:0.9423\n",
      "2022-05-04 15:19:31,582 INFO: val Loss:0.095 | Acc:0.9789 | F1:0.8703\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 15:21:11,341 INFO: Epoch:[088/100]\n",
      "2022-05-04 15:21:11,342 INFO: Train Loss:0.036 | Acc:0.9877 | F1:0.9496\n",
      "2022-05-04 15:21:17,030 INFO: val Loss:0.091 | Acc:0.9754 | F1:0.8613\n",
      "2022-05-04 15:21:17,567 INFO: -----------------SAVE:88epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.14it/s]\n",
      "2022-05-04 15:22:57,485 INFO: Epoch:[089/100]\n",
      "2022-05-04 15:22:57,486 INFO: Train Loss:0.048 | Acc:0.9883 | F1:0.9559\n",
      "2022-05-04 15:23:03,418 INFO: val Loss:0.094 | Acc:0.9766 | F1:0.8638\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 15:24:42,649 INFO: Epoch:[090/100]\n",
      "2022-05-04 15:24:42,649 INFO: Train Loss:0.047 | Acc:0.9871 | F1:0.9441\n",
      "2022-05-04 15:24:48,306 INFO: val Loss:0.099 | Acc:0.9789 | F1:0.8747\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.17it/s]\n",
      "2022-05-04 15:26:27,145 INFO: Epoch:[091/100]\n",
      "2022-05-04 15:26:27,146 INFO: Train Loss:0.050 | Acc:0.9868 | F1:0.9500\n",
      "2022-05-04 15:26:32,804 INFO: val Loss:0.100 | Acc:0.9731 | F1:0.8509\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 15:28:12,172 INFO: Epoch:[092/100]\n",
      "2022-05-04 15:28:12,173 INFO: Train Loss:0.035 | Acc:0.9915 | F1:0.9633\n",
      "2022-05-04 15:28:17,819 INFO: val Loss:0.107 | Acc:0.9778 | F1:0.8565\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 15:29:56,881 INFO: Epoch:[093/100]\n",
      "2022-05-04 15:29:56,881 INFO: Train Loss:0.041 | Acc:0.9904 | F1:0.9690\n",
      "2022-05-04 15:30:02,755 INFO: val Loss:0.102 | Acc:0.9766 | F1:0.8505\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 15:31:42,793 INFO: Epoch:[094/100]\n",
      "2022-05-04 15:31:42,794 INFO: Train Loss:0.036 | Acc:0.9892 | F1:0.9609\n",
      "2022-05-04 15:31:48,474 INFO: val Loss:0.089 | Acc:0.9801 | F1:0.8810\n",
      "2022-05-04 15:31:49,085 INFO: -----------------SAVE:94epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 15:33:28,476 INFO: Epoch:[095/100]\n",
      "2022-05-04 15:33:28,477 INFO: Train Loss:0.033 | Acc:0.9915 | F1:0.9638\n",
      "2022-05-04 15:33:34,142 INFO: val Loss:0.088 | Acc:0.9789 | F1:0.8793\n",
      "2022-05-04 15:33:34,675 INFO: -----------------SAVE:95epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 15:35:17,541 INFO: Epoch:[096/100]\n",
      "2022-05-04 15:35:17,542 INFO: Train Loss:0.037 | Acc:0.9909 | F1:0.9702\n",
      "2022-05-04 15:35:23,698 INFO: val Loss:0.088 | Acc:0.9778 | F1:0.8651\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 15:37:06,578 INFO: Epoch:[097/100]\n",
      "2022-05-04 15:37:06,579 INFO: Train Loss:0.040 | Acc:0.9886 | F1:0.9542\n",
      "2022-05-04 15:37:12,597 INFO: val Loss:0.089 | Acc:0.9778 | F1:0.8657\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 15:38:55,347 INFO: Epoch:[098/100]\n",
      "2022-05-04 15:38:55,347 INFO: Train Loss:0.043 | Acc:0.9874 | F1:0.9522\n",
      "2022-05-04 15:39:01,362 INFO: val Loss:0.089 | Acc:0.9766 | F1:0.8670\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:40:43,710 INFO: Epoch:[099/100]\n",
      "2022-05-04 15:40:43,710 INFO: Train Loss:0.030 | Acc:0.9924 | F1:0.9692\n",
      "2022-05-04 15:40:49,650 INFO: val Loss:0.086 | Acc:0.9778 | F1:0.8635\n",
      "2022-05-04 15:40:50,272 INFO: -----------------SAVE:99epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.10it/s]\n",
      "2022-05-04 15:42:32,205 INFO: Epoch:[100/100]\n",
      "2022-05-04 15:42:32,206 INFO: Train Loss:0.032 | Acc:0.9933 | F1:0.9753\n",
      "2022-05-04 15:42:38,171 INFO: val Loss:0.088 | Acc:0.9789 | F1:0.8764\n",
      "2022-05-04 15:42:38,172 INFO: \n",
      "Best Val Epoch:99 | Val Loss:0.0861 | Val Acc:0.9778 | Val F1:0.8635\n",
      "2022-05-04 15:42:38,172 INFO: Total Process time:175.065Minute\n",
      "2022-05-04 15:42:38,174 INFO: {'exp_num': '3', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_040', 'drop_path_rate': 0.2, 'img_size': 256, 'batch_size': 16, 'epochs': 100, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 15, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'step': 0, 'fold': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Dataset size:3422\n",
      "Dataset size:855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-04 15:42:38,440 INFO: Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-regnet/regnety_040-f0d569f9.pth)\n",
      "2022-05-04 15:42:38,625 INFO: Computational complexity:       5.2 GMac\n",
      "2022-05-04 15:42:38,626 INFO: Number of parameters:           19.65 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 15:44:21,455 INFO: Epoch:[001/100]\n",
      "2022-05-04 15:44:21,455 INFO: Train Loss:4.586 | Acc:0.0099 | F1:0.0025\n",
      "2022-05-04 15:44:27,517 INFO: val Loss:4.449 | Acc:0.0012 | F1:0.0002\n",
      "2022-05-04 15:44:28,050 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:43<00:00,  2.07it/s]\n",
      "2022-05-04 15:46:11,268 INFO: Epoch:[002/100]\n",
      "2022-05-04 15:46:11,269 INFO: Train Loss:4.566 | Acc:0.0152 | F1:0.0043\n",
      "2022-05-04 15:46:17,227 INFO: val Loss:4.426 | Acc:0.0058 | F1:0.0010\n",
      "2022-05-04 15:46:17,834 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 15:48:00,716 INFO: Epoch:[003/100]\n",
      "2022-05-04 15:48:00,716 INFO: Train Loss:4.534 | Acc:0.0158 | F1:0.0037\n",
      "2022-05-04 15:48:06,784 INFO: val Loss:4.369 | Acc:0.0152 | F1:0.0036\n",
      "2022-05-04 15:48:07,334 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:49:49,928 INFO: Epoch:[004/100]\n",
      "2022-05-04 15:49:49,929 INFO: Train Loss:4.482 | Acc:0.0251 | F1:0.0061\n",
      "2022-05-04 15:49:55,951 INFO: val Loss:4.310 | Acc:0.0257 | F1:0.0050\n",
      "2022-05-04 15:49:56,480 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:51:38,923 INFO: Epoch:[005/100]\n",
      "2022-05-04 15:51:38,924 INFO: Train Loss:4.404 | Acc:0.0412 | F1:0.0102\n",
      "2022-05-04 15:51:44,953 INFO: val Loss:4.237 | Acc:0.0690 | F1:0.0166\n",
      "2022-05-04 15:51:45,478 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:53:27,936 INFO: Epoch:[006/100]\n",
      "2022-05-04 15:53:27,936 INFO: Train Loss:4.033 | Acc:0.1964 | F1:0.0418\n",
      "2022-05-04 15:53:33,961 INFO: val Loss:3.608 | Acc:0.4187 | F1:0.0746\n",
      "2022-05-04 15:53:34,492 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:55:16,863 INFO: Epoch:[007/100]\n",
      "2022-05-04 15:55:16,863 INFO: Train Loss:3.400 | Acc:0.5520 | F1:0.1017\n",
      "2022-05-04 15:55:22,871 INFO: val Loss:2.914 | Acc:0.7626 | F1:0.1293\n",
      "2022-05-04 15:55:23,397 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:57:05,918 INFO: Epoch:[008/100]\n",
      "2022-05-04 15:57:05,919 INFO: Train Loss:2.719 | Acc:0.7236 | F1:0.1252\n",
      "2022-05-04 15:57:11,896 INFO: val Loss:2.043 | Acc:0.8339 | F1:0.1446\n",
      "2022-05-04 15:57:12,427 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 15:58:54,772 INFO: Epoch:[009/100]\n",
      "2022-05-04 15:58:54,772 INFO: Train Loss:2.216 | Acc:0.7694 | F1:0.1351\n",
      "2022-05-04 15:59:00,801 INFO: val Loss:1.411 | Acc:0.8398 | F1:0.1514\n",
      "2022-05-04 15:59:01,339 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:00:43,652 INFO: Epoch:[010/100]\n",
      "2022-05-04 16:00:43,652 INFO: Train Loss:1.841 | Acc:0.8095 | F1:0.1456\n",
      "2022-05-04 16:00:49,630 INFO: val Loss:1.163 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-04 16:00:50,167 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:02:32,432 INFO: Epoch:[011/100]\n",
      "2022-05-04 16:02:32,432 INFO: Train Loss:1.644 | Acc:0.8252 | F1:0.1505\n",
      "2022-05-04 16:02:38,405 INFO: val Loss:1.040 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-04 16:02:38,936 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:04:21,295 INFO: Epoch:[012/100]\n",
      "2022-05-04 16:04:21,296 INFO: Train Loss:1.485 | Acc:0.8346 | F1:0.1530\n",
      "2022-05-04 16:04:27,310 INFO: val Loss:0.896 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-04 16:04:27,926 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:06:10,447 INFO: Epoch:[013/100]\n",
      "2022-05-04 16:06:10,448 INFO: Train Loss:1.430 | Acc:0.8364 | F1:0.1530\n",
      "2022-05-04 16:06:16,507 INFO: val Loss:0.768 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-04 16:06:17,044 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:07:59,568 INFO: Epoch:[014/100]\n",
      "2022-05-04 16:07:59,569 INFO: Train Loss:1.308 | Acc:0.8352 | F1:0.1528\n",
      "2022-05-04 16:08:05,609 INFO: val Loss:0.731 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-04 16:08:06,147 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:09:48,589 INFO: Epoch:[015/100]\n",
      "2022-05-04 16:09:48,589 INFO: Train Loss:1.152 | Acc:0.8413 | F1:0.1546\n",
      "2022-05-04 16:09:54,589 INFO: val Loss:0.667 | Acc:0.8515 | F1:0.1678\n",
      "2022-05-04 16:09:55,136 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:11:37,341 INFO: Epoch:[016/100]\n",
      "2022-05-04 16:11:37,342 INFO: Train Loss:1.020 | Acc:0.8454 | F1:0.1686\n",
      "2022-05-04 16:11:43,390 INFO: val Loss:0.627 | Acc:0.8561 | F1:0.1864\n",
      "2022-05-04 16:11:43,921 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:13:26,275 INFO: Epoch:[017/100]\n",
      "2022-05-04 16:13:26,275 INFO: Train Loss:0.947 | Acc:0.8477 | F1:0.1856\n",
      "2022-05-04 16:13:32,297 INFO: val Loss:0.546 | Acc:0.8620 | F1:0.2095\n",
      "2022-05-04 16:13:32,832 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:15:15,359 INFO: Epoch:[018/100]\n",
      "2022-05-04 16:15:15,359 INFO: Train Loss:0.849 | Acc:0.8530 | F1:0.2093\n",
      "2022-05-04 16:15:21,334 INFO: val Loss:0.508 | Acc:0.8737 | F1:0.2676\n",
      "2022-05-04 16:15:21,928 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.10it/s]\n",
      "2022-05-04 16:17:04,019 INFO: Epoch:[019/100]\n",
      "2022-05-04 16:17:04,019 INFO: Train Loss:0.798 | Acc:0.8518 | F1:0.2209\n",
      "2022-05-04 16:17:09,953 INFO: val Loss:0.468 | Acc:0.8725 | F1:0.2548\n",
      "2022-05-04 16:17:10,496 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.10it/s]\n",
      "2022-05-04 16:18:52,618 INFO: Epoch:[020/100]\n",
      "2022-05-04 16:18:52,618 INFO: Train Loss:0.711 | Acc:0.8627 | F1:0.2717\n",
      "2022-05-04 16:18:58,618 INFO: val Loss:0.429 | Acc:0.8784 | F1:0.2802\n",
      "2022-05-04 16:18:59,153 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 16:20:41,838 INFO: Epoch:[021/100]\n",
      "2022-05-04 16:20:41,838 INFO: Train Loss:0.671 | Acc:0.8612 | F1:0.2626\n",
      "2022-05-04 16:20:47,871 INFO: val Loss:0.427 | Acc:0.8889 | F1:0.3372\n",
      "2022-05-04 16:20:48,413 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 16:22:31,250 INFO: Epoch:[022/100]\n",
      "2022-05-04 16:22:31,250 INFO: Train Loss:0.625 | Acc:0.8688 | F1:0.3044\n",
      "2022-05-04 16:22:37,205 INFO: val Loss:0.413 | Acc:0.8819 | F1:0.3277\n",
      "2022-05-04 16:22:37,736 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:24:20,172 INFO: Epoch:[023/100]\n",
      "2022-05-04 16:24:20,172 INFO: Train Loss:0.608 | Acc:0.8688 | F1:0.3181\n",
      "2022-05-04 16:24:26,304 INFO: val Loss:0.377 | Acc:0.8877 | F1:0.3350\n",
      "2022-05-04 16:24:26,894 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:26:09,305 INFO: Epoch:[024/100]\n",
      "2022-05-04 16:26:09,306 INFO: Train Loss:0.579 | Acc:0.8679 | F1:0.3189\n",
      "2022-05-04 16:26:15,275 INFO: val Loss:0.352 | Acc:0.8936 | F1:0.4073\n",
      "2022-05-04 16:26:15,812 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:27:58,315 INFO: Epoch:[025/100]\n",
      "2022-05-04 16:27:58,316 INFO: Train Loss:0.525 | Acc:0.8770 | F1:0.3561\n",
      "2022-05-04 16:28:04,364 INFO: val Loss:0.385 | Acc:0.8982 | F1:0.4137\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.10it/s]\n",
      "2022-05-04 16:29:46,503 INFO: Epoch:[026/100]\n",
      "2022-05-04 16:29:46,503 INFO: Train Loss:0.519 | Acc:0.8787 | F1:0.3845\n",
      "2022-05-04 16:29:52,506 INFO: val Loss:0.331 | Acc:0.8959 | F1:0.3973\n",
      "2022-05-04 16:29:53,049 INFO: -----------------SAVE:26epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:31:35,346 INFO: Epoch:[027/100]\n",
      "2022-05-04 16:31:35,346 INFO: Train Loss:0.492 | Acc:0.8814 | F1:0.3870\n",
      "2022-05-04 16:31:41,340 INFO: val Loss:0.284 | Acc:0.9240 | F1:0.5320\n",
      "2022-05-04 16:31:41,873 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:33:24,221 INFO: Epoch:[028/100]\n",
      "2022-05-04 16:33:24,222 INFO: Train Loss:0.474 | Acc:0.8895 | F1:0.4458\n",
      "2022-05-04 16:33:30,239 INFO: val Loss:0.297 | Acc:0.9181 | F1:0.5048\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:35:12,574 INFO: Epoch:[029/100]\n",
      "2022-05-04 16:35:12,574 INFO: Train Loss:0.435 | Acc:0.8878 | F1:0.4344\n",
      "2022-05-04 16:35:18,619 INFO: val Loss:0.290 | Acc:0.9146 | F1:0.5039\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 16:37:01,472 INFO: Epoch:[030/100]\n",
      "2022-05-04 16:37:01,473 INFO: Train Loss:0.453 | Acc:0.8930 | F1:0.4583\n",
      "2022-05-04 16:37:07,608 INFO: val Loss:0.318 | Acc:0.9158 | F1:0.5039\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.10it/s]\n",
      "2022-05-04 16:38:49,547 INFO: Epoch:[031/100]\n",
      "2022-05-04 16:38:49,548 INFO: Train Loss:0.419 | Acc:0.8942 | F1:0.4730\n",
      "2022-05-04 16:38:55,262 INFO: val Loss:0.299 | Acc:0.9181 | F1:0.5311\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:43<00:00,  2.07it/s]\n",
      "2022-05-04 16:40:38,604 INFO: Epoch:[032/100]\n",
      "2022-05-04 16:40:38,604 INFO: Train Loss:0.401 | Acc:0.9001 | F1:0.5022\n",
      "2022-05-04 16:40:44,478 INFO: val Loss:0.272 | Acc:0.9181 | F1:0.5722\n",
      "2022-05-04 16:40:45,093 INFO: -----------------SAVE:32epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:44<00:00,  2.05it/s]\n",
      "2022-05-04 16:42:29,680 INFO: Epoch:[033/100]\n",
      "2022-05-04 16:42:29,681 INFO: Train Loss:0.377 | Acc:0.9056 | F1:0.5374\n",
      "2022-05-04 16:42:35,627 INFO: val Loss:0.254 | Acc:0.9205 | F1:0.5857\n",
      "2022-05-04 16:42:36,176 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 16:44:17,722 INFO: Epoch:[034/100]\n",
      "2022-05-04 16:44:17,722 INFO: Train Loss:0.374 | Acc:0.9009 | F1:0.5229\n",
      "2022-05-04 16:44:23,457 INFO: val Loss:0.230 | Acc:0.9310 | F1:0.6094\n",
      "2022-05-04 16:44:23,998 INFO: -----------------SAVE:34epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 16:46:04,028 INFO: Epoch:[035/100]\n",
      "2022-05-04 16:46:04,029 INFO: Train Loss:0.340 | Acc:0.9088 | F1:0.5664\n",
      "2022-05-04 16:46:09,775 INFO: val Loss:0.269 | Acc:0.9228 | F1:0.5481\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 16:47:52,037 INFO: Epoch:[036/100]\n",
      "2022-05-04 16:47:52,037 INFO: Train Loss:0.332 | Acc:0.9088 | F1:0.5583\n",
      "2022-05-04 16:47:57,769 INFO: val Loss:0.239 | Acc:0.9275 | F1:0.5829\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 16:49:38,477 INFO: Epoch:[037/100]\n",
      "2022-05-04 16:49:38,477 INFO: Train Loss:0.323 | Acc:0.9109 | F1:0.5756\n",
      "2022-05-04 16:49:44,200 INFO: val Loss:0.227 | Acc:0.9333 | F1:0.6148\n",
      "2022-05-04 16:49:44,749 INFO: -----------------SAVE:37epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 16:51:25,531 INFO: Epoch:[038/100]\n",
      "2022-05-04 16:51:25,531 INFO: Train Loss:0.311 | Acc:0.9161 | F1:0.5726\n",
      "2022-05-04 16:51:31,500 INFO: val Loss:0.233 | Acc:0.9322 | F1:0.6122\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 16:53:12,406 INFO: Epoch:[039/100]\n",
      "2022-05-04 16:53:12,407 INFO: Train Loss:0.300 | Acc:0.9234 | F1:0.6287\n",
      "2022-05-04 16:53:18,265 INFO: val Loss:0.206 | Acc:0.9392 | F1:0.6724\n",
      "2022-05-04 16:53:18,816 INFO: -----------------SAVE:39epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 16:55:00,048 INFO: Epoch:[040/100]\n",
      "2022-05-04 16:55:00,048 INFO: Train Loss:0.295 | Acc:0.9252 | F1:0.6480\n",
      "2022-05-04 16:55:05,941 INFO: val Loss:0.204 | Acc:0.9322 | F1:0.6040\n",
      "2022-05-04 16:55:06,545 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.10it/s]\n",
      "2022-05-04 16:56:48,688 INFO: Epoch:[041/100]\n",
      "2022-05-04 16:56:48,688 INFO: Train Loss:0.280 | Acc:0.9249 | F1:0.6398\n",
      "2022-05-04 16:56:54,425 INFO: val Loss:0.239 | Acc:0.9310 | F1:0.5917\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.10it/s]\n",
      "2022-05-04 16:58:36,489 INFO: Epoch:[042/100]\n",
      "2022-05-04 16:58:36,489 INFO: Train Loss:0.264 | Acc:0.9267 | F1:0.6522\n",
      "2022-05-04 16:58:42,392 INFO: val Loss:0.254 | Acc:0.9263 | F1:0.6492\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:43<00:00,  2.07it/s]\n",
      "2022-05-04 17:00:25,946 INFO: Epoch:[043/100]\n",
      "2022-05-04 17:00:25,946 INFO: Train Loss:0.263 | Acc:0.9272 | F1:0.6563\n",
      "2022-05-04 17:00:31,773 INFO: val Loss:0.231 | Acc:0.9368 | F1:0.6333\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 17:02:12,684 INFO: Epoch:[044/100]\n",
      "2022-05-04 17:02:12,684 INFO: Train Loss:0.247 | Acc:0.9331 | F1:0.6734\n",
      "2022-05-04 17:02:18,542 INFO: val Loss:0.209 | Acc:0.9333 | F1:0.6022\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 17:03:59,207 INFO: Epoch:[045/100]\n",
      "2022-05-04 17:03:59,207 INFO: Train Loss:0.249 | Acc:0.9325 | F1:0.6825\n",
      "2022-05-04 17:04:04,924 INFO: val Loss:0.195 | Acc:0.9450 | F1:0.6923\n",
      "2022-05-04 17:04:05,455 INFO: -----------------SAVE:45epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.14it/s]\n",
      "2022-05-04 17:05:45,420 INFO: Epoch:[046/100]\n",
      "2022-05-04 17:05:45,421 INFO: Train Loss:0.228 | Acc:0.9386 | F1:0.7229\n",
      "2022-05-04 17:05:51,250 INFO: val Loss:0.224 | Acc:0.9345 | F1:0.6324\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 17:07:31,431 INFO: Epoch:[047/100]\n",
      "2022-05-04 17:07:31,431 INFO: Train Loss:0.242 | Acc:0.9307 | F1:0.6756\n",
      "2022-05-04 17:07:37,116 INFO: val Loss:0.206 | Acc:0.9380 | F1:0.6826\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 17:09:17,982 INFO: Epoch:[048/100]\n",
      "2022-05-04 17:09:17,983 INFO: Train Loss:0.222 | Acc:0.9389 | F1:0.7086\n",
      "2022-05-04 17:09:23,852 INFO: val Loss:0.161 | Acc:0.9579 | F1:0.7639\n",
      "2022-05-04 17:09:24,423 INFO: -----------------SAVE:48epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.08it/s]\n",
      "2022-05-04 17:11:07,071 INFO: Epoch:[049/100]\n",
      "2022-05-04 17:11:07,072 INFO: Train Loss:0.213 | Acc:0.9430 | F1:0.7446\n",
      "2022-05-04 17:11:12,842 INFO: val Loss:0.205 | Acc:0.9474 | F1:0.7195\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 17:12:54,185 INFO: Epoch:[050/100]\n",
      "2022-05-04 17:12:54,185 INFO: Train Loss:0.209 | Acc:0.9427 | F1:0.7260\n",
      "2022-05-04 17:12:59,927 INFO: val Loss:0.199 | Acc:0.9439 | F1:0.6860\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 17:14:40,684 INFO: Epoch:[051/100]\n",
      "2022-05-04 17:14:40,684 INFO: Train Loss:0.195 | Acc:0.9456 | F1:0.7527\n",
      "2022-05-04 17:14:46,404 INFO: val Loss:0.179 | Acc:0.9520 | F1:0.7227\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 17:16:26,625 INFO: Epoch:[052/100]\n",
      "2022-05-04 17:16:26,625 INFO: Train Loss:0.190 | Acc:0.9477 | F1:0.7484\n",
      "2022-05-04 17:16:32,267 INFO: val Loss:0.177 | Acc:0.9509 | F1:0.7765\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 17:18:12,386 INFO: Epoch:[053/100]\n",
      "2022-05-04 17:18:12,387 INFO: Train Loss:0.188 | Acc:0.9456 | F1:0.7631\n",
      "2022-05-04 17:18:18,247 INFO: val Loss:0.184 | Acc:0.9520 | F1:0.7512\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 17:19:58,867 INFO: Epoch:[054/100]\n",
      "2022-05-04 17:19:58,867 INFO: Train Loss:0.176 | Acc:0.9492 | F1:0.7620\n",
      "2022-05-04 17:20:04,682 INFO: val Loss:0.129 | Acc:0.9626 | F1:0.8201\n",
      "2022-05-04 17:20:05,276 INFO: -----------------SAVE:54epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.12it/s]\n",
      "2022-05-04 17:21:46,451 INFO: Epoch:[055/100]\n",
      "2022-05-04 17:21:46,451 INFO: Train Loss:0.169 | Acc:0.9474 | F1:0.7555\n",
      "2022-05-04 17:21:52,357 INFO: val Loss:0.177 | Acc:0.9404 | F1:0.6870\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 17:23:32,001 INFO: Epoch:[056/100]\n",
      "2022-05-04 17:23:32,001 INFO: Train Loss:0.170 | Acc:0.9494 | F1:0.7708\n",
      "2022-05-04 17:23:38,016 INFO: val Loss:0.193 | Acc:0.9462 | F1:0.6961\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 17:25:19,667 INFO: Epoch:[057/100]\n",
      "2022-05-04 17:25:19,668 INFO: Train Loss:0.171 | Acc:0.9524 | F1:0.7825\n",
      "2022-05-04 17:25:25,545 INFO: val Loss:0.148 | Acc:0.9602 | F1:0.8150\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.10it/s]\n",
      "2022-05-04 17:27:07,314 INFO: Epoch:[058/100]\n",
      "2022-05-04 17:27:07,314 INFO: Train Loss:0.155 | Acc:0.9568 | F1:0.8031\n",
      "2022-05-04 17:27:13,071 INFO: val Loss:0.150 | Acc:0.9591 | F1:0.7708\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:42<00:00,  2.09it/s]\n",
      "2022-05-04 17:28:55,392 INFO: Epoch:[059/100]\n",
      "2022-05-04 17:28:55,392 INFO: Train Loss:0.155 | Acc:0.9544 | F1:0.7946\n",
      "2022-05-04 17:29:01,171 INFO: val Loss:0.141 | Acc:0.9556 | F1:0.7555\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 17:30:42,565 INFO: Epoch:[060/100]\n",
      "2022-05-04 17:30:42,566 INFO: Train Loss:0.157 | Acc:0.9547 | F1:0.7829\n",
      "2022-05-04 17:30:48,307 INFO: val Loss:0.147 | Acc:0.9556 | F1:0.7706\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.11it/s]\n",
      "2022-05-04 17:32:29,587 INFO: Epoch:[061/100]\n",
      "2022-05-04 17:32:29,587 INFO: Train Loss:0.143 | Acc:0.9597 | F1:0.8137\n",
      "2022-05-04 17:32:35,290 INFO: val Loss:0.155 | Acc:0.9544 | F1:0.7622\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 17:34:15,573 INFO: Epoch:[062/100]\n",
      "2022-05-04 17:34:15,574 INFO: Train Loss:0.145 | Acc:0.9600 | F1:0.8255\n",
      "2022-05-04 17:34:21,383 INFO: val Loss:0.190 | Acc:0.9509 | F1:0.7417\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 17:36:01,590 INFO: Epoch:[063/100]\n",
      "2022-05-04 17:36:01,591 INFO: Train Loss:0.144 | Acc:0.9611 | F1:0.8280\n",
      "2022-05-04 17:36:07,322 INFO: val Loss:0.160 | Acc:0.9485 | F1:0.7130\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 17:37:47,332 INFO: Epoch:[064/100]\n",
      "2022-05-04 17:37:47,332 INFO: Train Loss:0.137 | Acc:0.9579 | F1:0.8166\n",
      "2022-05-04 17:37:53,246 INFO: val Loss:0.137 | Acc:0.9602 | F1:0.7912\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.14it/s]\n",
      "2022-05-04 17:39:33,170 INFO: Epoch:[065/100]\n",
      "2022-05-04 17:39:33,171 INFO: Train Loss:0.128 | Acc:0.9635 | F1:0.8395\n",
      "2022-05-04 17:39:38,904 INFO: val Loss:0.161 | Acc:0.9579 | F1:0.7906\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.14it/s]\n",
      "2022-05-04 17:41:19,087 INFO: Epoch:[066/100]\n",
      "2022-05-04 17:41:19,088 INFO: Train Loss:0.127 | Acc:0.9649 | F1:0.8596\n",
      "2022-05-04 17:41:24,989 INFO: val Loss:0.161 | Acc:0.9544 | F1:0.7886\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.12it/s]\n",
      "2022-05-04 17:43:06,144 INFO: Epoch:[067/100]\n",
      "2022-05-04 17:43:06,144 INFO: Train Loss:0.116 | Acc:0.9679 | F1:0.8612\n",
      "2022-05-04 17:43:11,852 INFO: val Loss:0.147 | Acc:0.9626 | F1:0.8049\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 17:44:52,313 INFO: Epoch:[068/100]\n",
      "2022-05-04 17:44:52,313 INFO: Train Loss:0.114 | Acc:0.9699 | F1:0.8703\n",
      "2022-05-04 17:44:58,017 INFO: val Loss:0.130 | Acc:0.9637 | F1:0.8369\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:44<00:00,  2.05it/s]\n",
      "2022-05-04 17:46:42,518 INFO: Epoch:[069/100]\n",
      "2022-05-04 17:46:42,519 INFO: Train Loss:0.109 | Acc:0.9696 | F1:0.8776\n",
      "2022-05-04 17:46:49,269 INFO: val Loss:0.109 | Acc:0.9673 | F1:0.8404\n",
      "2022-05-04 17:46:49,827 INFO: -----------------SAVE:69epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:51<00:00,  1.92it/s]\n",
      "2022-05-04 17:48:41,227 INFO: Epoch:[070/100]\n",
      "2022-05-04 17:48:41,228 INFO: Train Loss:0.105 | Acc:0.9693 | F1:0.8680\n",
      "2022-05-04 17:48:47,154 INFO: val Loss:0.132 | Acc:0.9626 | F1:0.8090\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 17:50:28,159 INFO: Epoch:[071/100]\n",
      "2022-05-04 17:50:28,159 INFO: Train Loss:0.106 | Acc:0.9699 | F1:0.8744\n",
      "2022-05-04 17:50:34,084 INFO: val Loss:0.122 | Acc:0.9614 | F1:0.7953\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:41<00:00,  2.12it/s]\n",
      "2022-05-04 17:52:15,174 INFO: Epoch:[072/100]\n",
      "2022-05-04 17:52:15,174 INFO: Train Loss:0.098 | Acc:0.9714 | F1:0.8767\n",
      "2022-05-04 17:52:21,004 INFO: val Loss:0.133 | Acc:0.9614 | F1:0.8093\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 17:53:59,941 INFO: Epoch:[073/100]\n",
      "2022-05-04 17:53:59,941 INFO: Train Loss:0.092 | Acc:0.9722 | F1:0.8847\n",
      "2022-05-04 17:54:05,672 INFO: val Loss:0.126 | Acc:0.9626 | F1:0.7986\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 17:55:45,345 INFO: Epoch:[074/100]\n",
      "2022-05-04 17:55:45,345 INFO: Train Loss:0.091 | Acc:0.9737 | F1:0.8951\n",
      "2022-05-04 17:55:50,983 INFO: val Loss:0.118 | Acc:0.9626 | F1:0.8336\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 17:57:30,098 INFO: Epoch:[075/100]\n",
      "2022-05-04 17:57:30,099 INFO: Train Loss:0.087 | Acc:0.9752 | F1:0.8921\n",
      "2022-05-04 17:57:35,852 INFO: val Loss:0.107 | Acc:0.9684 | F1:0.8439\n",
      "2022-05-04 17:57:36,483 INFO: -----------------SAVE:75epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 17:59:15,638 INFO: Epoch:[076/100]\n",
      "2022-05-04 17:59:15,638 INFO: Train Loss:0.078 | Acc:0.9763 | F1:0.9035\n",
      "2022-05-04 17:59:21,355 INFO: val Loss:0.133 | Acc:0.9649 | F1:0.8033\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:01:00,816 INFO: Epoch:[077/100]\n",
      "2022-05-04 18:01:00,816 INFO: Train Loss:0.080 | Acc:0.9766 | F1:0.9005\n",
      "2022-05-04 18:01:06,565 INFO: val Loss:0.096 | Acc:0.9614 | F1:0.7827\n",
      "2022-05-04 18:01:07,190 INFO: -----------------SAVE:77epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:02:46,207 INFO: Epoch:[078/100]\n",
      "2022-05-04 18:02:46,207 INFO: Train Loss:0.073 | Acc:0.9781 | F1:0.9101\n",
      "2022-05-04 18:02:51,964 INFO: val Loss:0.120 | Acc:0.9708 | F1:0.8398\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:04:31,369 INFO: Epoch:[079/100]\n",
      "2022-05-04 18:04:31,369 INFO: Train Loss:0.068 | Acc:0.9825 | F1:0.9276\n",
      "2022-05-04 18:04:37,062 INFO: val Loss:0.120 | Acc:0.9602 | F1:0.8140\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:06:16,391 INFO: Epoch:[080/100]\n",
      "2022-05-04 18:06:16,392 INFO: Train Loss:0.067 | Acc:0.9813 | F1:0.9249\n",
      "2022-05-04 18:06:22,190 INFO: val Loss:0.119 | Acc:0.9626 | F1:0.8396\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:08:01,490 INFO: Epoch:[081/100]\n",
      "2022-05-04 18:08:01,491 INFO: Train Loss:0.064 | Acc:0.9795 | F1:0.9113\n",
      "2022-05-04 18:08:07,214 INFO: val Loss:0.121 | Acc:0.9614 | F1:0.8135\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:09:46,293 INFO: Epoch:[082/100]\n",
      "2022-05-04 18:09:46,293 INFO: Train Loss:0.067 | Acc:0.9793 | F1:0.9138\n",
      "2022-05-04 18:09:51,962 INFO: val Loss:0.134 | Acc:0.9591 | F1:0.8286\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:11:31,457 INFO: Epoch:[083/100]\n",
      "2022-05-04 18:11:31,457 INFO: Train Loss:0.059 | Acc:0.9813 | F1:0.9255\n",
      "2022-05-04 18:11:37,240 INFO: val Loss:0.103 | Acc:0.9731 | F1:0.8539\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:13:16,300 INFO: Epoch:[084/100]\n",
      "2022-05-04 18:13:16,300 INFO: Train Loss:0.063 | Acc:0.9831 | F1:0.9357\n",
      "2022-05-04 18:13:21,965 INFO: val Loss:0.125 | Acc:0.9684 | F1:0.8418\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:38<00:00,  2.16it/s]\n",
      "2022-05-04 18:15:00,959 INFO: Epoch:[085/100]\n",
      "2022-05-04 18:15:00,960 INFO: Train Loss:0.053 | Acc:0.9845 | F1:0.9397\n",
      "2022-05-04 18:15:06,858 INFO: val Loss:0.110 | Acc:0.9673 | F1:0.8191\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:16:46,089 INFO: Epoch:[086/100]\n",
      "2022-05-04 18:16:46,089 INFO: Train Loss:0.051 | Acc:0.9854 | F1:0.9439\n",
      "2022-05-04 18:16:51,817 INFO: val Loss:0.110 | Acc:0.9649 | F1:0.8331\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:18:31,048 INFO: Epoch:[087/100]\n",
      "2022-05-04 18:18:31,049 INFO: Train Loss:0.046 | Acc:0.9874 | F1:0.9485\n",
      "2022-05-04 18:18:36,738 INFO: val Loss:0.093 | Acc:0.9754 | F1:0.8791\n",
      "2022-05-04 18:18:37,320 INFO: -----------------SAVE:87epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.16it/s]\n",
      "2022-05-04 18:20:16,469 INFO: Epoch:[088/100]\n",
      "2022-05-04 18:20:16,469 INFO: Train Loss:0.043 | Acc:0.9898 | F1:0.9569\n",
      "2022-05-04 18:20:22,173 INFO: val Loss:0.116 | Acc:0.9673 | F1:0.8315\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:22:01,512 INFO: Epoch:[089/100]\n",
      "2022-05-04 18:22:01,513 INFO: Train Loss:0.040 | Acc:0.9871 | F1:0.9467\n",
      "2022-05-04 18:22:07,164 INFO: val Loss:0.117 | Acc:0.9708 | F1:0.8683\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:23:46,477 INFO: Epoch:[090/100]\n",
      "2022-05-04 18:23:46,477 INFO: Train Loss:0.039 | Acc:0.9889 | F1:0.9587\n",
      "2022-05-04 18:23:52,304 INFO: val Loss:0.106 | Acc:0.9661 | F1:0.8416\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.14it/s]\n",
      "2022-05-04 18:25:32,290 INFO: Epoch:[091/100]\n",
      "2022-05-04 18:25:32,291 INFO: Train Loss:0.052 | Acc:0.9848 | F1:0.9377\n",
      "2022-05-04 18:25:38,276 INFO: val Loss:0.101 | Acc:0.9708 | F1:0.8430\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:39<00:00,  2.15it/s]\n",
      "2022-05-04 18:27:17,966 INFO: Epoch:[092/100]\n",
      "2022-05-04 18:27:17,966 INFO: Train Loss:0.036 | Acc:0.9912 | F1:0.9646\n",
      "2022-05-04 18:27:23,741 INFO: val Loss:0.102 | Acc:0.9696 | F1:0.8487\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.13it/s]\n",
      "2022-05-04 18:29:04,139 INFO: Epoch:[093/100]\n",
      "2022-05-04 18:29:04,139 INFO: Train Loss:0.039 | Acc:0.9889 | F1:0.9546\n",
      "2022-05-04 18:29:09,857 INFO: val Loss:0.099 | Acc:0.9719 | F1:0.8674\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:40<00:00,  2.12it/s]\n",
      "2022-05-04 18:30:50,822 INFO: Epoch:[094/100]\n",
      "2022-05-04 18:30:50,823 INFO: Train Loss:0.036 | Acc:0.9915 | F1:0.9674\n",
      "2022-05-04 18:30:56,749 INFO: val Loss:0.101 | Acc:0.9719 | F1:0.8632\n",
      " 53%|██████████████████████████████████████████▏                                     | 113/214 [00:53<00:47,  2.13it/s]"
     ]
    }
   ],
   "source": [
    "# df_test['file_name'] = df_test['file_name'].apply(lambda x:x.replace('test_imgs', 'test_1024'))\n",
    "test_transform = get_train_augmentation(img_size=img_size, ver=1)\n",
    "test_dataset = Test_dataset(df_test, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "start = 0 # first time : Only Trainset\n",
    "steps = 6 # Number of pseudo labeling times \n",
    "for step in range(start, steps+1): \n",
    "    models_path = []\n",
    "    args.step = step\n",
    "    for s_fold in range(5): # 5fold\n",
    "        args.fold = s_fold\n",
    "        args.exp_num = str(s_fold)\n",
    "        save_path = main(args)\n",
    "        models_path.append(save_path)\n",
    "    ensemble = ensemble_5fold(models_path, test_loader, device)\n",
    "    make_pseudo_df(df_train, df_test, ensemble, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For submission\n",
    "sub.iloc[:, 1] = ensemble.argmax(axis=1)\n",
    "labels = ['bottle-broken_large', 'bottle-broken_small', 'bottle-contamination', 'bottle-good', 'cable-bent_wire', 'cable-cable_swap', 'cable-combined', 'cable-cut_inner_insulation', 'cable-cut_outer_insulation', 'cable-good', 'cable-missing_cable', 'cable-missing_wire', 'cable-poke_insulation', 'capsule-crack', 'capsule-faulty_imprint', 'capsule-good', 'capsule-poke', 'capsule-scratch', 'capsule-squeeze', 'carpet-color', 'carpet-cut', 'carpet-good', 'carpet-hole', 'carpet-metal_contamination', 'carpet-thread', 'grid-bent', 'grid-broken', 'grid-glue', 'grid-good', 'grid-metal_contamination', 'grid-thread', 'hazelnut-crack', 'hazelnut-cut', 'hazelnut-good', 'hazelnut-hole', 'hazelnut-print', 'leather-color', 'leather-cut', 'leather-fold', 'leather-glue', 'leather-good', 'leather-poke', 'metal_nut-bent', 'metal_nut-color', 'metal_nut-flip', 'metal_nut-good', 'metal_nut-scratch', 'pill-color', 'pill-combined', 'pill-contamination', 'pill-crack', 'pill-faulty_imprint', 'pill-good', 'pill-pill_type', 'pill-scratch', 'screw-good', 'screw-manipulated_front', 'screw-scratch_head', 'screw-scratch_neck', 'screw-thread_side', 'screw-thread_top', 'tile-crack', 'tile-glue_strip', 'tile-good', 'tile-gray_stroke', 'tile-oil', 'tile-rough', 'toothbrush-defective', 'toothbrush-good', 'transistor-bent_lead', 'transistor-cut_lead', 'transistor-damaged_case', 'transistor-good', 'transistor-misplaced', 'wood-color', 'wood-combined', 'wood-good', 'wood-hole', 'wood-liquid', 'wood-scratch', 'zipper-broken_teeth', 'zipper-combined', 'zipper-fabric_border', 'zipper-fabric_interior', 'zipper-good', 'zipper-rough', 'zipper-split_teeth', 'zipper-squeezed_teeth']\n",
    "original_labels = dict(zip(range(len(labels)),labels))\n",
    "sub['label'] = sub['label'].replace(original_labels)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ea827",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./data/0504_1_submission_ep100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상 샘플 개수\n",
    "good_cnt = 0\n",
    "for i in range(len(sub)):\n",
    "    if sub['label'][i][-4:] == 'good':\n",
    "        good_cnt += 1\n",
    "print(good_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28937c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_torch] *",
   "language": "python",
   "name": "conda-env-machine_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
