{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2040d05f",
   "metadata": {},
   "source": [
    "## pseudo labeling 제외"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b7d260",
   "metadata": {},
   "source": [
    "- RegNet040 5Fold ensemble\n",
    "- Pseudo labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4479e2",
   "metadata": {},
   "source": [
    "- Ubuntu 18.04, Cuda 11\n",
    "- opencv-python\n",
    "- numpy\n",
    "- pandas\n",
    "- timm\n",
    "- torch==1.8.0 torchvision 0.9.0 with cuda 11.1\n",
    "- natsort\n",
    "- scikit-learn\n",
    "- pillow\n",
    "- torch_optimizer\n",
    "- tqdm\n",
    "- ptflops\n",
    "- easydict\n",
    "- matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c38e7b2",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c90d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import logging  # 로그 출력\n",
    "import easydict  # 속성으로 dict 값에 access할 수 있음\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # process bar\n",
    "from os.path import join as opj\n",
    "from ptflops import get_model_complexity_info\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "# from PIL import Image\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_optimizer as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, grad_scaler\n",
    "from torchvision import transforms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c90e8a",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff47ae",
   "metadata": {},
   "source": [
    "Hyper-parameter 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30d4e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict(\n",
    "    {'exp_num':'0',\n",
    "     \n",
    "     # Path settings\n",
    "     'data_path':'./data',\n",
    "     'Kfold':5,\n",
    "     'model_path':'results/',\n",
    "\n",
    "     # Model parameter settings  # 고려사항\n",
    "#      'encoder_name':'regnety_040',  \n",
    "     'encoder_name':'regnety_160',\n",
    "#      'encoder_name':'efficientnet_b3',\n",
    "     'drop_path_rate':0.2,\n",
    "     \n",
    "     # Training parameter settings\n",
    "     ## Base Parameter\n",
    "     'img_size':224,  # 고려사항\n",
    "     'batch_size':16, # 고려사항\n",
    "#      'epochs':100,  # 고려사항\n",
    "     'epochs':150,\n",
    "     'optimizer':'Lamb',\n",
    "     'initial_lr':5e-6,\n",
    "     'weight_decay':1e-3,\n",
    "\n",
    "     ## Augmentation\n",
    "     'aug_ver':2,\n",
    "\n",
    "     ## Scheduler (OnecycleLR)\n",
    "     'scheduler':'cycle',\n",
    "     'warm_epoch':5,\n",
    "     'max_lr':1e-3,\n",
    "\n",
    "     ### Cosine Annealing\n",
    "     'min_lr':5e-6,\n",
    "     'tmax':145,\n",
    "\n",
    "     ## etc.\n",
    "     'patience':20,\n",
    "     'clipping':None,\n",
    "\n",
    "     # Hardware settings\n",
    "     'amp':True,\n",
    "     'multi_gpu':False,\n",
    "     'logging':False,\n",
    "     'num_workers':0,  # RuntimeError: DataLoader worker 오류 발생으로 0으로 설정\n",
    "#      'num_workers':4,  # 고려사항\n",
    "     'seed':42\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf0e95",
   "metadata": {},
   "source": [
    "# Utils for training and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74a4b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup Learning rate scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimizer(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "        \n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]\n",
    "\n",
    "# Logging\n",
    "def get_root_logger(logger_name='basicsr',\n",
    "                    log_level=logging.INFO,\n",
    "                    log_file=None):\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    # if the logger has been initialized, just return it\n",
    "    if logger.hasHandlers():\n",
    "        return logger\n",
    "\n",
    "    format_str = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(format=format_str, level=log_level)\n",
    "\n",
    "    if log_file is not None:\n",
    "        file_handler = logging.FileHandler(log_file, 'w')\n",
    "        file_handler.setFormatter(logging.Formatter(format_str))\n",
    "        file_handler.setLevel(log_level)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "class AvgMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.losses = []\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        self.losses.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c91ef",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "- 원본 이미지 사이즈가 큰 점을 감안해 (256,256)로 resize하여 데이터를 새롭게 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58036821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/train_df.csv')\n",
    "\n",
    "# # Resize Train Images\n",
    "# save_path = './data/train_256'  # 새로 저장할 폴더 경로\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "# for img in tqdm(df['file_name']):  # train_df의 'file_name' 컬럼을 참고하여\n",
    "#     name = os.path.basename(img)\n",
    "#     img = cv2.imread(opj('./data/train/', img))  # 해당 경로에 있는 png 이미지 읽어서\n",
    "#     img = cv2.resize(img, dsize=(256, 256))  # resize한 후\n",
    "# #   img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA) # 고려사항\n",
    "#     img = cv2.imwrite(opj(save_path, name), img)  # 새 폴더에 저장\n",
    "\n",
    "# # Resize Test Images\n",
    "# df = pd.read_csv('./data/test_df.csv')\n",
    "# save_path = './data/test_256'\n",
    "# os.makedirs(save_path, exist_ok=True)\n",
    "# for img in tqdm(df['file_name']):\n",
    "#     name = os.path.basename(img)\n",
    "#     img = cv2.imread(opj('./data/test/', img))\n",
    "#     img = cv2.resize(img, dsize=(256, 256))\n",
    "# #   img = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA) # 고려사항\n",
    "#     img = cv2.imwrite(opj(save_path, name), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eb9c5b",
   "metadata": {},
   "source": [
    "# Dataset & Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16ad6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_name = df['file_name'].values\n",
    "        # 각 label을 str->index로 변환\n",
    "        labels = ['bottle-broken_large', 'bottle-broken_small', 'bottle-contamination', 'bottle-good', 'cable-bent_wire', 'cable-cable_swap', 'cable-combined', 'cable-cut_inner_insulation', 'cable-cut_outer_insulation', 'cable-good', 'cable-missing_cable', 'cable-missing_wire', 'cable-poke_insulation', 'capsule-crack', 'capsule-faulty_imprint', 'capsule-good', 'capsule-poke', 'capsule-scratch', 'capsule-squeeze', 'carpet-color', 'carpet-cut', 'carpet-good', 'carpet-hole', 'carpet-metal_contamination', 'carpet-thread', 'grid-bent', 'grid-broken', 'grid-glue', 'grid-good', 'grid-metal_contamination', 'grid-thread', 'hazelnut-crack', 'hazelnut-cut', 'hazelnut-good', 'hazelnut-hole', 'hazelnut-print', 'leather-color', 'leather-cut', 'leather-fold', 'leather-glue', 'leather-good', 'leather-poke', 'metal_nut-bent', 'metal_nut-color', 'metal_nut-flip', 'metal_nut-good', 'metal_nut-scratch', 'pill-color', 'pill-combined', 'pill-contamination', 'pill-crack', 'pill-faulty_imprint', 'pill-good', 'pill-pill_type', 'pill-scratch', 'screw-good', 'screw-manipulated_front', 'screw-scratch_head', 'screw-scratch_neck', 'screw-thread_side', 'screw-thread_top', 'tile-crack', 'tile-glue_strip', 'tile-good', 'tile-gray_stroke', 'tile-oil', 'tile-rough', 'toothbrush-defective', 'toothbrush-good', 'transistor-bent_lead', 'transistor-cut_lead', 'transistor-damaged_case', 'transistor-good', 'transistor-misplaced', 'wood-color', 'wood-combined', 'wood-good', 'wood-hole', 'wood-liquid', 'wood-scratch', 'zipper-broken_teeth', 'zipper-combined', 'zipper-fabric_border', 'zipper-fabric_interior', 'zipper-good', 'zipper-rough', 'zipper-split_teeth', 'zipper-squeezed_teeth']\n",
    "        new = dict(zip(range(len(labels)),labels))\n",
    "        label_decoder = {val:key for key, val in new.items()}\n",
    "        df['label'] = df['label'].replace(label_decoder)\n",
    "\n",
    "        self.target = df['label'].values  # 목표는 label\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Dataset size:{len(self.file_name)}')\n",
    "\n",
    "    def __getitem__(self, idx):  # train 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "        image = cv2.imread(opj('./data/train_256/', self.file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "        \n",
    "        # PIL 사용 # 고려사항\n",
    "#         image = Image.open(opj('./data/train_256/', self.file_name[idx])).convert('RGB')\n",
    "#         image = self.transform(image)\n",
    "        \n",
    "        target = self.target[idx]\n",
    "#         print(f'target:{target}')\n",
    "\n",
    "        if self.transform is not None:\n",
    "        # HWC => CHW-layout 변환\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_name)\n",
    "\n",
    "class Test_dataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.test_file_name = df['file_name'].values\n",
    "        self.transform = transform\n",
    "\n",
    "        print(f'Test Dataset size:{len(self.test_file_name)}')\n",
    "\n",
    "    def __getitem__(self, idx): # test 경로에 있는 png 이미지 읽어서 float32로 변환\n",
    "        image = cv2.imread(opj('./data/test_256/', self.test_file_name[idx])).astype(np.float32)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # BGR=>RGB 변환\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(torch.from_numpy(image.transpose(2,0,1)))\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_file_name)\n",
    "\n",
    "def get_loader(df, phase: str, batch_size, shuffle,\n",
    "               num_workers, transform):\n",
    "    if phase == 'test':\n",
    "        dataset = Test_dataset(df, transform)  \n",
    "        # num_workers : 데이터 로딩에 사용하는 subprocess 개수\n",
    "        # pin_memory : True - 데이터로더가 Tensor를 CUDA 고정 메모리에 올림\n",
    "        # drop_last : batch의 크기에 따른 의존도 높은 함수를 사용할 때 우려되는 경우 마지막 batch를 사용하지 않을 수 있음\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
    "    else:\n",
    "        dataset = Train_Dataset(df, transform)\n",
    "        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True,\n",
    "                                 drop_last=False)\n",
    "    return data_loader\n",
    "\n",
    "def get_train_augmentation(img_size, ver):\n",
    "    if ver == 1: # for validset\n",
    "        transform = transforms.Compose([\n",
    "#                 transforms.ToTensor(),  # 고려사항\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "                ])\n",
    "\n",
    "    if ver == 2:\n",
    "        transform = transforms.Compose([\n",
    "#                 transforms.ToTensor(),  # 고려사항\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomVerticalFlip(),  # 추가\n",
    "                transforms.RandomAffine((20)),  # x, y축으로 이미지 늘림\n",
    "                transforms.RandomRotation(90),\n",
    "                transforms.Resize((img_size, img_size)),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225]),\n",
    "            ])\n",
    "    \n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a3605",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c73038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        # 사전 학습된 모델 사용하기\n",
    "        self.encoder = timm.create_model(args.encoder_name, pretrained=True,\n",
    "                                    drop_path_rate=args.drop_path_rate,\n",
    "                                    )\n",
    "#         num_head = self.encoder.head.fc.in_features  # Number of parallel attention heads\n",
    "#         self.encoder.head.fc = nn.Linear(num_head, 88)\n",
    "        \n",
    "        if 'regnet' in args.encoder_name:        \n",
    "            num_head = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Linear(num_head, 88)\n",
    "        \n",
    "        elif 'efficient' in args.encoder_name:\n",
    "            num_head = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Linear(num_head, 88)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class Network_test(nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(encoder_name, pretrained=True,\n",
    "                                    drop_path_rate=0,\n",
    "                                    )\n",
    "#         num_head = self.encoder.head.fc.in_features\n",
    "#         self.encoder.head.fc = nn.Linear(num_head, 88)\n",
    "        \n",
    "        if 'regnet' in encoder_name:        \n",
    "            num_head = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Linear(num_head, 88)\n",
    "        \n",
    "        elif 'efficient' in encoder_name:\n",
    "            num_head = self.encoder.classifier.in_features\n",
    "            self.encoder.classifier = nn.Linear(num_head, 88)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574592ec",
   "metadata": {},
   "source": [
    "# Trainer for Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3456802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, args, save_path):\n",
    "        '''\n",
    "        args: arguments\n",
    "        save_path: Model 가중치 저장 경로\n",
    "        '''\n",
    "        super(Trainer, self).__init__()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Logging\n",
    "        log_file = os.path.join(save_path, 'aws_log_0507_2_esb.log')\n",
    "        self.logger = get_root_logger(logger_name='IR', log_level=logging.INFO, log_file=log_file)\n",
    "        self.logger.info(args)\n",
    "        # self.logger.info(args.tag)\n",
    "\n",
    "        # Train, Valid Set load\n",
    "        ############################################################################\n",
    "        df_train = pd.read_csv(opj(args.data_path, 'train_df.csv'))\n",
    "        print('Read train_df.csv')\n",
    "            \n",
    "#         if args.step == 0 :\n",
    "#             df_train = pd.read_csv(opj(args.data_path, 'train_df.csv'))\n",
    "#             print('Read train_df.csv')\n",
    "#         else :\n",
    "#             df_train = pd.read_csv(opj(args.data_path, f'aws_0505_esb_train_{args.step}step.csv'))\n",
    "#             print(f'Read {args.step}step.csv')\n",
    "\n",
    "#         if args.image_type is not None:\n",
    "#             df_train['file_name'] = df_train['file_name'].apply(lambda x:x.replace('train_imgs', args.image_type))\n",
    "#             df_train['file_name'] = df_train['file_name'].apply(lambda x:x.replace('test_imgs', 'test_512'))\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=args.Kfold, shuffle=True, random_state=args.seed)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(df_train)), y=df_train['label'])):\n",
    "            df_train.loc[val_idx, 'fold'] = fold\n",
    "        val_idx = list(df_train[df_train['fold'] == int(args.fold)].index)\n",
    "\n",
    "        df_val = df_train[df_train['fold'] == args.fold].reset_index(drop=True)\n",
    "        df_train = df_train[df_train['fold'] != args.fold].reset_index(drop=True)\n",
    "\n",
    "        # Augmentation\n",
    "        self.train_transform = get_train_augmentation(img_size=args.img_size, ver=args.aug_ver)\n",
    "        self.test_transform = get_train_augmentation(img_size=args.img_size, ver=1)\n",
    "\n",
    "        # TrainLoader\n",
    "        self.train_loader = get_loader(df_train, phase='train', batch_size=args.batch_size, shuffle=True,\n",
    "                                       num_workers=args.num_workers, transform=self.train_transform)\n",
    "        self.val_loader = get_loader(df_val, phase='train', batch_size=args.batch_size, shuffle=False,\n",
    "                                       num_workers=args.num_workers, transform=self.test_transform)\n",
    "\n",
    "        # Network\n",
    "        self.model = Network(args).to(self.device)\n",
    "        macs, params = get_model_complexity_info(self.model, (3, args.img_size, args.img_size), as_strings=True,\n",
    "                                                 print_per_layer_stat=False, verbose=False)\n",
    "        self.logger.info('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "        self.logger.info('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer & Scheduler\n",
    "        self.optimizer = optim.Lamb(self.model.parameters(), lr=args.initial_lr, weight_decay=args.weight_decay)\n",
    "        \n",
    "        iter_per_epoch = len(self.train_loader)\n",
    "        self.warmup_scheduler = WarmUpLR(self.optimizer, iter_per_epoch * args.warm_epoch)\n",
    "\n",
    "        if args.scheduler == 'step':\n",
    "            self.scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=args.milestone, gamma=args.lr_factor, verbose=True)\n",
    "        elif args.scheduler == 'cos':\n",
    "            tmax = args.tmax # half-cycle \n",
    "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max = tmax, eta_min=args.min_lr, verbose=True)\n",
    "        elif args.scheduler == 'cycle':\n",
    "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=args.max_lr, steps_per_epoch=iter_per_epoch, epochs=args.epochs)\n",
    "\n",
    "        if args.multi_gpu:\n",
    "            self.model = nn.DataParallel(self.model).to(self.device)\n",
    "\n",
    "        # Train / Validate\n",
    "        best_loss = np.inf\n",
    "        best_acc = 0\n",
    "        best_epoch = 0\n",
    "        early_stopping = 0\n",
    "        start = time.time()\n",
    "        for epoch in range(1, args.epochs+1):\n",
    "            self.epoch = epoch\n",
    "\n",
    "            if args.scheduler == 'cos':\n",
    "                if epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Training\n",
    "            train_loss, train_acc, train_f1 = self.training(args)\n",
    "\n",
    "            # Model weight in Multi_GPU or Single GPU\n",
    "            state_dict= self.model.module.state_dict() if args.multi_gpu else self.model.state_dict()\n",
    "\n",
    "            # Validation\n",
    "            val_loss, val_acc, val_f1 = self.validate(args, phase='val')\n",
    "\n",
    "            # Save models\n",
    "            if val_loss < best_loss:\n",
    "                early_stopping = 0\n",
    "                best_epoch = epoch\n",
    "                best_loss = val_loss\n",
    "                best_acc = val_acc\n",
    "                best_f1 = val_f1\n",
    "\n",
    "                torch.save({'epoch':epoch,\n",
    "                            'state_dict':state_dict,\n",
    "                            'optimizer': self.optimizer.state_dict(),\n",
    "                            'scheduler': self.scheduler.state_dict(),\n",
    "                    }, os.path.join(save_path, 'aws_best_model_0507_2_esb.pth'))\n",
    "                self.logger.info(f'-----------------SAVE:{best_epoch}epoch----------------')\n",
    "            else:\n",
    "                early_stopping += 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if early_stopping == args.patience:\n",
    "                break\n",
    "\n",
    "        self.logger.info(f'\\nBest Val Epoch:{best_epoch} | Val Loss:{best_loss:.4f} | Val Acc:{best_acc:.4f} | Val F1:{best_f1:.4f}')\n",
    "        end = time.time()\n",
    "        self.logger.info(f'Total Process time:{(end - start) / 60:.3f}Minute')\n",
    "\n",
    "    # Training\n",
    "    def training(self, args):\n",
    "        self.model.train()\n",
    "        train_loss = AvgMeter()\n",
    "        train_acc = 0\n",
    "        preds_list = []\n",
    "        targets_list = []\n",
    "\n",
    "        scaler = grad_scaler.GradScaler()\n",
    "        for i, (images, targets) in enumerate(tqdm(self.train_loader)):\n",
    "            images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "            # ValueError: too many dimensions 'str'\n",
    "#             targets = torch.tensor(int(targets), device=self.device, dtype=torch.long)\n",
    "            targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "            \n",
    "            if self.epoch <= args.warm_epoch:\n",
    "                self.warmup_scheduler.step()\n",
    "\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            if args.amp:\n",
    "                with autocast():\n",
    "                    preds = self.model(images)\n",
    "                    loss = self.criterion(preds, targets)\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Gradient Clipping\n",
    "                if args.clipping is not None:\n",
    "                    scaler.unscale_(self.optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "\n",
    "                scaler.step(self.optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            else:\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), args.clipping)\n",
    "                self.optimizer.step()\n",
    "\n",
    "            if args.scheduler == 'cycle':\n",
    "                if self.epoch > args.warm_epoch:\n",
    "                    self.scheduler.step()\n",
    "\n",
    "            # Metric\n",
    "            train_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "            preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "            targets_list.extend(targets.cpu().detach().numpy())\n",
    "            # log\n",
    "            train_loss.update(loss.item(), n=images.size(0))\n",
    "\n",
    "        train_acc /= len(self.train_loader.dataset)\n",
    "        train_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "        self.logger.info(f'Epoch:[{self.epoch:03d}/{args.epochs:03d}]')\n",
    "        self.logger.info(f'Train Loss:{train_loss.avg:.3f} | Acc:{train_acc:.4f} | F1:{train_f1:.4f}')\n",
    "        return train_loss.avg, train_acc, train_f1\n",
    "            \n",
    "    # Validation or Dev\n",
    "    def validate(self, args, phase='val'):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = AvgMeter()\n",
    "            val_acc = 0\n",
    "            preds_list = []\n",
    "            targets_list = []\n",
    "\n",
    "            for i, (images, targets) in enumerate(self.val_loader):\n",
    "                images = torch.tensor(images, device=self.device, dtype=torch.float32)\n",
    "                targets = torch.tensor(targets, device=self.device, dtype=torch.long)\n",
    "\n",
    "                preds = self.model(images)\n",
    "                loss = self.criterion(preds, targets)\n",
    "\n",
    "                # Metric\n",
    "                val_acc += (preds.argmax(dim=1) == targets).sum().item()\n",
    "                preds_list.extend(preds.argmax(dim=1).cpu().detach().numpy())\n",
    "                targets_list.extend(targets.cpu().detach().numpy())\n",
    "\n",
    "                # log\n",
    "                val_loss.update(loss.item(), n=images.size(0))\n",
    "            val_acc /= len(self.val_loader.dataset)\n",
    "            val_f1 = f1_score(np.array(targets_list), np.array(preds_list), average='macro')\n",
    "\n",
    "            self.logger.info(f'{phase} Loss:{val_loss.avg:.3f} | Acc:{val_acc:.4f} | F1:{val_f1:.4f}')\n",
    "        return val_loss.avg, val_acc, val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66f503",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d2a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    print('<---- Training Params ---->')\n",
    "    \n",
    "    # Random Seed\n",
    "    seed = args.seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    save_path = os.path.join(args.model_path, (args.exp_num).zfill(3))\n",
    "    \n",
    "    # Create model directory\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    Trainer(args, save_path)\n",
    "\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5763bf",
   "metadata": {},
   "source": [
    "# Inference & Make pseudo label set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0beb201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder_name, test_loader, device, model_path):\n",
    "    model = Network_test(encoder_name).to(device)\n",
    "    model.load_state_dict(torch.load(opj(model_path, 'aws_best_model_0507_2_esb.pth'))['state_dict'])\n",
    "    model.eval()\n",
    "    preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(test_loader):\n",
    "            images = torch.as_tensor(images, device=device, dtype=torch.float32)\n",
    "            preds = model(images)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            preds_list.extend(preds.cpu().tolist())\n",
    "\n",
    "    return np.array(preds_list)\n",
    "\n",
    "def ensemble_5fold(model_path_list, test_loader, device):\n",
    "    predict_list = []\n",
    "    for model_path in model_path_list:  # 고려사항\n",
    "#         prediction = predict(encoder_name= 'efficientnet_b3', \n",
    "        prediction = predict(encoder_name= 'regnety_160', \n",
    "#         prediction = predict(encoder_name= 'regnety_040', \n",
    "                             test_loader = test_loader, device = device, model_path = model_path)\n",
    "        predict_list.append(prediction)\n",
    "    ensemble = (predict_list[0] + predict_list[1] + predict_list[2] + predict_list[3] + predict_list[4])/len(predict_list)\n",
    "\n",
    "    return ensemble\n",
    "\n",
    "\n",
    "# def make_pseudo_df(train_df, test_df, ensemble, step, threshold = 0.9, z_sample = 500): \n",
    "#     train_df_copy = train_df.copy()\n",
    "#     test_df_copy = test_df.copy()\n",
    "\n",
    "#     test_df_copy['label'] = ensemble.argmax(axis=1)\n",
    "#     pseudo_test_df = test_df_copy.iloc[np.where(ensemble > threshold)[0]].reset_index(drop=True)\n",
    "#     z_idx  = pseudo_test_df[pseudo_test_df['label'] == 0].sample(n=z_sample, random_state=42).index.tolist()\n",
    "#     ot_idx = pseudo_test_df[pseudo_test_df['label'].isin([*range(1,88)])].index.tolist()  # 고려사항\n",
    "#     pseudo_test_df = pseudo_test_df.iloc[z_idx + ot_idx]\n",
    "\n",
    "#     train_df_copy = train_df_copy.append(pseudo_test_df, ignore_index=True).reset_index(drop=True) # reset_index\n",
    "#     train_df_copy.to_csv(f'./data/0505_1_train_{step}step.csv', index=False)\n",
    "#     print(f'Make train_{step}step.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8c70a",
   "metadata": {},
   "source": [
    "# Train & Inference\n",
    "- 5fold Training -> Inference & Ensemble -> Make or Update Pseudo label set -> Add Dataset(Trainset + Pseudo label set)\n",
    "다음과 과정을 반복하기 때문에 Training과 Inference를 동시에 진행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "866d58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_size = 256  # 고려사항\n",
    "img_size = 224\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "sub = pd.read_csv('./data/sample_submission.csv')\n",
    "df_train = pd.read_csv('./data/train_df.csv')\n",
    "df_test = pd.read_csv('./data/test_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94941098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 15:38:01,550 INFO: {'exp_num': '0', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_160', 'drop_path_rate': 0.2, 'img_size': 224, 'batch_size': 16, 'epochs': 150, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 20, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'fold': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset size:2154\n",
      "<---- Training Params ---->\n",
      "Read train_df.csv\n",
      "Dataset size:3421\n",
      "Dataset size:856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 15:38:02,360 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\regnety_160-a5fe301d.pth\n",
      "2022-05-07 15:40:40,487 INFO: Computational complexity:       15.93 GMac\n",
      "2022-05-07 15:40:40,488 INFO: Number of parameters:           80.83 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:05<00:00,  1.71it/s]\n",
      "2022-05-07 15:42:45,834 INFO: Epoch:[001/150]\n",
      "2022-05-07 15:42:45,835 INFO: Train Loss:4.486 | Acc:0.0082 | F1:0.0034\n",
      "2022-05-07 15:42:55,904 INFO: val Loss:4.493 | Acc:0.0023 | F1:0.0003\n",
      "2022-05-07 15:42:57,663 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:55<00:00,  1.85it/s]\n",
      "2022-05-07 15:44:53,405 INFO: Epoch:[002/150]\n",
      "2022-05-07 15:44:53,406 INFO: Train Loss:4.467 | Acc:0.0134 | F1:0.0035\n",
      "2022-05-07 15:45:02,140 INFO: val Loss:4.487 | Acc:0.0012 | F1:0.0002\n",
      "2022-05-07 15:45:04,004 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:55<00:00,  1.85it/s]\n",
      "2022-05-07 15:46:59,649 INFO: Epoch:[003/150]\n",
      "2022-05-07 15:46:59,650 INFO: Train Loss:4.440 | Acc:0.0175 | F1:0.0080\n",
      "2022-05-07 15:47:08,400 INFO: val Loss:4.464 | Acc:0.0012 | F1:0.0005\n",
      "2022-05-07 15:47:10,264 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 15:49:06,274 INFO: Epoch:[004/150]\n",
      "2022-05-07 15:49:06,274 INFO: Train Loss:4.401 | Acc:0.0304 | F1:0.0074\n",
      "2022-05-07 15:49:15,044 INFO: val Loss:4.426 | Acc:0.0035 | F1:0.0011\n",
      "2022-05-07 15:49:16,950 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:58<00:00,  1.80it/s]\n",
      "2022-05-07 15:51:15,781 INFO: Epoch:[005/150]\n",
      "2022-05-07 15:51:15,781 INFO: Train Loss:4.342 | Acc:0.0734 | F1:0.0163\n",
      "2022-05-07 15:51:24,629 INFO: val Loss:4.359 | Acc:0.0327 | F1:0.0065\n",
      "2022-05-07 15:51:26,472 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 15:53:23,678 INFO: Epoch:[006/150]\n",
      "2022-05-07 15:53:23,678 INFO: Train Loss:3.971 | Acc:0.4095 | F1:0.0822\n",
      "2022-05-07 15:53:32,405 INFO: val Loss:3.612 | Acc:0.6916 | F1:0.1256\n",
      "2022-05-07 15:53:34,237 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 15:55:31,642 INFO: Epoch:[007/150]\n",
      "2022-05-07 15:55:31,642 INFO: Train Loss:3.133 | Acc:0.7720 | F1:0.1389\n",
      "2022-05-07 15:55:40,453 INFO: val Loss:2.530 | Acc:0.8446 | F1:0.1551\n",
      "2022-05-07 15:55:42,269 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 15:57:39,579 INFO: Epoch:[008/150]\n",
      "2022-05-07 15:57:39,580 INFO: Train Loss:2.256 | Acc:0.8246 | F1:0.1485\n",
      "2022-05-07 15:57:48,323 INFO: val Loss:1.621 | Acc:0.8435 | F1:0.1535\n",
      "2022-05-07 15:57:50,107 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 15:59:46,618 INFO: Epoch:[009/150]\n",
      "2022-05-07 15:59:46,618 INFO: Train Loss:1.537 | Acc:0.8378 | F1:0.1527\n",
      "2022-05-07 15:59:55,393 INFO: val Loss:1.070 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-07 15:59:57,173 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:01:54,413 INFO: Epoch:[010/150]\n",
      "2022-05-07 16:01:54,414 INFO: Train Loss:1.194 | Acc:0.8457 | F1:0.1553\n",
      "2022-05-07 16:02:03,270 INFO: val Loss:0.961 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-07 16:02:05,134 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:04:02,346 INFO: Epoch:[011/150]\n",
      "2022-05-07 16:04:02,347 INFO: Train Loss:1.038 | Acc:0.8465 | F1:0.1557\n",
      "2022-05-07 16:04:11,139 INFO: val Loss:0.858 | Acc:0.8481 | F1:0.1560\n",
      "2022-05-07 16:04:12,861 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 16:06:08,981 INFO: Epoch:[012/150]\n",
      "2022-05-07 16:06:08,982 INFO: Train Loss:0.926 | Acc:0.8460 | F1:0.1557\n",
      "2022-05-07 16:06:17,709 INFO: val Loss:0.738 | Acc:0.8481 | F1:0.1559\n",
      "2022-05-07 16:06:19,454 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 16:08:16,283 INFO: Epoch:[013/150]\n",
      "2022-05-07 16:08:16,283 INFO: Train Loss:0.806 | Acc:0.8486 | F1:0.1645\n",
      "2022-05-07 16:08:25,017 INFO: val Loss:0.671 | Acc:0.8516 | F1:0.1752\n",
      "2022-05-07 16:08:26,865 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 16:10:24,497 INFO: Epoch:[014/150]\n",
      "2022-05-07 16:10:24,498 INFO: Train Loss:0.719 | Acc:0.8515 | F1:0.1756\n",
      "2022-05-07 16:10:33,286 INFO: val Loss:0.620 | Acc:0.8621 | F1:0.2258\n",
      "2022-05-07 16:10:35,236 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 16:12:32,686 INFO: Epoch:[015/150]\n",
      "2022-05-07 16:12:32,686 INFO: Train Loss:0.654 | Acc:0.8585 | F1:0.2227\n",
      "2022-05-07 16:12:41,444 INFO: val Loss:0.545 | Acc:0.8797 | F1:0.3392\n",
      "2022-05-07 16:12:43,377 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:14:40,519 INFO: Epoch:[016/150]\n",
      "2022-05-07 16:14:40,519 INFO: Train Loss:0.591 | Acc:0.8688 | F1:0.2815\n",
      "2022-05-07 16:14:49,284 INFO: val Loss:0.486 | Acc:0.8808 | F1:0.3311\n",
      "2022-05-07 16:14:51,160 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:16:48,262 INFO: Epoch:[017/150]\n",
      "2022-05-07 16:16:48,262 INFO: Train Loss:0.523 | Acc:0.8784 | F1:0.3255\n",
      "2022-05-07 16:16:57,032 INFO: val Loss:0.453 | Acc:0.8972 | F1:0.4124\n",
      "2022-05-07 16:16:58,895 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:18:55,935 INFO: Epoch:[018/150]\n",
      "2022-05-07 16:18:55,936 INFO: Train Loss:0.481 | Acc:0.8851 | F1:0.3812\n",
      "2022-05-07 16:19:04,765 INFO: val Loss:0.369 | Acc:0.9065 | F1:0.4742\n",
      "2022-05-07 16:19:07,295 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:21:04,508 INFO: Epoch:[019/150]\n",
      "2022-05-07 16:21:04,509 INFO: Train Loss:0.438 | Acc:0.8956 | F1:0.4393\n",
      "2022-05-07 16:21:13,276 INFO: val Loss:0.343 | Acc:0.9054 | F1:0.4595\n",
      "2022-05-07 16:21:15,083 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 16:23:12,858 INFO: Epoch:[020/150]\n",
      "2022-05-07 16:23:12,858 INFO: Train Loss:0.375 | Acc:0.9053 | F1:0.4904\n",
      "2022-05-07 16:23:21,613 INFO: val Loss:0.313 | Acc:0.9089 | F1:0.4910\n",
      "2022-05-07 16:23:23,506 INFO: -----------------SAVE:20epoch----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 16:25:20,488 INFO: Epoch:[021/150]\n",
      "2022-05-07 16:25:20,489 INFO: Train Loss:0.343 | Acc:0.9111 | F1:0.5328\n",
      "2022-05-07 16:25:29,265 INFO: val Loss:0.277 | Acc:0.9206 | F1:0.5491\n",
      "2022-05-07 16:25:31,207 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 16:27:28,552 INFO: Epoch:[022/150]\n",
      "2022-05-07 16:27:28,552 INFO: Train Loss:0.311 | Acc:0.9187 | F1:0.5745\n",
      "2022-05-07 16:27:37,350 INFO: val Loss:0.266 | Acc:0.9229 | F1:0.5684\n",
      "2022-05-07 16:27:39,326 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:29:36,564 INFO: Epoch:[023/150]\n",
      "2022-05-07 16:29:36,564 INFO: Train Loss:0.287 | Acc:0.9246 | F1:0.6172\n",
      "2022-05-07 16:29:45,342 INFO: val Loss:0.290 | Acc:0.9171 | F1:0.5397\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:31:42,572 INFO: Epoch:[024/150]\n",
      "2022-05-07 16:31:42,573 INFO: Train Loss:0.273 | Acc:0.9293 | F1:0.6560\n",
      "2022-05-07 16:31:51,405 INFO: val Loss:0.247 | Acc:0.9217 | F1:0.6068\n",
      "2022-05-07 16:31:53,263 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 16:33:50,053 INFO: Epoch:[025/150]\n",
      "2022-05-07 16:33:50,053 INFO: Train Loss:0.248 | Acc:0.9345 | F1:0.6809\n",
      "2022-05-07 16:33:58,789 INFO: val Loss:0.274 | Acc:0.9299 | F1:0.6230\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:35:55,928 INFO: Epoch:[026/150]\n",
      "2022-05-07 16:35:55,929 INFO: Train Loss:0.244 | Acc:0.9298 | F1:0.6650\n",
      "2022-05-07 16:36:04,723 INFO: val Loss:0.257 | Acc:0.9322 | F1:0.5883\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:38:01,763 INFO: Epoch:[027/150]\n",
      "2022-05-07 16:38:01,764 INFO: Train Loss:0.226 | Acc:0.9392 | F1:0.7187\n",
      "2022-05-07 16:38:10,559 INFO: val Loss:0.219 | Acc:0.9381 | F1:0.6580\n",
      "2022-05-07 16:38:12,460 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:40:09,678 INFO: Epoch:[028/150]\n",
      "2022-05-07 16:40:09,679 INFO: Train Loss:0.219 | Acc:0.9410 | F1:0.7208\n",
      "2022-05-07 16:40:18,434 INFO: val Loss:0.218 | Acc:0.9369 | F1:0.6518\n",
      "2022-05-07 16:40:20,418 INFO: -----------------SAVE:28epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 16:42:17,365 INFO: Epoch:[029/150]\n",
      "2022-05-07 16:42:17,366 INFO: Train Loss:0.212 | Acc:0.9436 | F1:0.7327\n",
      "2022-05-07 16:42:26,119 INFO: val Loss:0.209 | Acc:0.9474 | F1:0.7113\n",
      "2022-05-07 16:42:28,106 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 16:44:25,385 INFO: Epoch:[030/150]\n",
      "2022-05-07 16:44:25,386 INFO: Train Loss:0.205 | Acc:0.9439 | F1:0.7510\n",
      "2022-05-07 16:44:34,120 INFO: val Loss:0.207 | Acc:0.9404 | F1:0.6864\n",
      "2022-05-07 16:44:36,000 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:46:33,138 INFO: Epoch:[031/150]\n",
      "2022-05-07 16:46:33,138 INFO: Train Loss:0.208 | Acc:0.9445 | F1:0.7549\n",
      "2022-05-07 16:46:41,893 INFO: val Loss:0.257 | Acc:0.9334 | F1:0.6606\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 16:48:38,837 INFO: Epoch:[032/150]\n",
      "2022-05-07 16:48:38,838 INFO: Train Loss:0.180 | Acc:0.9512 | F1:0.7843\n",
      "2022-05-07 16:48:47,578 INFO: val Loss:0.206 | Acc:0.9404 | F1:0.6993\n",
      "2022-05-07 16:48:49,791 INFO: -----------------SAVE:32epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:50:46,798 INFO: Epoch:[033/150]\n",
      "2022-05-07 16:50:46,798 INFO: Train Loss:0.192 | Acc:0.9491 | F1:0.7876\n",
      "2022-05-07 16:50:55,559 INFO: val Loss:0.267 | Acc:0.9381 | F1:0.6842\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:52:52,599 INFO: Epoch:[034/150]\n",
      "2022-05-07 16:52:52,600 INFO: Train Loss:0.178 | Acc:0.9515 | F1:0.7816\n",
      "2022-05-07 16:53:01,364 INFO: val Loss:0.210 | Acc:0.9451 | F1:0.7031\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:54:58,424 INFO: Epoch:[035/150]\n",
      "2022-05-07 16:54:58,425 INFO: Train Loss:0.178 | Acc:0.9515 | F1:0.7884\n",
      "2022-05-07 16:55:07,225 INFO: val Loss:0.235 | Acc:0.9439 | F1:0.7027\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:57:04,405 INFO: Epoch:[036/150]\n",
      "2022-05-07 16:57:04,405 INFO: Train Loss:0.163 | Acc:0.9582 | F1:0.8242\n",
      "2022-05-07 16:57:13,132 INFO: val Loss:0.343 | Acc:0.9136 | F1:0.6792\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 16:59:10,175 INFO: Epoch:[037/150]\n",
      "2022-05-07 16:59:10,175 INFO: Train Loss:0.176 | Acc:0.9550 | F1:0.7995\n",
      "2022-05-07 16:59:18,927 INFO: val Loss:0.218 | Acc:0.9404 | F1:0.7131\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:01:16,033 INFO: Epoch:[038/150]\n",
      "2022-05-07 17:01:16,034 INFO: Train Loss:0.161 | Acc:0.9564 | F1:0.8141\n",
      "2022-05-07 17:01:24,801 INFO: val Loss:0.199 | Acc:0.9533 | F1:0.7789\n",
      "2022-05-07 17:01:26,733 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:03:23,773 INFO: Epoch:[039/150]\n",
      "2022-05-07 17:03:23,773 INFO: Train Loss:0.158 | Acc:0.9588 | F1:0.8301\n",
      "2022-05-07 17:03:32,556 INFO: val Loss:0.286 | Acc:0.9357 | F1:0.7074\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:05:29,316 INFO: Epoch:[040/150]\n",
      "2022-05-07 17:05:29,316 INFO: Train Loss:0.151 | Acc:0.9567 | F1:0.8135\n",
      "2022-05-07 17:05:38,073 INFO: val Loss:0.213 | Acc:0.9416 | F1:0.6940\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:07:34,877 INFO: Epoch:[041/150]\n",
      "2022-05-07 17:07:34,878 INFO: Train Loss:0.159 | Acc:0.9556 | F1:0.8134\n",
      "2022-05-07 17:07:43,649 INFO: val Loss:0.215 | Acc:0.9416 | F1:0.7239\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:09:40,401 INFO: Epoch:[042/150]\n",
      "2022-05-07 17:09:40,401 INFO: Train Loss:0.130 | Acc:0.9652 | F1:0.8568\n",
      "2022-05-07 17:09:49,146 INFO: val Loss:0.211 | Acc:0.9509 | F1:0.7436\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:11:46,168 INFO: Epoch:[043/150]\n",
      "2022-05-07 17:11:46,168 INFO: Train Loss:0.164 | Acc:0.9512 | F1:0.7918\n",
      "2022-05-07 17:11:54,917 INFO: val Loss:0.166 | Acc:0.9568 | F1:0.7869\n",
      "2022-05-07 17:11:56,726 INFO: -----------------SAVE:43epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:13:53,407 INFO: Epoch:[044/150]\n",
      "2022-05-07 17:13:53,408 INFO: Train Loss:0.135 | Acc:0.9626 | F1:0.8479\n",
      "2022-05-07 17:14:02,239 INFO: val Loss:0.199 | Acc:0.9533 | F1:0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:15:59,235 INFO: Epoch:[045/150]\n",
      "2022-05-07 17:15:59,235 INFO: Train Loss:0.133 | Acc:0.9667 | F1:0.8691\n",
      "2022-05-07 17:16:08,025 INFO: val Loss:0.208 | Acc:0.9556 | F1:0.7758\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:18:04,897 INFO: Epoch:[046/150]\n",
      "2022-05-07 17:18:04,898 INFO: Train Loss:0.144 | Acc:0.9617 | F1:0.8448\n",
      "2022-05-07 17:18:13,641 INFO: val Loss:0.193 | Acc:0.9498 | F1:0.7652\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:20:10,559 INFO: Epoch:[047/150]\n",
      "2022-05-07 17:20:10,559 INFO: Train Loss:0.134 | Acc:0.9623 | F1:0.8598\n",
      "2022-05-07 17:20:19,302 INFO: val Loss:0.182 | Acc:0.9568 | F1:0.8231\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:22:16,304 INFO: Epoch:[048/150]\n",
      "2022-05-07 17:22:16,305 INFO: Train Loss:0.127 | Acc:0.9649 | F1:0.8580\n",
      "2022-05-07 17:22:25,081 INFO: val Loss:0.233 | Acc:0.9439 | F1:0.7139\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:24:21,755 INFO: Epoch:[049/150]\n",
      "2022-05-07 17:24:21,756 INFO: Train Loss:0.128 | Acc:0.9664 | F1:0.8607\n",
      "2022-05-07 17:24:30,513 INFO: val Loss:0.181 | Acc:0.9603 | F1:0.8110\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:26:27,149 INFO: Epoch:[050/150]\n",
      "2022-05-07 17:26:27,149 INFO: Train Loss:0.133 | Acc:0.9661 | F1:0.8777\n",
      "2022-05-07 17:26:35,918 INFO: val Loss:0.213 | Acc:0.9521 | F1:0.7716\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:28:32,825 INFO: Epoch:[051/150]\n",
      "2022-05-07 17:28:32,825 INFO: Train Loss:0.124 | Acc:0.9655 | F1:0.8773\n",
      "2022-05-07 17:28:41,589 INFO: val Loss:0.204 | Acc:0.9533 | F1:0.7508\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:30:38,563 INFO: Epoch:[052/150]\n",
      "2022-05-07 17:30:38,564 INFO: Train Loss:0.120 | Acc:0.9655 | F1:0.8719\n",
      "2022-05-07 17:30:47,297 INFO: val Loss:0.164 | Acc:0.9638 | F1:0.8184\n",
      "2022-05-07 17:30:49,154 INFO: -----------------SAVE:52epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:32:46,334 INFO: Epoch:[053/150]\n",
      "2022-05-07 17:32:46,334 INFO: Train Loss:0.117 | Acc:0.9687 | F1:0.8795\n",
      "2022-05-07 17:32:55,123 INFO: val Loss:0.166 | Acc:0.9591 | F1:0.7620\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:34:52,256 INFO: Epoch:[054/150]\n",
      "2022-05-07 17:34:52,257 INFO: Train Loss:0.112 | Acc:0.9678 | F1:0.8747\n",
      "2022-05-07 17:35:01,029 INFO: val Loss:0.175 | Acc:0.9650 | F1:0.8168\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 17:36:57,888 INFO: Epoch:[055/150]\n",
      "2022-05-07 17:36:57,889 INFO: Train Loss:0.113 | Acc:0.9684 | F1:0.8759\n",
      "2022-05-07 17:37:06,692 INFO: val Loss:0.180 | Acc:0.9591 | F1:0.8022\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 17:39:03,961 INFO: Epoch:[056/150]\n",
      "2022-05-07 17:39:03,961 INFO: Train Loss:0.107 | Acc:0.9681 | F1:0.8848\n",
      "2022-05-07 17:39:12,686 INFO: val Loss:0.183 | Acc:0.9533 | F1:0.7708\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:41:09,833 INFO: Epoch:[057/150]\n",
      "2022-05-07 17:41:09,834 INFO: Train Loss:0.103 | Acc:0.9699 | F1:0.8855\n",
      "2022-05-07 17:41:18,606 INFO: val Loss:0.206 | Acc:0.9556 | F1:0.7576\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:43:15,756 INFO: Epoch:[058/150]\n",
      "2022-05-07 17:43:15,756 INFO: Train Loss:0.109 | Acc:0.9690 | F1:0.8747\n",
      "2022-05-07 17:43:24,487 INFO: val Loss:0.180 | Acc:0.9509 | F1:0.7178\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:45:21,609 INFO: Epoch:[059/150]\n",
      "2022-05-07 17:45:21,609 INFO: Train Loss:0.100 | Acc:0.9722 | F1:0.8924\n",
      "2022-05-07 17:45:30,342 INFO: val Loss:0.171 | Acc:0.9568 | F1:0.8040\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:47:27,475 INFO: Epoch:[060/150]\n",
      "2022-05-07 17:47:27,475 INFO: Train Loss:0.095 | Acc:0.9752 | F1:0.8993\n",
      "2022-05-07 17:47:36,224 INFO: val Loss:0.199 | Acc:0.9568 | F1:0.8016\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 17:49:33,522 INFO: Epoch:[061/150]\n",
      "2022-05-07 17:49:33,522 INFO: Train Loss:0.095 | Acc:0.9740 | F1:0.8950\n",
      "2022-05-07 17:49:42,294 INFO: val Loss:0.186 | Acc:0.9579 | F1:0.7865\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:51:39,501 INFO: Epoch:[062/150]\n",
      "2022-05-07 17:51:39,501 INFO: Train Loss:0.096 | Acc:0.9725 | F1:0.8888\n",
      "2022-05-07 17:51:48,228 INFO: val Loss:0.136 | Acc:0.9673 | F1:0.8342\n",
      "2022-05-07 17:51:50,150 INFO: -----------------SAVE:62epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:53:47,406 INFO: Epoch:[063/150]\n",
      "2022-05-07 17:53:47,406 INFO: Train Loss:0.084 | Acc:0.9778 | F1:0.9135\n",
      "2022-05-07 17:53:56,139 INFO: val Loss:0.217 | Acc:0.9544 | F1:0.7828\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:55:53,192 INFO: Epoch:[064/150]\n",
      "2022-05-07 17:55:53,192 INFO: Train Loss:0.098 | Acc:0.9734 | F1:0.9011\n",
      "2022-05-07 17:56:01,962 INFO: val Loss:0.220 | Acc:0.9568 | F1:0.8052\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 17:57:59,163 INFO: Epoch:[065/150]\n",
      "2022-05-07 17:57:59,164 INFO: Train Loss:0.090 | Acc:0.9775 | F1:0.9142\n",
      "2022-05-07 17:58:07,931 INFO: val Loss:0.340 | Acc:0.9357 | F1:0.7291\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:00:05,186 INFO: Epoch:[066/150]\n",
      "2022-05-07 18:00:05,186 INFO: Train Loss:0.086 | Acc:0.9749 | F1:0.9080\n",
      "2022-05-07 18:00:13,948 INFO: val Loss:0.220 | Acc:0.9544 | F1:0.7640\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 18:02:11,734 INFO: Epoch:[067/150]\n",
      "2022-05-07 18:02:11,735 INFO: Train Loss:0.086 | Acc:0.9746 | F1:0.9025\n",
      "2022-05-07 18:02:20,678 INFO: val Loss:0.217 | Acc:0.9544 | F1:0.8170\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 18:04:18,483 INFO: Epoch:[068/150]\n",
      "2022-05-07 18:04:18,483 INFO: Train Loss:0.088 | Acc:0.9731 | F1:0.8979\n",
      "2022-05-07 18:04:27,243 INFO: val Loss:0.173 | Acc:0.9626 | F1:0.8079\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:06:24,366 INFO: Epoch:[069/150]\n",
      "2022-05-07 18:06:24,366 INFO: Train Loss:0.080 | Acc:0.9763 | F1:0.9086\n",
      "2022-05-07 18:06:33,105 INFO: val Loss:0.189 | Acc:0.9638 | F1:0.8218\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 18:08:30,103 INFO: Epoch:[070/150]\n",
      "2022-05-07 18:08:30,104 INFO: Train Loss:0.073 | Acc:0.9798 | F1:0.9264\n",
      "2022-05-07 18:08:38,835 INFO: val Loss:0.200 | Acc:0.9661 | F1:0.8294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:10:35,956 INFO: Epoch:[071/150]\n",
      "2022-05-07 18:10:35,956 INFO: Train Loss:0.080 | Acc:0.9778 | F1:0.9174\n",
      "2022-05-07 18:10:44,691 INFO: val Loss:0.220 | Acc:0.9626 | F1:0.7990\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 18:12:41,450 INFO: Epoch:[072/150]\n",
      "2022-05-07 18:12:41,450 INFO: Train Loss:0.083 | Acc:0.9757 | F1:0.9123\n",
      "2022-05-07 18:12:50,179 INFO: val Loss:0.150 | Acc:0.9603 | F1:0.8103\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:14:46,562 INFO: Epoch:[073/150]\n",
      "2022-05-07 18:14:46,563 INFO: Train Loss:0.077 | Acc:0.9798 | F1:0.9273\n",
      "2022-05-07 18:14:55,279 INFO: val Loss:0.166 | Acc:0.9638 | F1:0.8252\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:16:51,788 INFO: Epoch:[074/150]\n",
      "2022-05-07 18:16:51,789 INFO: Train Loss:0.084 | Acc:0.9772 | F1:0.9075\n",
      "2022-05-07 18:17:00,559 INFO: val Loss:0.196 | Acc:0.9614 | F1:0.8061\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:18:56,999 INFO: Epoch:[075/150]\n",
      "2022-05-07 18:18:56,999 INFO: Train Loss:0.069 | Acc:0.9828 | F1:0.9439\n",
      "2022-05-07 18:19:05,767 INFO: val Loss:0.190 | Acc:0.9509 | F1:0.7842\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:21:02,306 INFO: Epoch:[076/150]\n",
      "2022-05-07 18:21:02,307 INFO: Train Loss:0.081 | Acc:0.9784 | F1:0.9117\n",
      "2022-05-07 18:21:11,083 INFO: val Loss:0.150 | Acc:0.9650 | F1:0.8109\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 18:23:08,353 INFO: Epoch:[077/150]\n",
      "2022-05-07 18:23:08,354 INFO: Train Loss:0.066 | Acc:0.9828 | F1:0.9364\n",
      "2022-05-07 18:23:17,144 INFO: val Loss:0.205 | Acc:0.9603 | F1:0.8161\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:25:14,242 INFO: Epoch:[078/150]\n",
      "2022-05-07 18:25:14,243 INFO: Train Loss:0.056 | Acc:0.9851 | F1:0.9501\n",
      "2022-05-07 18:25:23,005 INFO: val Loss:0.150 | Acc:0.9661 | F1:0.8250\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:27:20,052 INFO: Epoch:[079/150]\n",
      "2022-05-07 18:27:20,052 INFO: Train Loss:0.071 | Acc:0.9807 | F1:0.9284\n",
      "2022-05-07 18:27:28,927 INFO: val Loss:0.167 | Acc:0.9556 | F1:0.7868\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:29:26,165 INFO: Epoch:[080/150]\n",
      "2022-05-07 18:29:26,165 INFO: Train Loss:0.056 | Acc:0.9836 | F1:0.9408\n",
      "2022-05-07 18:29:34,919 INFO: val Loss:0.187 | Acc:0.9614 | F1:0.8053\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:31:31,939 INFO: Epoch:[081/150]\n",
      "2022-05-07 18:31:31,939 INFO: Train Loss:0.072 | Acc:0.9836 | F1:0.9436\n",
      "2022-05-07 18:31:40,676 INFO: val Loss:0.148 | Acc:0.9650 | F1:0.8352\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:33:37,844 INFO: Epoch:[082/150]\n",
      "2022-05-07 18:33:37,844 INFO: Train Loss:0.059 | Acc:0.9851 | F1:0.9452\n",
      "2022-05-07 18:33:46,588 INFO: val Loss:0.193 | Acc:0.9638 | F1:0.8484\n",
      "2022-05-07 18:33:46,589 INFO: \n",
      "Best Val Epoch:62 | Val Loss:0.1360 | Val Acc:0.9673 | Val F1:0.8342\n",
      "2022-05-07 18:33:46,589 INFO: Total Process time:173.102Minute\n",
      "2022-05-07 18:33:46,592 INFO: {'exp_num': '1', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_160', 'drop_path_rate': 0.2, 'img_size': 224, 'batch_size': 16, 'epochs': 150, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 20, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'fold': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Read train_df.csv\n",
      "Dataset size:3421\n",
      "Dataset size:856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 18:33:47,393 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "2022-05-07 18:33:47,768 INFO: Computational complexity:       15.93 GMac\n",
      "2022-05-07 18:33:47,768 INFO: Number of parameters:           80.83 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:35:44,888 INFO: Epoch:[001/150]\n",
      "2022-05-07 18:35:44,889 INFO: Train Loss:4.484 | Acc:0.0111 | F1:0.0041\n",
      "2022-05-07 18:35:53,771 INFO: val Loss:4.502 | Acc:0.0000 | F1:0.0000\n",
      "2022-05-07 18:35:55,545 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.80it/s]\n",
      "2022-05-07 18:37:54,742 INFO: Epoch:[002/150]\n",
      "2022-05-07 18:37:54,742 INFO: Train Loss:4.468 | Acc:0.0120 | F1:0.0040\n",
      "2022-05-07 18:38:03,664 INFO: val Loss:4.486 | Acc:0.0000 | F1:0.0000\n",
      "2022-05-07 18:38:05,495 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:58<00:00,  1.81it/s]\n",
      "2022-05-07 18:40:03,756 INFO: Epoch:[003/150]\n",
      "2022-05-07 18:40:03,757 INFO: Train Loss:4.439 | Acc:0.0184 | F1:0.0081\n",
      "2022-05-07 18:40:12,580 INFO: val Loss:4.463 | Acc:0.0012 | F1:0.0003\n",
      "2022-05-07 18:40:14,701 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 18:42:14,022 INFO: Epoch:[004/150]\n",
      "2022-05-07 18:42:14,022 INFO: Train Loss:4.397 | Acc:0.0392 | F1:0.0097\n",
      "2022-05-07 18:42:22,880 INFO: val Loss:4.413 | Acc:0.0047 | F1:0.0008\n",
      "2022-05-07 18:42:24,700 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:58<00:00,  1.81it/s]\n",
      "2022-05-07 18:44:23,037 INFO: Epoch:[005/150]\n",
      "2022-05-07 18:44:23,038 INFO: Train Loss:4.339 | Acc:0.0710 | F1:0.0164\n",
      "2022-05-07 18:44:31,875 INFO: val Loss:4.352 | Acc:0.0514 | F1:0.0087\n",
      "2022-05-07 18:44:33,732 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:46:30,338 INFO: Epoch:[006/150]\n",
      "2022-05-07 18:46:30,338 INFO: Train Loss:3.985 | Acc:0.4025 | F1:0.0804\n",
      "2022-05-07 18:46:39,094 INFO: val Loss:3.628 | Acc:0.6402 | F1:0.1184\n",
      "2022-05-07 18:46:40,834 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:48:37,188 INFO: Epoch:[007/150]\n",
      "2022-05-07 18:48:37,188 INFO: Train Loss:3.158 | Acc:0.7702 | F1:0.1392\n",
      "2022-05-07 18:48:45,929 INFO: val Loss:2.578 | Acc:0.8341 | F1:0.1448\n",
      "2022-05-07 18:48:47,753 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-07 18:50:44,311 INFO: Epoch:[008/150]\n",
      "2022-05-07 18:50:44,312 INFO: Train Loss:2.240 | Acc:0.8252 | F1:0.1479\n",
      "2022-05-07 18:50:53,053 INFO: val Loss:1.561 | Acc:0.8400 | F1:0.1507\n",
      "2022-05-07 18:50:54,983 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:52:52,241 INFO: Epoch:[009/150]\n",
      "2022-05-07 18:52:52,241 INFO: Train Loss:1.496 | Acc:0.8384 | F1:0.1516\n",
      "2022-05-07 18:53:01,072 INFO: val Loss:1.035 | Acc:0.8493 | F1:0.1569\n",
      "2022-05-07 18:53:03,018 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 18:54:59,685 INFO: Epoch:[010/150]\n",
      "2022-05-07 18:54:59,685 INFO: Train Loss:1.197 | Acc:0.8413 | F1:0.1545\n",
      "2022-05-07 18:55:08,448 INFO: val Loss:0.967 | Acc:0.8493 | F1:0.1563\n",
      "2022-05-07 18:55:10,333 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 18:57:07,281 INFO: Epoch:[011/150]\n",
      "2022-05-07 18:57:07,282 INFO: Train Loss:1.050 | Acc:0.8442 | F1:0.1554\n",
      "2022-05-07 18:57:16,054 INFO: val Loss:0.844 | Acc:0.8493 | F1:0.1562\n",
      "2022-05-07 18:57:17,910 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 18:59:15,044 INFO: Epoch:[012/150]\n",
      "2022-05-07 18:59:15,045 INFO: Train Loss:0.912 | Acc:0.8465 | F1:0.1556\n",
      "2022-05-07 18:59:23,774 INFO: val Loss:0.744 | Acc:0.8493 | F1:0.1562\n",
      "2022-05-07 18:59:26,060 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:01:22,895 INFO: Epoch:[013/150]\n",
      "2022-05-07 19:01:22,895 INFO: Train Loss:0.805 | Acc:0.8471 | F1:0.1579\n",
      "2022-05-07 19:01:31,647 INFO: val Loss:0.705 | Acc:0.8516 | F1:0.1678\n",
      "2022-05-07 19:01:33,501 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:03:30,684 INFO: Epoch:[014/150]\n",
      "2022-05-07 19:03:30,684 INFO: Train Loss:0.731 | Acc:0.8533 | F1:0.1926\n",
      "2022-05-07 19:03:39,423 INFO: val Loss:0.657 | Acc:0.8610 | F1:0.2203\n",
      "2022-05-07 19:03:41,297 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:05:38,281 INFO: Epoch:[015/150]\n",
      "2022-05-07 19:05:38,282 INFO: Train Loss:0.660 | Acc:0.8568 | F1:0.2175\n",
      "2022-05-07 19:05:47,035 INFO: val Loss:0.551 | Acc:0.8610 | F1:0.2595\n",
      "2022-05-07 19:05:48,921 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:07:46,039 INFO: Epoch:[016/150]\n",
      "2022-05-07 19:07:46,039 INFO: Train Loss:0.588 | Acc:0.8676 | F1:0.2740\n",
      "2022-05-07 19:07:54,804 INFO: val Loss:0.501 | Acc:0.8738 | F1:0.2691\n",
      "2022-05-07 19:07:56,769 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:09:53,931 INFO: Epoch:[017/150]\n",
      "2022-05-07 19:09:53,931 INFO: Train Loss:0.543 | Acc:0.8787 | F1:0.3336\n",
      "2022-05-07 19:10:02,719 INFO: val Loss:0.431 | Acc:0.8773 | F1:0.3380\n",
      "2022-05-07 19:10:04,559 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:12:01,561 INFO: Epoch:[018/150]\n",
      "2022-05-07 19:12:01,561 INFO: Train Loss:0.486 | Acc:0.8857 | F1:0.3970\n",
      "2022-05-07 19:12:10,308 INFO: val Loss:0.427 | Acc:0.8937 | F1:0.4016\n",
      "2022-05-07 19:12:12,000 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:14:08,679 INFO: Epoch:[019/150]\n",
      "2022-05-07 19:14:08,680 INFO: Train Loss:0.441 | Acc:0.8936 | F1:0.4274\n",
      "2022-05-07 19:14:17,403 INFO: val Loss:0.371 | Acc:0.9030 | F1:0.4486\n",
      "2022-05-07 19:14:19,380 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:16:16,575 INFO: Epoch:[020/150]\n",
      "2022-05-07 19:16:16,576 INFO: Train Loss:0.403 | Acc:0.8986 | F1:0.4647\n",
      "2022-05-07 19:16:25,325 INFO: val Loss:0.339 | Acc:0.9124 | F1:0.4975\n",
      "2022-05-07 19:16:27,131 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:18:24,009 INFO: Epoch:[021/150]\n",
      "2022-05-07 19:18:24,010 INFO: Train Loss:0.374 | Acc:0.9068 | F1:0.5192\n",
      "2022-05-07 19:18:32,770 INFO: val Loss:0.334 | Acc:0.9007 | F1:0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 19:18:34,506 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:20:31,311 INFO: Epoch:[022/150]\n",
      "2022-05-07 19:20:31,312 INFO: Train Loss:0.338 | Acc:0.9129 | F1:0.5566\n",
      "2022-05-07 19:20:40,079 INFO: val Loss:0.367 | Acc:0.9159 | F1:0.5434\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 19:22:37,658 INFO: Epoch:[023/150]\n",
      "2022-05-07 19:22:37,658 INFO: Train Loss:0.321 | Acc:0.9179 | F1:0.5982\n",
      "2022-05-07 19:22:46,407 INFO: val Loss:0.314 | Acc:0.9229 | F1:0.5676\n",
      "2022-05-07 19:22:48,270 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:24:45,369 INFO: Epoch:[024/150]\n",
      "2022-05-07 19:24:45,369 INFO: Train Loss:0.298 | Acc:0.9199 | F1:0.6023\n",
      "2022-05-07 19:24:54,118 INFO: val Loss:0.325 | Acc:0.9065 | F1:0.5320\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:26:50,847 INFO: Epoch:[025/150]\n",
      "2022-05-07 19:26:50,848 INFO: Train Loss:0.287 | Acc:0.9220 | F1:0.6350\n",
      "2022-05-07 19:26:59,635 INFO: val Loss:0.261 | Acc:0.9229 | F1:0.5690\n",
      "2022-05-07 19:27:01,507 INFO: -----------------SAVE:25epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:28:58,529 INFO: Epoch:[026/150]\n",
      "2022-05-07 19:28:58,529 INFO: Train Loss:0.250 | Acc:0.9290 | F1:0.6647\n",
      "2022-05-07 19:29:07,311 INFO: val Loss:0.309 | Acc:0.9182 | F1:0.5290\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:31:04,313 INFO: Epoch:[027/150]\n",
      "2022-05-07 19:31:04,314 INFO: Train Loss:0.241 | Acc:0.9325 | F1:0.6811\n",
      "2022-05-07 19:31:13,045 INFO: val Loss:0.218 | Acc:0.9416 | F1:0.6591\n",
      "2022-05-07 19:31:14,971 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 19:33:12,248 INFO: Epoch:[028/150]\n",
      "2022-05-07 19:33:12,248 INFO: Train Loss:0.237 | Acc:0.9336 | F1:0.6934\n",
      "2022-05-07 19:33:21,005 INFO: val Loss:0.265 | Acc:0.9334 | F1:0.6051\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:35:17,982 INFO: Epoch:[029/150]\n",
      "2022-05-07 19:35:17,982 INFO: Train Loss:0.232 | Acc:0.9354 | F1:0.7099\n",
      "2022-05-07 19:35:26,715 INFO: val Loss:0.228 | Acc:0.9311 | F1:0.6116\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:37:23,734 INFO: Epoch:[030/150]\n",
      "2022-05-07 19:37:23,734 INFO: Train Loss:0.222 | Acc:0.9404 | F1:0.7512\n",
      "2022-05-07 19:37:32,504 INFO: val Loss:0.243 | Acc:0.9369 | F1:0.6374\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 19:39:29,966 INFO: Epoch:[031/150]\n",
      "2022-05-07 19:39:29,966 INFO: Train Loss:0.201 | Acc:0.9433 | F1:0.7630\n",
      "2022-05-07 19:39:38,698 INFO: val Loss:0.205 | Acc:0.9451 | F1:0.6883\n",
      "2022-05-07 19:39:40,654 INFO: -----------------SAVE:31epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:41:37,783 INFO: Epoch:[032/150]\n",
      "2022-05-07 19:41:37,783 INFO: Train Loss:0.182 | Acc:0.9471 | F1:0.7621\n",
      "2022-05-07 19:41:46,517 INFO: val Loss:0.322 | Acc:0.9287 | F1:0.6318\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:43:43,562 INFO: Epoch:[033/150]\n",
      "2022-05-07 19:43:43,563 INFO: Train Loss:0.212 | Acc:0.9488 | F1:0.7882\n",
      "2022-05-07 19:43:52,316 INFO: val Loss:0.227 | Acc:0.9393 | F1:0.6755\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:45:49,261 INFO: Epoch:[034/150]\n",
      "2022-05-07 19:45:49,261 INFO: Train Loss:0.190 | Acc:0.9491 | F1:0.8024\n",
      "2022-05-07 19:45:57,999 INFO: val Loss:0.243 | Acc:0.9404 | F1:0.6636\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:47:55,010 INFO: Epoch:[035/150]\n",
      "2022-05-07 19:47:55,011 INFO: Train Loss:0.173 | Acc:0.9535 | F1:0.8095\n",
      "2022-05-07 19:48:03,777 INFO: val Loss:0.247 | Acc:0.9381 | F1:0.6691\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:50:00,728 INFO: Epoch:[036/150]\n",
      "2022-05-07 19:50:00,728 INFO: Train Loss:0.184 | Acc:0.9509 | F1:0.7969\n",
      "2022-05-07 19:50:09,489 INFO: val Loss:0.218 | Acc:0.9357 | F1:0.6698\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:52:06,411 INFO: Epoch:[037/150]\n",
      "2022-05-07 19:52:06,411 INFO: Train Loss:0.176 | Acc:0.9529 | F1:0.8068\n",
      "2022-05-07 19:52:15,186 INFO: val Loss:0.218 | Acc:0.9264 | F1:0.6855\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:54:11,999 INFO: Epoch:[038/150]\n",
      "2022-05-07 19:54:12,000 INFO: Train Loss:0.166 | Acc:0.9553 | F1:0.8188\n",
      "2022-05-07 19:54:20,752 INFO: val Loss:0.205 | Acc:0.9521 | F1:0.7514\n",
      "2022-05-07 19:54:22,694 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 19:56:19,887 INFO: Epoch:[039/150]\n",
      "2022-05-07 19:56:19,887 INFO: Train Loss:0.170 | Acc:0.9524 | F1:0.8091\n",
      "2022-05-07 19:56:28,640 INFO: val Loss:0.237 | Acc:0.9498 | F1:0.7263\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 19:58:25,614 INFO: Epoch:[040/150]\n",
      "2022-05-07 19:58:25,615 INFO: Train Loss:0.155 | Acc:0.9570 | F1:0.8273\n",
      "2022-05-07 19:58:34,400 INFO: val Loss:0.263 | Acc:0.9416 | F1:0.6973\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:00:31,440 INFO: Epoch:[041/150]\n",
      "2022-05-07 20:00:31,440 INFO: Train Loss:0.174 | Acc:0.9532 | F1:0.8226\n",
      "2022-05-07 20:00:40,169 INFO: val Loss:0.194 | Acc:0.9544 | F1:0.7476\n",
      "2022-05-07 20:00:42,026 INFO: -----------------SAVE:41epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:02:39,196 INFO: Epoch:[042/150]\n",
      "2022-05-07 20:02:39,196 INFO: Train Loss:0.140 | Acc:0.9617 | F1:0.8493\n",
      "2022-05-07 20:02:47,951 INFO: val Loss:0.219 | Acc:0.9521 | F1:0.7295\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.81it/s]\n",
      "2022-05-07 20:04:45,874 INFO: Epoch:[043/150]\n",
      "2022-05-07 20:04:45,874 INFO: Train Loss:0.143 | Acc:0.9576 | F1:0.8335\n",
      "2022-05-07 20:04:54,792 INFO: val Loss:0.236 | Acc:0.9451 | F1:0.6681\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:06:52,067 INFO: Epoch:[044/150]\n",
      "2022-05-07 20:06:52,067 INFO: Train Loss:0.152 | Acc:0.9600 | F1:0.8430\n",
      "2022-05-07 20:07:00,844 INFO: val Loss:0.251 | Acc:0.9463 | F1:0.6957\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:08:57,947 INFO: Epoch:[045/150]\n",
      "2022-05-07 20:08:57,947 INFO: Train Loss:0.139 | Acc:0.9667 | F1:0.8701\n",
      "2022-05-07 20:09:06,716 INFO: val Loss:0.204 | Acc:0.9486 | F1:0.7187\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:11:04,107 INFO: Epoch:[046/150]\n",
      "2022-05-07 20:11:04,107 INFO: Train Loss:0.131 | Acc:0.9655 | F1:0.8571\n",
      "2022-05-07 20:11:12,890 INFO: val Loss:0.191 | Acc:0.9509 | F1:0.7310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 20:11:14,786 INFO: -----------------SAVE:46epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:13:12,015 INFO: Epoch:[047/150]\n",
      "2022-05-07 20:13:12,015 INFO: Train Loss:0.129 | Acc:0.9626 | F1:0.8555\n",
      "2022-05-07 20:13:20,766 INFO: val Loss:0.207 | Acc:0.9568 | F1:0.7620\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 20:15:17,630 INFO: Epoch:[048/150]\n",
      "2022-05-07 20:15:17,631 INFO: Train Loss:0.136 | Acc:0.9632 | F1:0.8662\n",
      "2022-05-07 20:15:26,393 INFO: val Loss:0.254 | Acc:0.9428 | F1:0.6863\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 20:17:23,344 INFO: Epoch:[049/150]\n",
      "2022-05-07 20:17:23,345 INFO: Train Loss:0.150 | Acc:0.9643 | F1:0.8542\n",
      "2022-05-07 20:17:32,097 INFO: val Loss:0.224 | Acc:0.9498 | F1:0.6978\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:19:29,184 INFO: Epoch:[050/150]\n",
      "2022-05-07 20:19:29,184 INFO: Train Loss:0.117 | Acc:0.9676 | F1:0.8648\n",
      "2022-05-07 20:19:37,952 INFO: val Loss:0.201 | Acc:0.9626 | F1:0.7835\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:21:35,003 INFO: Epoch:[051/150]\n",
      "2022-05-07 20:21:35,003 INFO: Train Loss:0.122 | Acc:0.9658 | F1:0.8680\n",
      "2022-05-07 20:21:43,764 INFO: val Loss:0.193 | Acc:0.9521 | F1:0.7437\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:23:41,254 INFO: Epoch:[052/150]\n",
      "2022-05-07 20:23:41,255 INFO: Train Loss:0.111 | Acc:0.9696 | F1:0.8847\n",
      "2022-05-07 20:23:49,990 INFO: val Loss:0.161 | Acc:0.9673 | F1:0.8154\n",
      "2022-05-07 20:23:51,982 INFO: -----------------SAVE:52epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:25:49,084 INFO: Epoch:[053/150]\n",
      "2022-05-07 20:25:49,085 INFO: Train Loss:0.111 | Acc:0.9714 | F1:0.8962\n",
      "2022-05-07 20:25:57,846 INFO: val Loss:0.235 | Acc:0.9509 | F1:0.7090\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:27:54,946 INFO: Epoch:[054/150]\n",
      "2022-05-07 20:27:54,946 INFO: Train Loss:0.125 | Acc:0.9696 | F1:0.8910\n",
      "2022-05-07 20:28:03,735 INFO: val Loss:0.939 | Acc:0.8914 | F1:0.6811\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 20:30:00,687 INFO: Epoch:[055/150]\n",
      "2022-05-07 20:30:00,687 INFO: Train Loss:0.114 | Acc:0.9684 | F1:0.8799\n",
      "2022-05-07 20:30:09,461 INFO: val Loss:0.226 | Acc:0.9509 | F1:0.7123\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:32:06,617 INFO: Epoch:[056/150]\n",
      "2022-05-07 20:32:06,617 INFO: Train Loss:0.108 | Acc:0.9699 | F1:0.8813\n",
      "2022-05-07 20:32:15,392 INFO: val Loss:0.232 | Acc:0.9509 | F1:0.7443\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 20:34:12,282 INFO: Epoch:[057/150]\n",
      "2022-05-07 20:34:12,282 INFO: Train Loss:0.114 | Acc:0.9708 | F1:0.8987\n",
      "2022-05-07 20:34:21,065 INFO: val Loss:0.242 | Acc:0.9474 | F1:0.7476\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 20:36:18,046 INFO: Epoch:[058/150]\n",
      "2022-05-07 20:36:18,046 INFO: Train Loss:0.104 | Acc:0.9681 | F1:0.8890\n",
      "2022-05-07 20:36:26,808 INFO: val Loss:0.229 | Acc:0.9521 | F1:0.7323\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:38:24,187 INFO: Epoch:[059/150]\n",
      "2022-05-07 20:38:24,188 INFO: Train Loss:0.098 | Acc:0.9725 | F1:0.8929\n",
      "2022-05-07 20:38:32,968 INFO: val Loss:0.184 | Acc:0.9591 | F1:0.7730\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:40:30,199 INFO: Epoch:[060/150]\n",
      "2022-05-07 20:40:30,199 INFO: Train Loss:0.093 | Acc:0.9754 | F1:0.8983\n",
      "2022-05-07 20:40:38,992 INFO: val Loss:0.193 | Acc:0.9568 | F1:0.7622\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:42:36,036 INFO: Epoch:[061/150]\n",
      "2022-05-07 20:42:36,037 INFO: Train Loss:0.111 | Acc:0.9684 | F1:0.8778\n",
      "2022-05-07 20:42:44,788 INFO: val Loss:0.209 | Acc:0.9591 | F1:0.7824\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:44:42,059 INFO: Epoch:[062/150]\n",
      "2022-05-07 20:44:42,059 INFO: Train Loss:0.107 | Acc:0.9734 | F1:0.9041\n",
      "2022-05-07 20:44:50,794 INFO: val Loss:0.189 | Acc:0.9591 | F1:0.7882\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-07 20:46:47,733 INFO: Epoch:[063/150]\n",
      "2022-05-07 20:46:47,734 INFO: Train Loss:0.104 | Acc:0.9711 | F1:0.8857\n",
      "2022-05-07 20:46:56,527 INFO: val Loss:0.182 | Acc:0.9603 | F1:0.7672\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:48:53,682 INFO: Epoch:[064/150]\n",
      "2022-05-07 20:48:53,682 INFO: Train Loss:0.094 | Acc:0.9787 | F1:0.9249\n",
      "2022-05-07 20:49:02,454 INFO: val Loss:0.202 | Acc:0.9614 | F1:0.7867\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:50:59,731 INFO: Epoch:[065/150]\n",
      "2022-05-07 20:50:59,731 INFO: Train Loss:0.101 | Acc:0.9749 | F1:0.9072\n",
      "2022-05-07 20:51:08,521 INFO: val Loss:0.177 | Acc:0.9568 | F1:0.7664\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:53:05,726 INFO: Epoch:[066/150]\n",
      "2022-05-07 20:53:05,727 INFO: Train Loss:0.086 | Acc:0.9757 | F1:0.9047\n",
      "2022-05-07 20:53:14,501 INFO: val Loss:0.231 | Acc:0.9474 | F1:0.7261\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:55:11,549 INFO: Epoch:[067/150]\n",
      "2022-05-07 20:55:11,550 INFO: Train Loss:0.094 | Acc:0.9766 | F1:0.9165\n",
      "2022-05-07 20:55:20,333 INFO: val Loss:0.217 | Acc:0.9579 | F1:0.7650\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 20:57:17,648 INFO: Epoch:[068/150]\n",
      "2022-05-07 20:57:17,648 INFO: Train Loss:0.085 | Acc:0.9775 | F1:0.9177\n",
      "2022-05-07 20:57:26,405 INFO: val Loss:0.226 | Acc:0.9556 | F1:0.7841\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 20:59:23,619 INFO: Epoch:[069/150]\n",
      "2022-05-07 20:59:23,619 INFO: Train Loss:0.078 | Acc:0.9790 | F1:0.9350\n",
      "2022-05-07 20:59:32,378 INFO: val Loss:0.228 | Acc:0.9544 | F1:0.7590\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 21:01:29,510 INFO: Epoch:[070/150]\n",
      "2022-05-07 21:01:29,510 INFO: Train Loss:0.076 | Acc:0.9792 | F1:0.9293\n",
      "2022-05-07 21:01:38,277 INFO: val Loss:0.173 | Acc:0.9591 | F1:0.7994\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-07 21:03:35,799 INFO: Epoch:[071/150]\n",
      "2022-05-07 21:03:35,799 INFO: Train Loss:0.085 | Acc:0.9757 | F1:0.9126\n",
      "2022-05-07 21:03:44,733 INFO: val Loss:0.248 | Acc:0.9486 | F1:0.7574\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-07 21:05:41,859 INFO: Epoch:[072/150]\n",
      "2022-05-07 21:05:41,859 INFO: Train Loss:0.088 | Acc:0.9746 | F1:0.9044\n",
      "2022-05-07 21:05:50,611 INFO: val Loss:0.238 | Acc:0.9416 | F1:0.7170\n",
      "2022-05-07 21:05:50,611 INFO: \n",
      "Best Val Epoch:52 | Val Loss:0.1609 | Val Acc:0.9673 | Val F1:0.8154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 21:05:50,612 INFO: Total Process time:152.047Minute\n",
      "2022-05-07 21:05:50,613 INFO: {'exp_num': '2', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_160', 'drop_path_rate': 0.2, 'img_size': 224, 'batch_size': 16, 'epochs': 150, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 20, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'fold': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Read train_df.csv\n",
      "Dataset size:3422\n",
      "Dataset size:855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 21:05:51,448 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "2022-05-07 21:05:51,817 INFO: Computational complexity:       15.93 GMac\n",
      "2022-05-07 21:05:51,818 INFO: Number of parameters:           80.83 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 21:07:51,364 INFO: Epoch:[001/150]\n",
      "2022-05-07 21:07:51,365 INFO: Train Loss:4.482 | Acc:0.0091 | F1:0.0043\n",
      "2022-05-07 21:08:01,889 INFO: val Loss:4.496 | Acc:0.0012 | F1:0.0002\n",
      "2022-05-07 21:08:03,687 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:10:03,880 INFO: Epoch:[002/150]\n",
      "2022-05-07 21:10:03,880 INFO: Train Loss:4.470 | Acc:0.0091 | F1:0.0041\n",
      "2022-05-07 21:10:13,156 INFO: val Loss:4.485 | Acc:0.0023 | F1:0.0007\n",
      "2022-05-07 21:10:14,956 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 21:12:14,699 INFO: Epoch:[003/150]\n",
      "2022-05-07 21:12:14,700 INFO: Train Loss:4.439 | Acc:0.0167 | F1:0.0057\n",
      "2022-05-07 21:12:23,938 INFO: val Loss:4.446 | Acc:0.0035 | F1:0.0006\n",
      "2022-05-07 21:12:25,678 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 21:14:25,328 INFO: Epoch:[004/150]\n",
      "2022-05-07 21:14:25,329 INFO: Train Loss:4.401 | Acc:0.0345 | F1:0.0089\n",
      "2022-05-07 21:14:34,585 INFO: val Loss:4.410 | Acc:0.0140 | F1:0.0035\n",
      "2022-05-07 21:14:36,410 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 21:16:35,872 INFO: Epoch:[005/150]\n",
      "2022-05-07 21:16:35,873 INFO: Train Loss:4.339 | Acc:0.0643 | F1:0.0130\n",
      "2022-05-07 21:16:45,090 INFO: val Loss:4.334 | Acc:0.0608 | F1:0.0093\n",
      "2022-05-07 21:16:46,869 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 21:18:46,251 INFO: Epoch:[006/150]\n",
      "2022-05-07 21:18:46,251 INFO: Train Loss:3.995 | Acc:0.4024 | F1:0.0800\n",
      "2022-05-07 21:18:55,498 INFO: val Loss:3.667 | Acc:0.6620 | F1:0.1195\n",
      "2022-05-07 21:18:57,251 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:20:57,617 INFO: Epoch:[007/150]\n",
      "2022-05-07 21:20:57,618 INFO: Train Loss:3.159 | Acc:0.7791 | F1:0.1425\n",
      "2022-05-07 21:21:06,980 INFO: val Loss:2.541 | Acc:0.8398 | F1:0.1509\n",
      "2022-05-07 21:21:08,866 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:23:09,321 INFO: Epoch:[008/150]\n",
      "2022-05-07 21:23:09,322 INFO: Train Loss:2.251 | Acc:0.8220 | F1:0.1461\n",
      "2022-05-07 21:23:18,634 INFO: val Loss:1.586 | Acc:0.8480 | F1:0.1556\n",
      "2022-05-07 21:23:20,722 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:25:21,007 INFO: Epoch:[009/150]\n",
      "2022-05-07 21:25:21,007 INFO: Train Loss:1.494 | Acc:0.8393 | F1:0.1525\n",
      "2022-05-07 21:25:30,296 INFO: val Loss:1.073 | Acc:0.8491 | F1:0.1562\n",
      "2022-05-07 21:25:32,262 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:27:32,505 INFO: Epoch:[010/150]\n",
      "2022-05-07 21:27:32,505 INFO: Train Loss:1.194 | Acc:0.8437 | F1:0.1552\n",
      "2022-05-07 21:27:41,774 INFO: val Loss:0.954 | Acc:0.8491 | F1:0.1562\n",
      "2022-05-07 21:27:43,793 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:29:44,171 INFO: Epoch:[011/150]\n",
      "2022-05-07 21:29:44,171 INFO: Train Loss:1.048 | Acc:0.8457 | F1:0.1557\n",
      "2022-05-07 21:29:53,410 INFO: val Loss:0.865 | Acc:0.8491 | F1:0.1562\n",
      "2022-05-07 21:29:55,323 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:31:55,713 INFO: Epoch:[012/150]\n",
      "2022-05-07 21:31:55,714 INFO: Train Loss:0.914 | Acc:0.8475 | F1:0.1560\n",
      "2022-05-07 21:32:05,171 INFO: val Loss:0.737 | Acc:0.8503 | F1:0.1638\n",
      "2022-05-07 21:32:07,043 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-07 21:34:09,989 INFO: Epoch:[013/150]\n",
      "2022-05-07 21:34:09,989 INFO: Train Loss:0.813 | Acc:0.8477 | F1:0.1605\n",
      "2022-05-07 21:34:20,250 INFO: val Loss:0.682 | Acc:0.8526 | F1:0.1754\n",
      "2022-05-07 21:34:22,288 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:04<00:00,  1.72it/s]\n",
      "2022-05-07 21:36:26,469 INFO: Epoch:[014/150]\n",
      "2022-05-07 21:36:26,470 INFO: Train Loss:0.725 | Acc:0.8518 | F1:0.1812\n",
      "2022-05-07 21:36:35,712 INFO: val Loss:0.615 | Acc:0.8526 | F1:0.1757\n",
      "2022-05-07 21:36:37,685 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-07 21:38:40,476 INFO: Epoch:[015/150]\n",
      "2022-05-07 21:38:40,477 INFO: Train Loss:0.654 | Acc:0.8565 | F1:0.2107\n",
      "2022-05-07 21:38:49,727 INFO: val Loss:0.542 | Acc:0.8690 | F1:0.2534\n",
      "2022-05-07 21:38:51,771 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 21:40:52,533 INFO: Epoch:[016/150]\n",
      "2022-05-07 21:40:52,534 INFO: Train Loss:0.605 | Acc:0.8629 | F1:0.2631\n",
      "2022-05-07 21:41:01,903 INFO: val Loss:0.512 | Acc:0.8807 | F1:0.3032\n",
      "2022-05-07 21:41:04,014 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 21:43:04,832 INFO: Epoch:[017/150]\n",
      "2022-05-07 21:43:04,832 INFO: Train Loss:0.544 | Acc:0.8776 | F1:0.3332\n",
      "2022-05-07 21:43:14,152 INFO: val Loss:0.446 | Acc:0.8830 | F1:0.3390\n",
      "2022-05-07 21:43:16,284 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 21:45:16,914 INFO: Epoch:[018/150]\n",
      "2022-05-07 21:45:16,915 INFO: Train Loss:0.482 | Acc:0.8852 | F1:0.3809\n",
      "2022-05-07 21:45:26,126 INFO: val Loss:0.430 | Acc:0.8877 | F1:0.3594\n",
      "2022-05-07 21:45:28,048 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:47:28,561 INFO: Epoch:[019/150]\n",
      "2022-05-07 21:47:28,562 INFO: Train Loss:0.441 | Acc:0.8913 | F1:0.4162\n",
      "2022-05-07 21:47:37,793 INFO: val Loss:0.393 | Acc:0.8936 | F1:0.3840\n",
      "2022-05-07 21:47:39,811 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 21:49:40,621 INFO: Epoch:[020/150]\n",
      "2022-05-07 21:49:40,622 INFO: Train Loss:0.400 | Acc:0.9018 | F1:0.4830\n",
      "2022-05-07 21:49:49,895 INFO: val Loss:0.349 | Acc:0.9111 | F1:0.4784\n",
      "2022-05-07 21:49:51,679 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:51:51,708 INFO: Epoch:[021/150]\n",
      "2022-05-07 21:51:51,708 INFO: Train Loss:0.364 | Acc:0.9097 | F1:0.5340\n",
      "2022-05-07 21:52:01,037 INFO: val Loss:0.311 | Acc:0.9135 | F1:0.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-07 21:52:02,877 INFO: -----------------SAVE:21epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:54:03,040 INFO: Epoch:[022/150]\n",
      "2022-05-07 21:54:03,041 INFO: Train Loss:0.326 | Acc:0.9138 | F1:0.5531\n",
      "2022-05-07 21:54:12,269 INFO: val Loss:0.326 | Acc:0.9181 | F1:0.5639\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 21:56:12,433 INFO: Epoch:[023/150]\n",
      "2022-05-07 21:56:12,434 INFO: Train Loss:0.314 | Acc:0.9141 | F1:0.5775\n",
      "2022-05-07 21:56:21,692 INFO: val Loss:0.255 | Acc:0.9275 | F1:0.5768\n",
      "2022-05-07 21:56:23,406 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 21:58:23,253 INFO: Epoch:[024/150]\n",
      "2022-05-07 21:58:23,254 INFO: Train Loss:0.302 | Acc:0.9220 | F1:0.6238\n",
      "2022-05-07 21:58:32,456 INFO: val Loss:0.257 | Acc:0.9240 | F1:0.5494\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:00:32,653 INFO: Epoch:[025/150]\n",
      "2022-05-07 22:00:32,653 INFO: Train Loss:0.274 | Acc:0.9264 | F1:0.6391\n",
      "2022-05-07 22:00:41,875 INFO: val Loss:0.255 | Acc:0.9228 | F1:0.6189\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:02:42,159 INFO: Epoch:[026/150]\n",
      "2022-05-07 22:02:42,159 INFO: Train Loss:0.247 | Acc:0.9348 | F1:0.6993\n",
      "2022-05-07 22:02:51,421 INFO: val Loss:0.245 | Acc:0.9251 | F1:0.5997\n",
      "2022-05-07 22:02:53,318 INFO: -----------------SAVE:26epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:04:53,955 INFO: Epoch:[027/150]\n",
      "2022-05-07 22:04:53,956 INFO: Train Loss:0.245 | Acc:0.9348 | F1:0.6959\n",
      "2022-05-07 22:05:03,281 INFO: val Loss:0.227 | Acc:0.9392 | F1:0.6646\n",
      "2022-05-07 22:05:05,250 INFO: -----------------SAVE:27epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.76it/s]\n",
      "2022-05-07 22:07:06,827 INFO: Epoch:[028/150]\n",
      "2022-05-07 22:07:06,828 INFO: Train Loss:0.227 | Acc:0.9372 | F1:0.7227\n",
      "2022-05-07 22:07:16,627 INFO: val Loss:0.228 | Acc:0.9415 | F1:0.6547\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.77it/s]\n",
      "2022-05-07 22:09:17,716 INFO: Epoch:[029/150]\n",
      "2022-05-07 22:09:17,717 INFO: Train Loss:0.218 | Acc:0.9380 | F1:0.7207\n",
      "2022-05-07 22:09:27,024 INFO: val Loss:0.180 | Acc:0.9520 | F1:0.7336\n",
      "2022-05-07 22:09:28,904 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:11:29,676 INFO: Epoch:[030/150]\n",
      "2022-05-07 22:11:29,677 INFO: Train Loss:0.208 | Acc:0.9433 | F1:0.7481\n",
      "2022-05-07 22:11:39,270 INFO: val Loss:0.237 | Acc:0.9380 | F1:0.6665\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:13:39,743 INFO: Epoch:[031/150]\n",
      "2022-05-07 22:13:39,744 INFO: Train Loss:0.207 | Acc:0.9389 | F1:0.7408\n",
      "2022-05-07 22:13:49,015 INFO: val Loss:0.201 | Acc:0.9532 | F1:0.7496\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:15:49,143 INFO: Epoch:[032/150]\n",
      "2022-05-07 22:15:49,143 INFO: Train Loss:0.202 | Acc:0.9445 | F1:0.7633\n",
      "2022-05-07 22:15:58,427 INFO: val Loss:0.207 | Acc:0.9427 | F1:0.6894\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:17:58,743 INFO: Epoch:[033/150]\n",
      "2022-05-07 22:17:58,744 INFO: Train Loss:0.194 | Acc:0.9430 | F1:0.7548\n",
      "2022-05-07 22:18:08,098 INFO: val Loss:0.258 | Acc:0.9357 | F1:0.6739\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:20:08,500 INFO: Epoch:[034/150]\n",
      "2022-05-07 22:20:08,500 INFO: Train Loss:0.170 | Acc:0.9521 | F1:0.7838\n",
      "2022-05-07 22:20:17,781 INFO: val Loss:0.196 | Acc:0.9415 | F1:0.6648\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:22:18,473 INFO: Epoch:[035/150]\n",
      "2022-05-07 22:22:18,473 INFO: Train Loss:0.186 | Acc:0.9483 | F1:0.7690\n",
      "2022-05-07 22:22:27,711 INFO: val Loss:0.264 | Acc:0.9263 | F1:0.7186\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:24:28,368 INFO: Epoch:[036/150]\n",
      "2022-05-07 22:24:28,368 INFO: Train Loss:0.167 | Acc:0.9568 | F1:0.8294\n",
      "2022-05-07 22:24:37,613 INFO: val Loss:0.204 | Acc:0.9520 | F1:0.7281\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:26:37,828 INFO: Epoch:[037/150]\n",
      "2022-05-07 22:26:37,829 INFO: Train Loss:0.184 | Acc:0.9506 | F1:0.8007\n",
      "2022-05-07 22:26:47,080 INFO: val Loss:0.185 | Acc:0.9497 | F1:0.7327\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:28:47,423 INFO: Epoch:[038/150]\n",
      "2022-05-07 22:28:47,423 INFO: Train Loss:0.151 | Acc:0.9585 | F1:0.8336\n",
      "2022-05-07 22:28:56,718 INFO: val Loss:0.190 | Acc:0.9544 | F1:0.7366\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:30:57,204 INFO: Epoch:[039/150]\n",
      "2022-05-07 22:30:57,205 INFO: Train Loss:0.159 | Acc:0.9562 | F1:0.8179\n",
      "2022-05-07 22:31:06,470 INFO: val Loss:0.238 | Acc:0.9333 | F1:0.7258\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:33:06,854 INFO: Epoch:[040/150]\n",
      "2022-05-07 22:33:06,854 INFO: Train Loss:0.158 | Acc:0.9573 | F1:0.8261\n",
      "2022-05-07 22:33:16,200 INFO: val Loss:0.213 | Acc:0.9532 | F1:0.7609\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:35:16,618 INFO: Epoch:[041/150]\n",
      "2022-05-07 22:35:16,619 INFO: Train Loss:0.148 | Acc:0.9608 | F1:0.8310\n",
      "2022-05-07 22:35:25,848 INFO: val Loss:0.211 | Acc:0.9474 | F1:0.7481\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:37:26,535 INFO: Epoch:[042/150]\n",
      "2022-05-07 22:37:26,536 INFO: Train Loss:0.165 | Acc:0.9550 | F1:0.8204\n",
      "2022-05-07 22:37:35,844 INFO: val Loss:0.204 | Acc:0.9520 | F1:0.7399\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:39:36,377 INFO: Epoch:[043/150]\n",
      "2022-05-07 22:39:36,377 INFO: Train Loss:0.150 | Acc:0.9620 | F1:0.8513\n",
      "2022-05-07 22:39:45,613 INFO: val Loss:0.234 | Acc:0.9485 | F1:0.7840\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:41:45,897 INFO: Epoch:[044/150]\n",
      "2022-05-07 22:41:45,898 INFO: Train Loss:0.155 | Acc:0.9553 | F1:0.8221\n",
      "2022-05-07 22:41:55,162 INFO: val Loss:0.156 | Acc:0.9649 | F1:0.7774\n",
      "2022-05-07 22:41:57,235 INFO: -----------------SAVE:44epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:43:57,841 INFO: Epoch:[045/150]\n",
      "2022-05-07 22:43:57,841 INFO: Train Loss:0.148 | Acc:0.9617 | F1:0.8392\n",
      "2022-05-07 22:44:07,141 INFO: val Loss:0.145 | Acc:0.9602 | F1:0.7778\n",
      "2022-05-07 22:44:08,966 INFO: -----------------SAVE:45epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-07 22:46:09,670 INFO: Epoch:[046/150]\n",
      "2022-05-07 22:46:09,671 INFO: Train Loss:0.143 | Acc:0.9620 | F1:0.8439\n",
      "2022-05-07 22:46:18,915 INFO: val Loss:0.183 | Acc:0.9579 | F1:0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-07 22:48:21,136 INFO: Epoch:[047/150]\n",
      "2022-05-07 22:48:21,137 INFO: Train Loss:0.140 | Acc:0.9638 | F1:0.8511\n",
      "2022-05-07 22:48:30,506 INFO: val Loss:0.133 | Acc:0.9696 | F1:0.8233\n",
      "2022-05-07 22:48:32,514 INFO: -----------------SAVE:47epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.76it/s]\n",
      "2022-05-07 22:50:33,844 INFO: Epoch:[048/150]\n",
      "2022-05-07 22:50:33,845 INFO: Train Loss:0.140 | Acc:0.9649 | F1:0.8621\n",
      "2022-05-07 22:50:43,108 INFO: val Loss:0.186 | Acc:0.9567 | F1:0.7555\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.77it/s]\n",
      "2022-05-07 22:52:44,144 INFO: Epoch:[049/150]\n",
      "2022-05-07 22:52:44,144 INFO: Train Loss:0.129 | Acc:0.9673 | F1:0.8713\n",
      "2022-05-07 22:52:53,404 INFO: val Loss:0.135 | Acc:0.9626 | F1:0.7995\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:54:53,662 INFO: Epoch:[050/150]\n",
      "2022-05-07 22:54:53,663 INFO: Train Loss:0.121 | Acc:0.9658 | F1:0.8782\n",
      "2022-05-07 22:55:02,982 INFO: val Loss:0.256 | Acc:0.9532 | F1:0.7446\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:57:03,321 INFO: Epoch:[051/150]\n",
      "2022-05-07 22:57:03,322 INFO: Train Loss:0.133 | Acc:0.9673 | F1:0.8608\n",
      "2022-05-07 22:57:12,571 INFO: val Loss:0.344 | Acc:0.9251 | F1:0.7658\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 22:59:13,123 INFO: Epoch:[052/150]\n",
      "2022-05-07 22:59:13,123 INFO: Train Loss:0.115 | Acc:0.9661 | F1:0.8576\n",
      "2022-05-07 22:59:22,419 INFO: val Loss:0.149 | Acc:0.9626 | F1:0.7928\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 23:01:22,975 INFO: Epoch:[053/150]\n",
      "2022-05-07 23:01:22,976 INFO: Train Loss:0.125 | Acc:0.9643 | F1:0.8622\n",
      "2022-05-07 23:01:32,268 INFO: val Loss:0.185 | Acc:0.9637 | F1:0.8039\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:07<00:00,  1.68it/s]\n",
      "2022-05-07 23:03:39,486 INFO: Epoch:[054/150]\n",
      "2022-05-07 23:03:39,486 INFO: Train Loss:0.113 | Acc:0.9690 | F1:0.8876\n",
      "2022-05-07 23:03:48,733 INFO: val Loss:0.168 | Acc:0.9614 | F1:0.8005\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 23:05:49,007 INFO: Epoch:[055/150]\n",
      "2022-05-07 23:05:49,008 INFO: Train Loss:0.104 | Acc:0.9705 | F1:0.8790\n",
      "2022-05-07 23:05:58,306 INFO: val Loss:0.190 | Acc:0.9626 | F1:0.7769\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-07 23:07:58,666 INFO: Epoch:[056/150]\n",
      "2022-05-07 23:07:58,666 INFO: Train Loss:0.129 | Acc:0.9661 | F1:0.8691\n",
      "2022-05-07 23:08:07,962 INFO: val Loss:0.132 | Acc:0.9696 | F1:0.8607\n",
      "2022-05-07 23:08:09,811 INFO: -----------------SAVE:56epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-07 23:10:11,859 INFO: Epoch:[057/150]\n",
      "2022-05-07 23:10:11,860 INFO: Train Loss:0.112 | Acc:0.9679 | F1:0.8862\n",
      "2022-05-07 23:10:21,379 INFO: val Loss:0.150 | Acc:0.9661 | F1:0.8160\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-07 23:12:23,787 INFO: Epoch:[058/150]\n",
      "2022-05-07 23:12:23,788 INFO: Train Loss:0.092 | Acc:0.9752 | F1:0.9010\n",
      "2022-05-07 23:12:33,021 INFO: val Loss:0.178 | Acc:0.9614 | F1:0.7922\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 23:14:32,810 INFO: Epoch:[059/150]\n",
      "2022-05-07 23:14:32,811 INFO: Train Loss:0.109 | Acc:0.9734 | F1:0.8926\n",
      "2022-05-07 23:14:42,038 INFO: val Loss:0.137 | Acc:0.9696 | F1:0.8246\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 23:16:41,742 INFO: Epoch:[060/150]\n",
      "2022-05-07 23:16:41,743 INFO: Train Loss:0.107 | Acc:0.9717 | F1:0.8956\n",
      "2022-05-07 23:16:50,943 INFO: val Loss:0.160 | Acc:0.9637 | F1:0.7870\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.78it/s]\n",
      "2022-05-07 23:18:50,911 INFO: Epoch:[061/150]\n",
      "2022-05-07 23:18:50,911 INFO: Train Loss:0.099 | Acc:0.9760 | F1:0.9043\n",
      "2022-05-07 23:19:00,121 INFO: val Loss:0.162 | Acc:0.9649 | F1:0.7930\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-07 23:20:59,955 INFO: Epoch:[062/150]\n",
      "2022-05-07 23:20:59,955 INFO: Train Loss:0.104 | Acc:0.9743 | F1:0.8976\n",
      "2022-05-07 23:21:09,282 INFO: val Loss:0.231 | Acc:0.9415 | F1:0.8071\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:06<00:00,  1.69it/s]\n",
      "2022-05-07 23:23:15,596 INFO: Epoch:[063/150]\n",
      "2022-05-07 23:23:15,597 INFO: Train Loss:0.106 | Acc:0.9714 | F1:0.8878\n",
      "2022-05-07 23:23:24,985 INFO: val Loss:0.144 | Acc:0.9673 | F1:0.8466\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.63it/s]\n",
      "2022-05-07 23:25:36,309 INFO: Epoch:[064/150]\n",
      "2022-05-07 23:25:36,309 INFO: Train Loss:0.097 | Acc:0.9763 | F1:0.9069\n",
      "2022-05-07 23:25:46,305 INFO: val Loss:0.151 | Acc:0.9708 | F1:0.8449\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-07 23:27:56,446 INFO: Epoch:[065/150]\n",
      "2022-05-07 23:27:56,447 INFO: Train Loss:0.088 | Acc:0.9760 | F1:0.9056\n",
      "2022-05-07 23:28:06,610 INFO: val Loss:0.196 | Acc:0.9602 | F1:0.7799\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-07 23:30:16,176 INFO: Epoch:[066/150]\n",
      "2022-05-07 23:30:16,177 INFO: Train Loss:0.095 | Acc:0.9719 | F1:0.8965\n",
      "2022-05-07 23:30:26,156 INFO: val Loss:0.139 | Acc:0.9684 | F1:0.8361\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-07 23:32:34,934 INFO: Epoch:[067/150]\n",
      "2022-05-07 23:32:34,935 INFO: Train Loss:0.095 | Acc:0.9734 | F1:0.9108\n",
      "2022-05-07 23:32:44,992 INFO: val Loss:0.193 | Acc:0.9591 | F1:0.7656\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-07 23:34:55,814 INFO: Epoch:[068/150]\n",
      "2022-05-07 23:34:55,814 INFO: Train Loss:0.089 | Acc:0.9772 | F1:0.9190\n",
      "2022-05-07 23:35:05,929 INFO: val Loss:0.141 | Acc:0.9661 | F1:0.8280\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-07 23:37:15,138 INFO: Epoch:[069/150]\n",
      "2022-05-07 23:37:15,139 INFO: Train Loss:0.103 | Acc:0.9731 | F1:0.8955\n",
      "2022-05-07 23:37:25,232 INFO: val Loss:0.162 | Acc:0.9614 | F1:0.7834\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-07 23:39:35,554 INFO: Epoch:[070/150]\n",
      "2022-05-07 23:39:35,554 INFO: Train Loss:0.081 | Acc:0.9790 | F1:0.9113\n",
      "2022-05-07 23:39:46,721 INFO: val Loss:0.128 | Acc:0.9673 | F1:0.8348\n",
      "2022-05-07 23:39:48,687 INFO: -----------------SAVE:70epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.62it/s]\n",
      "2022-05-07 23:42:00,694 INFO: Epoch:[071/150]\n",
      "2022-05-07 23:42:00,694 INFO: Train Loss:0.078 | Acc:0.9801 | F1:0.9293\n",
      "2022-05-07 23:42:10,989 INFO: val Loss:0.142 | Acc:0.9673 | F1:0.8457\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-07 23:44:20,738 INFO: Epoch:[072/150]\n",
      "2022-05-07 23:44:20,738 INFO: Train Loss:0.084 | Acc:0.9787 | F1:0.9249\n",
      "2022-05-07 23:44:31,612 INFO: val Loss:0.154 | Acc:0.9626 | F1:0.8328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.63it/s]\n",
      "2022-05-07 23:46:42,528 INFO: Epoch:[073/150]\n",
      "2022-05-07 23:46:42,529 INFO: Train Loss:0.075 | Acc:0.9798 | F1:0.9272\n",
      "2022-05-07 23:46:52,527 INFO: val Loss:0.164 | Acc:0.9591 | F1:0.8119\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:12<00:00,  1.62it/s]\n",
      "2022-05-07 23:49:04,751 INFO: Epoch:[074/150]\n",
      "2022-05-07 23:49:04,752 INFO: Train Loss:0.079 | Acc:0.9807 | F1:0.9291\n",
      "2022-05-07 23:49:14,798 INFO: val Loss:0.161 | Acc:0.9626 | F1:0.8135\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:14<00:00,  1.59it/s]\n",
      "2022-05-07 23:51:29,381 INFO: Epoch:[075/150]\n",
      "2022-05-07 23:51:29,382 INFO: Train Loss:0.087 | Acc:0.9784 | F1:0.9237\n",
      "2022-05-07 23:51:39,403 INFO: val Loss:0.176 | Acc:0.9626 | F1:0.8282\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.63it/s]\n",
      "2022-05-07 23:53:50,430 INFO: Epoch:[076/150]\n",
      "2022-05-07 23:53:50,431 INFO: Train Loss:0.071 | Acc:0.9798 | F1:0.9296\n",
      "2022-05-07 23:54:00,466 INFO: val Loss:0.192 | Acc:0.9614 | F1:0.8038\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-07 23:56:10,421 INFO: Epoch:[077/150]\n",
      "2022-05-07 23:56:10,422 INFO: Train Loss:0.079 | Acc:0.9784 | F1:0.9164\n",
      "2022-05-07 23:56:20,384 INFO: val Loss:0.132 | Acc:0.9708 | F1:0.8724\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-07 23:58:29,360 INFO: Epoch:[078/150]\n",
      "2022-05-07 23:58:29,361 INFO: Train Loss:0.078 | Acc:0.9798 | F1:0.9297\n",
      "2022-05-07 23:58:39,375 INFO: val Loss:0.207 | Acc:0.9602 | F1:0.8233\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-08 00:00:48,673 INFO: Epoch:[079/150]\n",
      "2022-05-08 00:00:48,673 INFO: Train Loss:0.074 | Acc:0.9801 | F1:0.9319\n",
      "2022-05-08 00:00:58,704 INFO: val Loss:0.371 | Acc:0.9275 | F1:0.8248\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 00:03:08,050 INFO: Epoch:[080/150]\n",
      "2022-05-08 00:03:08,051 INFO: Train Loss:0.080 | Acc:0.9801 | F1:0.9315\n",
      "2022-05-08 00:03:18,167 INFO: val Loss:0.195 | Acc:0.9661 | F1:0.8215\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 00:05:27,540 INFO: Epoch:[081/150]\n",
      "2022-05-08 00:05:27,541 INFO: Train Loss:0.067 | Acc:0.9845 | F1:0.9413\n",
      "2022-05-08 00:05:37,540 INFO: val Loss:0.128 | Acc:0.9754 | F1:0.8627\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-08 00:07:47,649 INFO: Epoch:[082/150]\n",
      "2022-05-08 00:07:47,650 INFO: Train Loss:0.080 | Acc:0.9798 | F1:0.9306\n",
      "2022-05-08 00:07:57,825 INFO: val Loss:0.150 | Acc:0.9719 | F1:0.8578\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 00:10:07,785 INFO: Epoch:[083/150]\n",
      "2022-05-08 00:10:07,785 INFO: Train Loss:0.055 | Acc:0.9851 | F1:0.9464\n",
      "2022-05-08 00:10:17,831 INFO: val Loss:0.155 | Acc:0.9602 | F1:0.7877\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-08 00:12:27,055 INFO: Epoch:[084/150]\n",
      "2022-05-08 00:12:27,055 INFO: Train Loss:0.059 | Acc:0.9860 | F1:0.9478\n",
      "2022-05-08 00:12:37,051 INFO: val Loss:0.165 | Acc:0.9649 | F1:0.8142\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:07<00:00,  1.68it/s]\n",
      "2022-05-08 00:14:44,815 INFO: Epoch:[085/150]\n",
      "2022-05-08 00:14:44,815 INFO: Train Loss:0.057 | Acc:0.9831 | F1:0.9367\n",
      "2022-05-08 00:14:54,096 INFO: val Loss:0.164 | Acc:0.9626 | F1:0.8056\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 00:16:56,817 INFO: Epoch:[086/150]\n",
      "2022-05-08 00:16:56,817 INFO: Train Loss:0.060 | Acc:0.9833 | F1:0.9482\n",
      "2022-05-08 00:17:06,207 INFO: val Loss:0.121 | Acc:0.9673 | F1:0.8168\n",
      "2022-05-08 00:17:08,142 INFO: -----------------SAVE:86epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 00:19:10,893 INFO: Epoch:[087/150]\n",
      "2022-05-08 00:19:10,893 INFO: Train Loss:0.056 | Acc:0.9860 | F1:0.9547\n",
      "2022-05-08 00:19:20,253 INFO: val Loss:0.150 | Acc:0.9719 | F1:0.8440\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:07<00:00,  1.68it/s]\n",
      "2022-05-08 00:21:27,422 INFO: Epoch:[088/150]\n",
      "2022-05-08 00:21:27,423 INFO: Train Loss:0.062 | Acc:0.9833 | F1:0.9393\n",
      "2022-05-08 00:21:37,335 INFO: val Loss:0.139 | Acc:0.9673 | F1:0.8194\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-08 00:23:46,113 INFO: Epoch:[089/150]\n",
      "2022-05-08 00:23:46,113 INFO: Train Loss:0.057 | Acc:0.9857 | F1:0.9481\n",
      "2022-05-08 00:23:56,018 INFO: val Loss:0.167 | Acc:0.9544 | F1:0.8366\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-08 00:26:05,312 INFO: Epoch:[090/150]\n",
      "2022-05-08 00:26:05,312 INFO: Train Loss:0.053 | Acc:0.9845 | F1:0.9417\n",
      "2022-05-08 00:26:15,356 INFO: val Loss:0.259 | Acc:0.9357 | F1:0.8067\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-08 00:28:25,790 INFO: Epoch:[091/150]\n",
      "2022-05-08 00:28:25,791 INFO: Train Loss:0.051 | Acc:0.9836 | F1:0.9436\n",
      "2022-05-08 00:28:35,646 INFO: val Loss:0.173 | Acc:0.9661 | F1:0.8143\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 00:30:45,527 INFO: Epoch:[092/150]\n",
      "2022-05-08 00:30:45,528 INFO: Train Loss:0.051 | Acc:0.9866 | F1:0.9536\n",
      "2022-05-08 00:30:56,421 INFO: val Loss:0.164 | Acc:0.9661 | F1:0.8206\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:16<00:00,  1.56it/s]\n",
      "2022-05-08 00:33:13,202 INFO: Epoch:[093/150]\n",
      "2022-05-08 00:33:13,202 INFO: Train Loss:0.043 | Acc:0.9892 | F1:0.9603\n",
      "2022-05-08 00:33:26,232 INFO: val Loss:0.202 | Acc:0.9673 | F1:0.8143\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:15<00:00,  1.58it/s]\n",
      "2022-05-08 00:35:41,619 INFO: Epoch:[094/150]\n",
      "2022-05-08 00:35:41,620 INFO: Train Loss:0.057 | Acc:0.9854 | F1:0.9461\n",
      "2022-05-08 00:35:52,759 INFO: val Loss:0.205 | Acc:0.9626 | F1:0.7996\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.63it/s]\n",
      "2022-05-08 00:38:03,989 INFO: Epoch:[095/150]\n",
      "2022-05-08 00:38:03,989 INFO: Train Loss:0.049 | Acc:0.9860 | F1:0.9494\n",
      "2022-05-08 00:38:14,280 INFO: val Loss:0.153 | Acc:0.9673 | F1:0.8354\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:13<00:00,  1.61it/s]\n",
      "2022-05-08 00:40:27,497 INFO: Epoch:[096/150]\n",
      "2022-05-08 00:40:27,497 INFO: Train Loss:0.050 | Acc:0.9874 | F1:0.9586\n",
      "2022-05-08 00:40:37,638 INFO: val Loss:0.156 | Acc:0.9661 | F1:0.8500\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:16<00:00,  1.57it/s]\n",
      "2022-05-08 00:42:53,897 INFO: Epoch:[097/150]\n",
      "2022-05-08 00:42:53,897 INFO: Train Loss:0.036 | Acc:0.9918 | F1:0.9667\n",
      "2022-05-08 00:43:03,906 INFO: val Loss:0.128 | Acc:0.9731 | F1:0.8373\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.67it/s]\n",
      "2022-05-08 00:45:12,261 INFO: Epoch:[098/150]\n",
      "2022-05-08 00:45:12,262 INFO: Train Loss:0.046 | Acc:0.9871 | F1:0.9480\n",
      "2022-05-08 00:45:22,205 INFO: val Loss:0.161 | Acc:0.9626 | F1:0.8230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:07<00:00,  1.68it/s]\n",
      "2022-05-08 00:47:29,636 INFO: Epoch:[099/150]\n",
      "2022-05-08 00:47:29,636 INFO: Train Loss:0.036 | Acc:0.9898 | F1:0.9629\n",
      "2022-05-08 00:47:39,258 INFO: val Loss:0.177 | Acc:0.9661 | F1:0.8482\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:12<00:00,  1.61it/s]\n",
      "2022-05-08 00:49:51,863 INFO: Epoch:[100/150]\n",
      "2022-05-08 00:49:51,864 INFO: Train Loss:0.040 | Acc:0.9892 | F1:0.9514\n",
      "2022-05-08 00:50:02,051 INFO: val Loss:0.163 | Acc:0.9614 | F1:0.8165\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 00:52:11,598 INFO: Epoch:[101/150]\n",
      "2022-05-08 00:52:11,598 INFO: Train Loss:0.044 | Acc:0.9895 | F1:0.9658\n",
      "2022-05-08 00:52:22,212 INFO: val Loss:0.169 | Acc:0.9626 | F1:0.8131\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.73it/s]\n",
      "2022-05-08 00:54:25,854 INFO: Epoch:[102/150]\n",
      "2022-05-08 00:54:25,855 INFO: Train Loss:0.042 | Acc:0.9895 | F1:0.9602\n",
      "2022-05-08 00:54:35,124 INFO: val Loss:0.129 | Acc:0.9731 | F1:0.8708\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:13<00:00,  1.61it/s]\n",
      "2022-05-08 00:56:48,277 INFO: Epoch:[103/150]\n",
      "2022-05-08 00:56:48,277 INFO: Train Loss:0.032 | Acc:0.9924 | F1:0.9719\n",
      "2022-05-08 00:56:59,726 INFO: val Loss:0.137 | Acc:0.9731 | F1:0.8503\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:21<00:00,  1.51it/s]\n",
      "2022-05-08 00:59:21,015 INFO: Epoch:[104/150]\n",
      "2022-05-08 00:59:21,015 INFO: Train Loss:0.032 | Acc:0.9915 | F1:0.9751\n",
      "2022-05-08 00:59:32,471 INFO: val Loss:0.135 | Acc:0.9719 | F1:0.8611\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:22<00:00,  1.50it/s]\n",
      "2022-05-08 01:01:55,002 INFO: Epoch:[105/150]\n",
      "2022-05-08 01:01:55,003 INFO: Train Loss:0.030 | Acc:0.9921 | F1:0.9705\n",
      "2022-05-08 01:02:06,615 INFO: val Loss:0.125 | Acc:0.9696 | F1:0.8628\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:04<00:00,  1.72it/s]\n",
      "2022-05-08 01:04:10,786 INFO: Epoch:[106/150]\n",
      "2022-05-08 01:04:10,786 INFO: Train Loss:0.029 | Acc:0.9924 | F1:0.9738\n",
      "2022-05-08 01:04:20,081 INFO: val Loss:0.154 | Acc:0.9673 | F1:0.8319\n",
      "2022-05-08 01:04:20,082 INFO: \n",
      "Best Val Epoch:86 | Val Loss:0.1206 | Val Acc:0.9673 | Val F1:0.8168\n",
      "2022-05-08 01:04:20,082 INFO: Total Process time:238.471Minute\n",
      "2022-05-08 01:04:20,089 INFO: {'exp_num': '3', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_160', 'drop_path_rate': 0.2, 'img_size': 224, 'batch_size': 16, 'epochs': 150, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 20, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'fold': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Read train_df.csv\n",
      "Dataset size:3422\n",
      "Dataset size:855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 01:04:21,130 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "2022-05-08 01:04:21,523 INFO: Computational complexity:       15.93 GMac\n",
      "2022-05-08 01:04:21,524 INFO: Number of parameters:           80.83 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.75it/s]\n",
      "2022-05-08 01:06:23,516 INFO: Epoch:[001/150]\n",
      "2022-05-08 01:06:23,516 INFO: Train Loss:4.488 | Acc:0.0067 | F1:0.0021\n",
      "2022-05-08 01:06:32,789 INFO: val Loss:4.486 | Acc:0.0012 | F1:0.0003\n",
      "2022-05-08 01:06:34,532 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.73it/s]\n",
      "2022-05-08 01:08:38,126 INFO: Epoch:[002/150]\n",
      "2022-05-08 01:08:38,126 INFO: Train Loss:4.467 | Acc:0.0108 | F1:0.0027\n",
      "2022-05-08 01:08:47,567 INFO: val Loss:4.480 | Acc:0.0000 | F1:0.0000\n",
      "2022-05-08 01:08:49,608 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 01:10:52,495 INFO: Epoch:[003/150]\n",
      "2022-05-08 01:10:52,495 INFO: Train Loss:4.442 | Acc:0.0172 | F1:0.0041\n",
      "2022-05-08 01:11:02,030 INFO: val Loss:4.447 | Acc:0.0047 | F1:0.0009\n",
      "2022-05-08 01:11:03,907 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.74it/s]\n",
      "2022-05-08 01:13:07,086 INFO: Epoch:[004/150]\n",
      "2022-05-08 01:13:07,087 INFO: Train Loss:4.404 | Acc:0.0313 | F1:0.0101\n",
      "2022-05-08 01:13:16,417 INFO: val Loss:4.413 | Acc:0.0140 | F1:0.0033\n",
      "2022-05-08 01:13:19,060 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:15:21,412 INFO: Epoch:[005/150]\n",
      "2022-05-08 01:15:21,413 INFO: Train Loss:4.345 | Acc:0.0678 | F1:0.0145\n",
      "2022-05-08 01:15:30,790 INFO: val Loss:4.350 | Acc:0.0503 | F1:0.0096\n",
      "2022-05-08 01:15:32,756 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:17:35,333 INFO: Epoch:[006/150]\n",
      "2022-05-08 01:17:35,333 INFO: Train Loss:3.996 | Acc:0.3904 | F1:0.0777\n",
      "2022-05-08 01:17:44,684 INFO: val Loss:3.662 | Acc:0.6316 | F1:0.1157\n",
      "2022-05-08 01:17:46,576 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:19:48,981 INFO: Epoch:[007/150]\n",
      "2022-05-08 01:19:48,982 INFO: Train Loss:3.184 | Acc:0.7537 | F1:0.1366\n",
      "2022-05-08 01:19:58,315 INFO: val Loss:2.664 | Acc:0.8327 | F1:0.1466\n",
      "2022-05-08 01:20:00,291 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:22:02,875 INFO: Epoch:[008/150]\n",
      "2022-05-08 01:22:02,875 INFO: Train Loss:2.305 | Acc:0.8206 | F1:0.1465\n",
      "2022-05-08 01:22:13,311 INFO: val Loss:1.689 | Acc:0.8398 | F1:0.1510\n",
      "2022-05-08 01:22:15,202 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.76it/s]\n",
      "2022-05-08 01:24:17,112 INFO: Epoch:[009/150]\n",
      "2022-05-08 01:24:17,112 INFO: Train Loss:1.563 | Acc:0.8387 | F1:0.1526\n",
      "2022-05-08 01:24:26,407 INFO: val Loss:1.084 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-08 01:24:28,323 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:26:30,546 INFO: Epoch:[010/150]\n",
      "2022-05-08 01:26:30,546 INFO: Train Loss:1.191 | Acc:0.8428 | F1:0.1545\n",
      "2022-05-08 01:26:39,832 INFO: val Loss:0.970 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-08 01:26:41,811 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:28:44,222 INFO: Epoch:[011/150]\n",
      "2022-05-08 01:28:44,222 INFO: Train Loss:1.036 | Acc:0.8466 | F1:0.1557\n",
      "2022-05-08 01:28:53,542 INFO: val Loss:0.856 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-08 01:28:55,445 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:30:57,919 INFO: Epoch:[012/150]\n",
      "2022-05-08 01:30:57,919 INFO: Train Loss:0.919 | Acc:0.8477 | F1:0.1559\n",
      "2022-05-08 01:31:07,291 INFO: val Loss:0.750 | Acc:0.8480 | F1:0.1561\n",
      "2022-05-08 01:31:09,238 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:33:11,742 INFO: Epoch:[013/150]\n",
      "2022-05-08 01:33:11,743 INFO: Train Loss:0.824 | Acc:0.8475 | F1:0.1559\n",
      "2022-05-08 01:33:20,975 INFO: val Loss:0.690 | Acc:0.8503 | F1:0.1654\n",
      "2022-05-08 01:33:22,884 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:35:25,267 INFO: Epoch:[014/150]\n",
      "2022-05-08 01:35:25,267 INFO: Train Loss:0.747 | Acc:0.8489 | F1:0.1666\n",
      "2022-05-08 01:35:34,547 INFO: val Loss:0.614 | Acc:0.8596 | F1:0.2064\n",
      "2022-05-08 01:35:36,641 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:37:39,227 INFO: Epoch:[015/150]\n",
      "2022-05-08 01:37:39,228 INFO: Train Loss:0.671 | Acc:0.8556 | F1:0.2064\n",
      "2022-05-08 01:37:48,515 INFO: val Loss:0.539 | Acc:0.8713 | F1:0.2586\n",
      "2022-05-08 01:37:50,403 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:06<00:00,  1.69it/s]\n",
      "2022-05-08 01:39:57,259 INFO: Epoch:[016/150]\n",
      "2022-05-08 01:39:57,259 INFO: Train Loss:0.589 | Acc:0.8673 | F1:0.2775\n",
      "2022-05-08 01:40:09,791 INFO: val Loss:0.473 | Acc:0.8749 | F1:0.3036\n",
      "2022-05-08 01:40:11,769 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.63it/s]\n",
      "2022-05-08 01:42:23,198 INFO: Epoch:[017/150]\n",
      "2022-05-08 01:42:23,199 INFO: Train Loss:0.528 | Acc:0.8776 | F1:0.3362\n",
      "2022-05-08 01:42:32,504 INFO: val Loss:0.416 | Acc:0.8842 | F1:0.3518\n",
      "2022-05-08 01:42:34,407 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 01:44:37,182 INFO: Epoch:[018/150]\n",
      "2022-05-08 01:44:37,183 INFO: Train Loss:0.480 | Acc:0.8840 | F1:0.3842\n",
      "2022-05-08 01:44:46,433 INFO: val Loss:0.378 | Acc:0.9064 | F1:0.4507\n",
      "2022-05-08 01:44:48,420 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:46:50,722 INFO: Epoch:[019/150]\n",
      "2022-05-08 01:46:50,723 INFO: Train Loss:0.439 | Acc:0.8966 | F1:0.4638\n",
      "2022-05-08 01:47:00,034 INFO: val Loss:0.343 | Acc:0.9099 | F1:0.4932\n",
      "2022-05-08 01:47:02,052 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:49:04,598 INFO: Epoch:[020/150]\n",
      "2022-05-08 01:49:04,599 INFO: Train Loss:0.385 | Acc:0.9030 | F1:0.4882\n",
      "2022-05-08 01:49:13,893 INFO: val Loss:0.347 | Acc:0.9123 | F1:0.5276\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:51:16,160 INFO: Epoch:[021/150]\n",
      "2022-05-08 01:51:16,160 INFO: Train Loss:0.372 | Acc:0.9056 | F1:0.5154\n",
      "2022-05-08 01:51:25,460 INFO: val Loss:0.355 | Acc:0.9076 | F1:0.5047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.74it/s]\n",
      "2022-05-08 01:53:28,597 INFO: Epoch:[022/150]\n",
      "2022-05-08 01:53:28,597 INFO: Train Loss:0.346 | Acc:0.9097 | F1:0.5377\n",
      "2022-05-08 01:53:37,877 INFO: val Loss:0.306 | Acc:0.9099 | F1:0.5423\n",
      "2022-05-08 01:53:39,848 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:55:42,247 INFO: Epoch:[023/150]\n",
      "2022-05-08 01:55:42,247 INFO: Train Loss:0.300 | Acc:0.9158 | F1:0.5900\n",
      "2022-05-08 01:55:51,491 INFO: val Loss:0.282 | Acc:0.9275 | F1:0.6071\n",
      "2022-05-08 01:55:53,484 INFO: -----------------SAVE:23epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 01:57:55,631 INFO: Epoch:[024/150]\n",
      "2022-05-08 01:57:55,632 INFO: Train Loss:0.289 | Acc:0.9246 | F1:0.6320\n",
      "2022-05-08 01:58:04,967 INFO: val Loss:0.233 | Acc:0.9228 | F1:0.6024\n",
      "2022-05-08 01:58:06,865 INFO: -----------------SAVE:24epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:00:09,338 INFO: Epoch:[025/150]\n",
      "2022-05-08 02:00:09,338 INFO: Train Loss:0.255 | Acc:0.9296 | F1:0.6509\n",
      "2022-05-08 02:00:18,590 INFO: val Loss:0.239 | Acc:0.9333 | F1:0.6191\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:02:21,019 INFO: Epoch:[026/150]\n",
      "2022-05-08 02:02:21,019 INFO: Train Loss:0.244 | Acc:0.9351 | F1:0.6987\n",
      "2022-05-08 02:02:30,306 INFO: val Loss:0.274 | Acc:0.9263 | F1:0.5644\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.74it/s]\n",
      "2022-05-08 02:04:33,397 INFO: Epoch:[027/150]\n",
      "2022-05-08 02:04:33,398 INFO: Train Loss:0.245 | Acc:0.9351 | F1:0.6961\n",
      "2022-05-08 02:04:42,720 INFO: val Loss:0.289 | Acc:0.9193 | F1:0.5866\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.73it/s]\n",
      "2022-05-08 02:06:46,080 INFO: Epoch:[028/150]\n",
      "2022-05-08 02:06:46,080 INFO: Train Loss:0.232 | Acc:0.9342 | F1:0.7139\n",
      "2022-05-08 02:06:55,514 INFO: val Loss:0.250 | Acc:0.9380 | F1:0.6815\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.74it/s]\n",
      "2022-05-08 02:08:58,649 INFO: Epoch:[029/150]\n",
      "2022-05-08 02:08:58,650 INFO: Train Loss:0.222 | Acc:0.9398 | F1:0.7212\n",
      "2022-05-08 02:09:07,978 INFO: val Loss:0.210 | Acc:0.9404 | F1:0.6824\n",
      "2022-05-08 02:09:09,889 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:11:12,282 INFO: Epoch:[030/150]\n",
      "2022-05-08 02:11:12,282 INFO: Train Loss:0.217 | Acc:0.9439 | F1:0.7516\n",
      "2022-05-08 02:11:21,580 INFO: val Loss:0.204 | Acc:0.9450 | F1:0.6824\n",
      "2022-05-08 02:11:23,473 INFO: -----------------SAVE:30epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 02:13:26,299 INFO: Epoch:[031/150]\n",
      "2022-05-08 02:13:26,300 INFO: Train Loss:0.199 | Acc:0.9468 | F1:0.7713\n",
      "2022-05-08 02:13:35,686 INFO: val Loss:0.207 | Acc:0.9439 | F1:0.7063\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:15:38,208 INFO: Epoch:[032/150]\n",
      "2022-05-08 02:15:38,208 INFO: Train Loss:0.206 | Acc:0.9459 | F1:0.7620\n",
      "2022-05-08 02:15:47,512 INFO: val Loss:0.242 | Acc:0.9368 | F1:0.6570\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.76it/s]\n",
      "2022-05-08 02:17:49,378 INFO: Epoch:[033/150]\n",
      "2022-05-08 02:17:49,378 INFO: Train Loss:0.207 | Acc:0.9439 | F1:0.7506\n",
      "2022-05-08 02:17:58,672 INFO: val Loss:0.184 | Acc:0.9520 | F1:0.7333\n",
      "2022-05-08 02:18:00,763 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:20:03,096 INFO: Epoch:[034/150]\n",
      "2022-05-08 02:20:03,096 INFO: Train Loss:0.190 | Acc:0.9483 | F1:0.7695\n",
      "2022-05-08 02:20:12,359 INFO: val Loss:0.188 | Acc:0.9450 | F1:0.6936\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:22:14,595 INFO: Epoch:[035/150]\n",
      "2022-05-08 02:22:14,595 INFO: Train Loss:0.167 | Acc:0.9559 | F1:0.8161\n",
      "2022-05-08 02:22:23,975 INFO: val Loss:0.238 | Acc:0.9439 | F1:0.7325\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:24:26,064 INFO: Epoch:[036/150]\n",
      "2022-05-08 02:24:26,064 INFO: Train Loss:0.190 | Acc:0.9494 | F1:0.7774\n",
      "2022-05-08 02:24:35,330 INFO: val Loss:0.206 | Acc:0.9427 | F1:0.6955\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:26:37,858 INFO: Epoch:[037/150]\n",
      "2022-05-08 02:26:37,858 INFO: Train Loss:0.173 | Acc:0.9512 | F1:0.7909\n",
      "2022-05-08 02:26:47,102 INFO: val Loss:0.229 | Acc:0.9485 | F1:0.7030\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:28:49,156 INFO: Epoch:[038/150]\n",
      "2022-05-08 02:28:49,156 INFO: Train Loss:0.185 | Acc:0.9497 | F1:0.7964\n",
      "2022-05-08 02:28:58,422 INFO: val Loss:0.180 | Acc:0.9544 | F1:0.7646\n",
      "2022-05-08 02:29:00,607 INFO: -----------------SAVE:38epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 02:31:03,337 INFO: Epoch:[039/150]\n",
      "2022-05-08 02:31:03,337 INFO: Train Loss:0.149 | Acc:0.9594 | F1:0.8353\n",
      "2022-05-08 02:31:12,605 INFO: val Loss:0.225 | Acc:0.9368 | F1:0.6633\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:33:15,021 INFO: Epoch:[040/150]\n",
      "2022-05-08 02:33:15,021 INFO: Train Loss:0.153 | Acc:0.9573 | F1:0.8256\n",
      "2022-05-08 02:33:24,256 INFO: val Loss:0.169 | Acc:0.9591 | F1:0.7762\n",
      "2022-05-08 02:33:26,469 INFO: -----------------SAVE:40epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 02:35:29,011 INFO: Epoch:[041/150]\n",
      "2022-05-08 02:35:29,011 INFO: Train Loss:0.155 | Acc:0.9550 | F1:0.8195\n",
      "2022-05-08 02:35:38,224 INFO: val Loss:0.188 | Acc:0.9614 | F1:0.8207\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 02:37:41,043 INFO: Epoch:[042/150]\n",
      "2022-05-08 02:37:41,043 INFO: Train Loss:0.164 | Acc:0.9579 | F1:0.8309\n",
      "2022-05-08 02:37:50,323 INFO: val Loss:0.186 | Acc:0.9532 | F1:0.7529\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.73it/s]\n",
      "2022-05-08 02:39:53,963 INFO: Epoch:[043/150]\n",
      "2022-05-08 02:39:53,963 INFO: Train Loss:0.128 | Acc:0.9626 | F1:0.8564\n",
      "2022-05-08 02:40:04,603 INFO: val Loss:0.204 | Acc:0.9579 | F1:0.7837\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-08 02:42:13,843 INFO: Epoch:[044/150]\n",
      "2022-05-08 02:42:13,844 INFO: Train Loss:0.135 | Acc:0.9641 | F1:0.8508\n",
      "2022-05-08 02:42:23,861 INFO: val Loss:0.162 | Acc:0.9591 | F1:0.7993\n",
      "2022-05-08 02:42:25,787 INFO: -----------------SAVE:44epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.62it/s]\n",
      "2022-05-08 02:44:37,731 INFO: Epoch:[045/150]\n",
      "2022-05-08 02:44:37,731 INFO: Train Loss:0.136 | Acc:0.9626 | F1:0.8546\n",
      "2022-05-08 02:44:49,046 INFO: val Loss:0.216 | Acc:0.9497 | F1:0.7577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:21<00:00,  1.51it/s]\n",
      "2022-05-08 02:47:10,674 INFO: Epoch:[046/150]\n",
      "2022-05-08 02:47:10,674 INFO: Train Loss:0.133 | Acc:0.9641 | F1:0.8620\n",
      "2022-05-08 02:47:21,915 INFO: val Loss:0.197 | Acc:0.9485 | F1:0.7109\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:18<00:00,  1.54it/s]\n",
      "2022-05-08 02:49:40,822 INFO: Epoch:[047/150]\n",
      "2022-05-08 02:49:40,823 INFO: Train Loss:0.127 | Acc:0.9638 | F1:0.8481\n",
      "2022-05-08 02:49:51,051 INFO: val Loss:0.181 | Acc:0.9532 | F1:0.7417\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.73it/s]\n",
      "2022-05-08 02:51:54,555 INFO: Epoch:[048/150]\n",
      "2022-05-08 02:51:54,556 INFO: Train Loss:0.149 | Acc:0.9594 | F1:0.8385\n",
      "2022-05-08 02:52:03,926 INFO: val Loss:0.163 | Acc:0.9544 | F1:0.7770\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:05<00:00,  1.70it/s]\n",
      "2022-05-08 02:54:09,725 INFO: Epoch:[049/150]\n",
      "2022-05-08 02:54:09,726 INFO: Train Loss:0.120 | Acc:0.9679 | F1:0.8667\n",
      "2022-05-08 02:54:19,917 INFO: val Loss:0.155 | Acc:0.9637 | F1:0.8037\n",
      "2022-05-08 02:54:21,902 INFO: -----------------SAVE:49epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 02:56:31,376 INFO: Epoch:[050/150]\n",
      "2022-05-08 02:56:31,376 INFO: Train Loss:0.130 | Acc:0.9676 | F1:0.8655\n",
      "2022-05-08 02:56:41,392 INFO: val Loss:0.163 | Acc:0.9591 | F1:0.7921\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-08 02:58:50,438 INFO: Epoch:[051/150]\n",
      "2022-05-08 02:58:50,438 INFO: Train Loss:0.125 | Acc:0.9664 | F1:0.8618\n",
      "2022-05-08 02:59:00,424 INFO: val Loss:0.158 | Acc:0.9602 | F1:0.7944\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-08 03:01:09,419 INFO: Epoch:[052/150]\n",
      "2022-05-08 03:01:09,420 INFO: Train Loss:0.116 | Acc:0.9679 | F1:0.8736\n",
      "2022-05-08 03:01:19,529 INFO: val Loss:0.212 | Acc:0.9579 | F1:0.7699\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 03:03:28,985 INFO: Epoch:[053/150]\n",
      "2022-05-08 03:03:28,986 INFO: Train Loss:0.114 | Acc:0.9679 | F1:0.8825\n",
      "2022-05-08 03:03:39,238 INFO: val Loss:0.158 | Acc:0.9637 | F1:0.8160\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 03:05:48,767 INFO: Epoch:[054/150]\n",
      "2022-05-08 03:05:48,768 INFO: Train Loss:0.103 | Acc:0.9717 | F1:0.8824\n",
      "2022-05-08 03:05:58,770 INFO: val Loss:0.154 | Acc:0.9626 | F1:0.7939\n",
      "2022-05-08 03:06:00,717 INFO: -----------------SAVE:54epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:13<00:00,  1.60it/s]\n",
      "2022-05-08 03:08:14,128 INFO: Epoch:[055/150]\n",
      "2022-05-08 03:08:14,129 INFO: Train Loss:0.111 | Acc:0.9711 | F1:0.8923\n",
      "2022-05-08 03:08:24,220 INFO: val Loss:0.250 | Acc:0.9509 | F1:0.7221\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:17<00:00,  1.56it/s]\n",
      "2022-05-08 03:10:41,580 INFO: Epoch:[056/150]\n",
      "2022-05-08 03:10:41,581 INFO: Train Loss:0.107 | Acc:0.9722 | F1:0.8868\n",
      "2022-05-08 03:10:54,054 INFO: val Loss:0.231 | Acc:0.9579 | F1:0.7578\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:12<00:00,  1.61it/s]\n",
      "2022-05-08 03:13:07,004 INFO: Epoch:[057/150]\n",
      "2022-05-08 03:13:07,005 INFO: Train Loss:0.115 | Acc:0.9693 | F1:0.8820\n",
      "2022-05-08 03:13:18,352 INFO: val Loss:0.157 | Acc:0.9626 | F1:0.8113\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:18<00:00,  1.54it/s]\n",
      "2022-05-08 03:15:37,259 INFO: Epoch:[058/150]\n",
      "2022-05-08 03:15:37,259 INFO: Train Loss:0.137 | Acc:0.9649 | F1:0.8632\n",
      "2022-05-08 03:15:48,790 INFO: val Loss:0.194 | Acc:0.9567 | F1:0.7870\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-08 03:17:59,306 INFO: Epoch:[059/150]\n",
      "2022-05-08 03:17:59,307 INFO: Train Loss:0.096 | Acc:0.9757 | F1:0.9134\n",
      "2022-05-08 03:18:11,078 INFO: val Loss:0.197 | Acc:0.9532 | F1:0.7557\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:18<00:00,  1.55it/s]\n",
      "2022-05-08 03:20:29,432 INFO: Epoch:[060/150]\n",
      "2022-05-08 03:20:29,432 INFO: Train Loss:0.090 | Acc:0.9775 | F1:0.9024\n",
      "2022-05-08 03:20:39,436 INFO: val Loss:0.173 | Acc:0.9626 | F1:0.7950\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:17<00:00,  1.55it/s]\n",
      "2022-05-08 03:22:57,187 INFO: Epoch:[061/150]\n",
      "2022-05-08 03:22:57,187 INFO: Train Loss:0.110 | Acc:0.9696 | F1:0.8832\n",
      "2022-05-08 03:23:08,751 INFO: val Loss:0.179 | Acc:0.9579 | F1:0.7708\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:21<00:00,  1.52it/s]\n",
      "2022-05-08 03:25:29,982 INFO: Epoch:[062/150]\n",
      "2022-05-08 03:25:29,983 INFO: Train Loss:0.095 | Acc:0.9769 | F1:0.9104\n",
      "2022-05-08 03:25:41,191 INFO: val Loss:0.200 | Acc:0.9567 | F1:0.7852\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:19<00:00,  1.54it/s]\n",
      "2022-05-08 03:28:00,218 INFO: Epoch:[063/150]\n",
      "2022-05-08 03:28:00,218 INFO: Train Loss:0.078 | Acc:0.9784 | F1:0.9268\n",
      "2022-05-08 03:28:11,628 INFO: val Loss:0.170 | Acc:0.9602 | F1:0.8172\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:12<00:00,  1.61it/s]\n",
      "2022-05-08 03:30:24,198 INFO: Epoch:[064/150]\n",
      "2022-05-08 03:30:24,198 INFO: Train Loss:0.079 | Acc:0.9775 | F1:0.9124\n",
      "2022-05-08 03:30:34,421 INFO: val Loss:0.187 | Acc:0.9532 | F1:0.7817\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.66it/s]\n",
      "2022-05-08 03:32:43,472 INFO: Epoch:[065/150]\n",
      "2022-05-08 03:32:43,472 INFO: Train Loss:0.084 | Acc:0.9757 | F1:0.9068\n",
      "2022-05-08 03:32:53,480 INFO: val Loss:0.199 | Acc:0.9567 | F1:0.7955\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.67it/s]\n",
      "2022-05-08 03:35:01,898 INFO: Epoch:[066/150]\n",
      "2022-05-08 03:35:01,899 INFO: Train Loss:0.090 | Acc:0.9755 | F1:0.9105\n",
      "2022-05-08 03:35:11,905 INFO: val Loss:0.192 | Acc:0.9591 | F1:0.8118\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 03:37:21,823 INFO: Epoch:[067/150]\n",
      "2022-05-08 03:37:21,824 INFO: Train Loss:0.082 | Acc:0.9760 | F1:0.9172\n",
      "2022-05-08 03:37:31,794 INFO: val Loss:0.224 | Acc:0.9509 | F1:0.7587\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-08 03:39:40,631 INFO: Epoch:[068/150]\n",
      "2022-05-08 03:39:40,631 INFO: Train Loss:0.091 | Acc:0.9772 | F1:0.9219\n",
      "2022-05-08 03:39:50,629 INFO: val Loss:0.198 | Acc:0.9591 | F1:0.8082\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-08 03:41:59,392 INFO: Epoch:[069/150]\n",
      "2022-05-08 03:41:59,392 INFO: Train Loss:0.072 | Acc:0.9757 | F1:0.9139\n",
      "2022-05-08 03:42:09,486 INFO: val Loss:0.165 | Acc:0.9649 | F1:0.8230\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:08<00:00,  1.66it/s]\n",
      "2022-05-08 03:44:18,391 INFO: Epoch:[070/150]\n",
      "2022-05-08 03:44:18,392 INFO: Train Loss:0.079 | Acc:0.9801 | F1:0.9214\n",
      "2022-05-08 03:44:28,306 INFO: val Loss:0.204 | Acc:0.9532 | F1:0.7644\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 03:46:31,110 INFO: Epoch:[071/150]\n",
      "2022-05-08 03:46:31,110 INFO: Train Loss:0.083 | Acc:0.9766 | F1:0.9205\n",
      "2022-05-08 03:46:40,381 INFO: val Loss:0.195 | Acc:0.9556 | F1:0.7544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:06<00:00,  1.69it/s]\n",
      "2022-05-08 03:48:47,117 INFO: Epoch:[072/150]\n",
      "2022-05-08 03:48:47,117 INFO: Train Loss:0.071 | Acc:0.9839 | F1:0.9463\n",
      "2022-05-08 03:48:57,066 INFO: val Loss:0.237 | Acc:0.9462 | F1:0.8048\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:11<00:00,  1.63it/s]\n",
      "2022-05-08 03:51:08,155 INFO: Epoch:[073/150]\n",
      "2022-05-08 03:51:08,155 INFO: Train Loss:0.082 | Acc:0.9795 | F1:0.9311\n",
      "2022-05-08 03:51:18,381 INFO: val Loss:0.161 | Acc:0.9626 | F1:0.7938\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:05<00:00,  1.70it/s]\n",
      "2022-05-08 03:53:24,208 INFO: Epoch:[074/150]\n",
      "2022-05-08 03:53:24,209 INFO: Train Loss:0.069 | Acc:0.9804 | F1:0.9177\n",
      "2022-05-08 03:53:33,121 INFO: val Loss:0.212 | Acc:0.9591 | F1:0.8119\n",
      "2022-05-08 03:53:33,122 INFO: \n",
      "Best Val Epoch:54 | Val Loss:0.1535 | Val Acc:0.9626 | Val F1:0.7939\n",
      "2022-05-08 03:53:33,122 INFO: Total Process time:169.193Minute\n",
      "2022-05-08 03:53:33,124 INFO: {'exp_num': '4', 'data_path': './data', 'Kfold': 5, 'model_path': 'results/', 'encoder_name': 'regnety_160', 'drop_path_rate': 0.2, 'img_size': 224, 'batch_size': 16, 'epochs': 150, 'optimizer': 'Lamb', 'initial_lr': 5e-06, 'weight_decay': 0.001, 'aug_ver': 2, 'scheduler': 'cycle', 'warm_epoch': 5, 'max_lr': 0.001, 'min_lr': 5e-06, 'tmax': 145, 'patience': 20, 'clipping': None, 'amp': True, 'multi_gpu': False, 'logging': False, 'num_workers': 0, 'seed': 42, 'fold': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---- Training Params ---->\n",
      "Read train_df.csv\n",
      "Dataset size:3422\n",
      "Dataset size:855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-08 03:53:33,963 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "2022-05-08 03:53:34,358 INFO: Computational complexity:       15.93 GMac\n",
      "2022-05-08 03:53:34,358 INFO: Number of parameters:           80.83 M \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:01<00:00,  1.77it/s]\n",
      "2022-05-08 03:55:35,561 INFO: Epoch:[001/150]\n",
      "2022-05-08 03:55:35,562 INFO: Train Loss:4.489 | Acc:0.0064 | F1:0.0024\n",
      "2022-05-08 03:55:44,465 INFO: val Loss:4.496 | Acc:0.0023 | F1:0.0014\n",
      "2022-05-08 03:55:46,968 INFO: -----------------SAVE:1epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 03:57:49,120 INFO: Epoch:[002/150]\n",
      "2022-05-08 03:57:49,121 INFO: Train Loss:4.469 | Acc:0.0172 | F1:0.0044\n",
      "2022-05-08 03:57:58,135 INFO: val Loss:4.483 | Acc:0.0023 | F1:0.0027\n",
      "2022-05-08 03:58:00,020 INFO: -----------------SAVE:2epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 04:00:02,474 INFO: Epoch:[003/150]\n",
      "2022-05-08 04:00:02,474 INFO: Train Loss:4.442 | Acc:0.0164 | F1:0.0038\n",
      "2022-05-08 04:00:11,513 INFO: val Loss:4.465 | Acc:0.0047 | F1:0.0022\n",
      "2022-05-08 04:00:13,237 INFO: -----------------SAVE:3epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:04<00:00,  1.73it/s]\n",
      "2022-05-08 04:02:17,272 INFO: Epoch:[004/150]\n",
      "2022-05-08 04:02:17,272 INFO: Train Loss:4.398 | Acc:0.0354 | F1:0.0095\n",
      "2022-05-08 04:02:26,198 INFO: val Loss:4.404 | Acc:0.0152 | F1:0.0047\n",
      "2022-05-08 04:02:28,197 INFO: -----------------SAVE:4epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.77it/s]\n",
      "2022-05-08 04:04:28,993 INFO: Epoch:[005/150]\n",
      "2022-05-08 04:04:28,993 INFO: Train Loss:4.339 | Acc:0.0684 | F1:0.0143\n",
      "2022-05-08 04:04:38,115 INFO: val Loss:4.347 | Acc:0.0292 | F1:0.0055\n",
      "2022-05-08 04:04:40,071 INFO: -----------------SAVE:5epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 04:06:42,121 INFO: Epoch:[006/150]\n",
      "2022-05-08 04:06:42,122 INFO: Train Loss:3.994 | Acc:0.4056 | F1:0.0824\n",
      "2022-05-08 04:06:50,922 INFO: val Loss:3.652 | Acc:0.6047 | F1:0.1096\n",
      "2022-05-08 04:06:53,578 INFO: -----------------SAVE:6epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.78it/s]\n",
      "2022-05-08 04:08:53,474 INFO: Epoch:[007/150]\n",
      "2022-05-08 04:08:53,474 INFO: Train Loss:3.163 | Acc:0.7650 | F1:0.1385\n",
      "2022-05-08 04:09:02,328 INFO: val Loss:2.651 | Acc:0.8409 | F1:0.1558\n",
      "2022-05-08 04:09:04,240 INFO: -----------------SAVE:7epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.78it/s]\n",
      "2022-05-08 04:11:04,159 INFO: Epoch:[008/150]\n",
      "2022-05-08 04:11:04,160 INFO: Train Loss:2.280 | Acc:0.8220 | F1:0.1467\n",
      "2022-05-08 04:11:12,947 INFO: val Loss:1.671 | Acc:0.8480 | F1:0.1578\n",
      "2022-05-08 04:11:14,875 INFO: -----------------SAVE:8epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:00<00:00,  1.78it/s]\n",
      "2022-05-08 04:13:15,129 INFO: Epoch:[009/150]\n",
      "2022-05-08 04:13:15,129 INFO: Train Loss:1.530 | Acc:0.8375 | F1:0.1528\n",
      "2022-05-08 04:13:24,015 INFO: val Loss:1.065 | Acc:0.8480 | F1:0.1578\n",
      "2022-05-08 04:13:26,007 INFO: -----------------SAVE:9epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.79it/s]\n",
      "2022-05-08 04:15:25,673 INFO: Epoch:[010/150]\n",
      "2022-05-08 04:15:25,673 INFO: Train Loss:1.200 | Acc:0.8445 | F1:0.1551\n",
      "2022-05-08 04:15:34,458 INFO: val Loss:0.953 | Acc:0.8480 | F1:0.1578\n",
      "2022-05-08 04:15:36,595 INFO: -----------------SAVE:10epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.74it/s]\n",
      "2022-05-08 04:17:39,454 INFO: Epoch:[011/150]\n",
      "2022-05-08 04:17:39,455 INFO: Train Loss:1.041 | Acc:0.8457 | F1:0.1557\n",
      "2022-05-08 04:17:48,985 INFO: val Loss:0.836 | Acc:0.8480 | F1:0.1578\n",
      "2022-05-08 04:17:50,998 INFO: -----------------SAVE:11epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:03<00:00,  1.73it/s]\n",
      "2022-05-08 04:19:54,852 INFO: Epoch:[012/150]\n",
      "2022-05-08 04:19:54,853 INFO: Train Loss:0.928 | Acc:0.8463 | F1:0.1579\n",
      "2022-05-08 04:20:03,920 INFO: val Loss:0.754 | Acc:0.8480 | F1:0.1579\n",
      "2022-05-08 04:20:05,867 INFO: -----------------SAVE:12epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:02<00:00,  1.75it/s]\n",
      "2022-05-08 04:22:08,236 INFO: Epoch:[013/150]\n",
      "2022-05-08 04:22:08,237 INFO: Train Loss:0.812 | Acc:0.8466 | F1:0.1558\n",
      "2022-05-08 04:22:17,592 INFO: val Loss:0.689 | Acc:0.8526 | F1:0.1865\n",
      "2022-05-08 04:22:19,533 INFO: -----------------SAVE:13epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:09<00:00,  1.65it/s]\n",
      "2022-05-08 04:24:29,301 INFO: Epoch:[014/150]\n",
      "2022-05-08 04:24:29,301 INFO: Train Loss:0.716 | Acc:0.8498 | F1:0.1726\n",
      "2022-05-08 04:24:39,328 INFO: val Loss:0.619 | Acc:0.8620 | F1:0.2300\n",
      "2022-05-08 04:24:41,300 INFO: -----------------SAVE:14epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [02:10<00:00,  1.64it/s]\n",
      "2022-05-08 04:26:51,543 INFO: Epoch:[015/150]\n",
      "2022-05-08 04:26:51,543 INFO: Train Loss:0.653 | Acc:0.8574 | F1:0.2095\n",
      "2022-05-08 04:27:00,790 INFO: val Loss:0.563 | Acc:0.8585 | F1:0.2638\n",
      "2022-05-08 04:27:02,710 INFO: -----------------SAVE:15epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:59<00:00,  1.78it/s]\n",
      "2022-05-08 04:29:02,619 INFO: Epoch:[016/150]\n",
      "2022-05-08 04:29:02,619 INFO: Train Loss:0.592 | Acc:0.8647 | F1:0.2597\n",
      "2022-05-08 04:29:11,907 INFO: val Loss:0.505 | Acc:0.8737 | F1:0.3089\n",
      "2022-05-08 04:29:13,829 INFO: -----------------SAVE:16epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 04:31:10,480 INFO: Epoch:[017/150]\n",
      "2022-05-08 04:31:10,481 INFO: Train Loss:0.530 | Acc:0.8755 | F1:0.3209\n",
      "2022-05-08 04:31:19,288 INFO: val Loss:0.441 | Acc:0.8901 | F1:0.4016\n",
      "2022-05-08 04:31:21,130 INFO: -----------------SAVE:17epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:33:17,583 INFO: Epoch:[018/150]\n",
      "2022-05-08 04:33:17,583 INFO: Train Loss:0.478 | Acc:0.8860 | F1:0.3836\n",
      "2022-05-08 04:33:26,374 INFO: val Loss:0.390 | Acc:0.9018 | F1:0.4341\n",
      "2022-05-08 04:33:28,218 INFO: -----------------SAVE:18epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:35:24,413 INFO: Epoch:[019/150]\n",
      "2022-05-08 04:35:24,413 INFO: Train Loss:0.429 | Acc:0.8942 | F1:0.4351\n",
      "2022-05-08 04:35:33,161 INFO: val Loss:0.373 | Acc:0.9029 | F1:0.4811\n",
      "2022-05-08 04:35:34,992 INFO: -----------------SAVE:19epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:37:31,437 INFO: Epoch:[020/150]\n",
      "2022-05-08 04:37:31,437 INFO: Train Loss:0.398 | Acc:0.8971 | F1:0.4698\n",
      "2022-05-08 04:37:40,234 INFO: val Loss:0.316 | Acc:0.9135 | F1:0.5058\n",
      "2022-05-08 04:37:42,026 INFO: -----------------SAVE:20epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:39:38,647 INFO: Epoch:[021/150]\n",
      "2022-05-08 04:39:38,647 INFO: Train Loss:0.343 | Acc:0.9091 | F1:0.5236\n",
      "2022-05-08 04:39:47,432 INFO: val Loss:0.337 | Acc:0.9029 | F1:0.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:41:43,973 INFO: Epoch:[022/150]\n",
      "2022-05-08 04:41:43,973 INFO: Train Loss:0.319 | Acc:0.9176 | F1:0.5777\n",
      "2022-05-08 04:41:52,716 INFO: val Loss:0.276 | Acc:0.9216 | F1:0.5803\n",
      "2022-05-08 04:41:54,578 INFO: -----------------SAVE:22epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 04:43:51,213 INFO: Epoch:[023/150]\n",
      "2022-05-08 04:43:51,214 INFO: Train Loss:0.306 | Acc:0.9217 | F1:0.6069\n",
      "2022-05-08 04:44:00,032 INFO: val Loss:0.312 | Acc:0.9216 | F1:0.5967\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:45:56,619 INFO: Epoch:[024/150]\n",
      "2022-05-08 04:45:56,620 INFO: Train Loss:0.269 | Acc:0.9255 | F1:0.6174\n",
      "2022-05-08 04:46:05,444 INFO: val Loss:0.298 | Acc:0.9216 | F1:0.5600\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:48:02,015 INFO: Epoch:[025/150]\n",
      "2022-05-08 04:48:02,015 INFO: Train Loss:0.270 | Acc:0.9246 | F1:0.6285\n",
      "2022-05-08 04:48:10,795 INFO: val Loss:0.275 | Acc:0.9345 | F1:0.6218\n",
      "2022-05-08 04:48:12,626 INFO: -----------------SAVE:25epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 04:50:09,316 INFO: Epoch:[026/150]\n",
      "2022-05-08 04:50:09,317 INFO: Train Loss:0.251 | Acc:0.9313 | F1:0.6688\n",
      "2022-05-08 04:50:18,097 INFO: val Loss:0.259 | Acc:0.9404 | F1:0.6757\n",
      "2022-05-08 04:50:20,063 INFO: -----------------SAVE:26epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 04:52:16,804 INFO: Epoch:[027/150]\n",
      "2022-05-08 04:52:16,805 INFO: Train Loss:0.237 | Acc:0.9363 | F1:0.7031\n",
      "2022-05-08 04:52:25,565 INFO: val Loss:0.267 | Acc:0.9251 | F1:0.5893\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 04:54:22,259 INFO: Epoch:[028/150]\n",
      "2022-05-08 04:54:22,260 INFO: Train Loss:0.224 | Acc:0.9398 | F1:0.7066\n",
      "2022-05-08 04:54:31,073 INFO: val Loss:0.282 | Acc:0.9275 | F1:0.6455\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 04:56:27,582 INFO: Epoch:[029/150]\n",
      "2022-05-08 04:56:27,582 INFO: Train Loss:0.223 | Acc:0.9375 | F1:0.7064\n",
      "2022-05-08 04:56:36,375 INFO: val Loss:0.232 | Acc:0.9380 | F1:0.6679\n",
      "2022-05-08 04:56:38,320 INFO: -----------------SAVE:29epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 04:58:34,985 INFO: Epoch:[030/150]\n",
      "2022-05-08 04:58:34,985 INFO: Train Loss:0.198 | Acc:0.9465 | F1:0.7334\n",
      "2022-05-08 04:58:43,775 INFO: val Loss:0.260 | Acc:0.9392 | F1:0.6766\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:00:40,457 INFO: Epoch:[031/150]\n",
      "2022-05-08 05:00:40,457 INFO: Train Loss:0.200 | Acc:0.9433 | F1:0.7442\n",
      "2022-05-08 05:00:49,237 INFO: val Loss:0.251 | Acc:0.9404 | F1:0.6918\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:02:45,906 INFO: Epoch:[032/150]\n",
      "2022-05-08 05:02:45,907 INFO: Train Loss:0.196 | Acc:0.9468 | F1:0.7550\n",
      "2022-05-08 05:02:54,685 INFO: val Loss:0.267 | Acc:0.9427 | F1:0.6884\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:04:51,065 INFO: Epoch:[033/150]\n",
      "2022-05-08 05:04:51,065 INFO: Train Loss:0.212 | Acc:0.9416 | F1:0.7489\n",
      "2022-05-08 05:04:59,822 INFO: val Loss:0.206 | Acc:0.9427 | F1:0.6992\n",
      "2022-05-08 05:05:01,732 INFO: -----------------SAVE:33epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:06:58,628 INFO: Epoch:[034/150]\n",
      "2022-05-08 05:06:58,628 INFO: Train Loss:0.190 | Acc:0.9459 | F1:0.7631\n",
      "2022-05-08 05:07:07,437 INFO: val Loss:0.287 | Acc:0.9404 | F1:0.6885\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:09:04,185 INFO: Epoch:[035/150]\n",
      "2022-05-08 05:09:04,186 INFO: Train Loss:0.160 | Acc:0.9565 | F1:0.8103\n",
      "2022-05-08 05:09:12,975 INFO: val Loss:0.251 | Acc:0.9380 | F1:0.6623\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:11:09,757 INFO: Epoch:[036/150]\n",
      "2022-05-08 05:11:09,757 INFO: Train Loss:0.181 | Acc:0.9530 | F1:0.8022\n",
      "2022-05-08 05:11:18,567 INFO: val Loss:0.242 | Acc:0.9415 | F1:0.6917\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:13:15,328 INFO: Epoch:[037/150]\n",
      "2022-05-08 05:13:15,329 INFO: Train Loss:0.166 | Acc:0.9538 | F1:0.8128\n",
      "2022-05-08 05:13:24,142 INFO: val Loss:0.217 | Acc:0.9439 | F1:0.7118\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:15:20,820 INFO: Epoch:[038/150]\n",
      "2022-05-08 05:15:20,821 INFO: Train Loss:0.151 | Acc:0.9544 | F1:0.7956\n",
      "2022-05-08 05:15:29,611 INFO: val Loss:0.240 | Acc:0.9380 | F1:0.6771\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:17:26,457 INFO: Epoch:[039/150]\n",
      "2022-05-08 05:17:26,457 INFO: Train Loss:0.149 | Acc:0.9611 | F1:0.8463\n",
      "2022-05-08 05:17:35,259 INFO: val Loss:0.213 | Acc:0.9520 | F1:0.7381\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-08 05:19:32,379 INFO: Epoch:[040/150]\n",
      "2022-05-08 05:19:32,379 INFO: Train Loss:0.155 | Acc:0.9553 | F1:0.8213\n",
      "2022-05-08 05:19:41,156 INFO: val Loss:0.271 | Acc:0.9392 | F1:0.6951\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:21:37,673 INFO: Epoch:[041/150]\n",
      "2022-05-08 05:21:37,673 INFO: Train Loss:0.162 | Acc:0.9556 | F1:0.8095\n",
      "2022-05-08 05:21:46,434 INFO: val Loss:0.224 | Acc:0.9462 | F1:0.7168\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.82it/s]\n",
      "2022-05-08 05:23:43,708 INFO: Epoch:[042/150]\n",
      "2022-05-08 05:23:43,708 INFO: Train Loss:0.148 | Acc:0.9568 | F1:0.8123\n",
      "2022-05-08 05:23:52,475 INFO: val Loss:0.223 | Acc:0.9462 | F1:0.6958\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:25:48,737 INFO: Epoch:[043/150]\n",
      "2022-05-08 05:25:48,737 INFO: Train Loss:0.138 | Acc:0.9629 | F1:0.8502\n",
      "2022-05-08 05:25:57,502 INFO: val Loss:0.262 | Acc:0.9450 | F1:0.6975\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:27:54,153 INFO: Epoch:[044/150]\n",
      "2022-05-08 05:27:54,153 INFO: Train Loss:0.147 | Acc:0.9626 | F1:0.8509\n",
      "2022-05-08 05:28:02,951 INFO: val Loss:0.223 | Acc:0.9474 | F1:0.7078\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:29:59,419 INFO: Epoch:[045/150]\n",
      "2022-05-08 05:29:59,419 INFO: Train Loss:0.144 | Acc:0.9617 | F1:0.8585\n",
      "2022-05-08 05:30:08,222 INFO: val Loss:0.286 | Acc:0.9404 | F1:0.6574\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:32:05,046 INFO: Epoch:[046/150]\n",
      "2022-05-08 05:32:05,046 INFO: Train Loss:0.151 | Acc:0.9600 | F1:0.8374\n",
      "2022-05-08 05:32:13,826 INFO: val Loss:0.213 | Acc:0.9509 | F1:0.7364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:34:10,412 INFO: Epoch:[047/150]\n",
      "2022-05-08 05:34:10,413 INFO: Train Loss:0.125 | Acc:0.9690 | F1:0.8793\n",
      "2022-05-08 05:34:19,171 INFO: val Loss:0.254 | Acc:0.9462 | F1:0.7142\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:36:15,636 INFO: Epoch:[048/150]\n",
      "2022-05-08 05:36:15,636 INFO: Train Loss:0.133 | Acc:0.9641 | F1:0.8524\n",
      "2022-05-08 05:36:24,406 INFO: val Loss:0.219 | Acc:0.9509 | F1:0.7064\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:38:21,147 INFO: Epoch:[049/150]\n",
      "2022-05-08 05:38:21,147 INFO: Train Loss:0.142 | Acc:0.9646 | F1:0.8612\n",
      "2022-05-08 05:38:29,952 INFO: val Loss:0.183 | Acc:0.9626 | F1:0.7868\n",
      "2022-05-08 05:38:31,932 INFO: -----------------SAVE:49epoch----------------\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:40:28,720 INFO: Epoch:[050/150]\n",
      "2022-05-08 05:40:28,720 INFO: Train Loss:0.136 | Acc:0.9641 | F1:0.8651\n",
      "2022-05-08 05:40:37,504 INFO: val Loss:0.311 | Acc:0.9485 | F1:0.7567\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:42:34,454 INFO: Epoch:[051/150]\n",
      "2022-05-08 05:42:34,454 INFO: Train Loss:0.135 | Acc:0.9611 | F1:0.8391\n",
      "2022-05-08 05:42:43,231 INFO: val Loss:0.210 | Acc:0.9602 | F1:0.7754\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:44:40,129 INFO: Epoch:[052/150]\n",
      "2022-05-08 05:44:40,129 INFO: Train Loss:0.120 | Acc:0.9655 | F1:0.8621\n",
      "2022-05-08 05:44:48,959 INFO: val Loss:0.208 | Acc:0.9556 | F1:0.7614\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.84it/s]\n",
      "2022-05-08 05:46:45,557 INFO: Epoch:[053/150]\n",
      "2022-05-08 05:46:45,558 INFO: Train Loss:0.104 | Acc:0.9690 | F1:0.8859\n",
      "2022-05-08 05:46:54,341 INFO: val Loss:0.207 | Acc:0.9509 | F1:0.7419\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:48:51,114 INFO: Epoch:[054/150]\n",
      "2022-05-08 05:48:51,114 INFO: Train Loss:0.112 | Acc:0.9717 | F1:0.8980\n",
      "2022-05-08 05:48:59,897 INFO: val Loss:0.266 | Acc:0.9474 | F1:0.6866\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:50:56,799 INFO: Epoch:[055/150]\n",
      "2022-05-08 05:50:56,800 INFO: Train Loss:0.122 | Acc:0.9661 | F1:0.8580\n",
      "2022-05-08 05:51:05,597 INFO: val Loss:0.263 | Acc:0.9427 | F1:0.6987\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-08 05:53:02,605 INFO: Epoch:[056/150]\n",
      "2022-05-08 05:53:02,606 INFO: Train Loss:0.116 | Acc:0.9638 | F1:0.8576\n",
      "2022-05-08 05:53:11,363 INFO: val Loss:0.202 | Acc:0.9556 | F1:0.7467\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:55:08,282 INFO: Epoch:[057/150]\n",
      "2022-05-08 05:55:08,283 INFO: Train Loss:0.110 | Acc:0.9699 | F1:0.8772\n",
      "2022-05-08 05:55:17,111 INFO: val Loss:0.240 | Acc:0.9485 | F1:0.7196\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:57:13,980 INFO: Epoch:[058/150]\n",
      "2022-05-08 05:57:13,981 INFO: Train Loss:0.105 | Acc:0.9708 | F1:0.8925\n",
      "2022-05-08 05:57:22,772 INFO: val Loss:0.202 | Acc:0.9591 | F1:0.7739\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 05:59:19,533 INFO: Epoch:[059/150]\n",
      "2022-05-08 05:59:19,533 INFO: Train Loss:0.091 | Acc:0.9722 | F1:0.8867\n",
      "2022-05-08 05:59:28,314 INFO: val Loss:0.224 | Acc:0.9520 | F1:0.7353\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-08 06:01:25,397 INFO: Epoch:[060/150]\n",
      "2022-05-08 06:01:25,397 INFO: Train Loss:0.101 | Acc:0.9690 | F1:0.8688\n",
      "2022-05-08 06:01:34,178 INFO: val Loss:0.183 | Acc:0.9602 | F1:0.7873\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:03:30,942 INFO: Epoch:[061/150]\n",
      "2022-05-08 06:03:30,942 INFO: Train Loss:0.092 | Acc:0.9737 | F1:0.9032\n",
      "2022-05-08 06:03:39,780 INFO: val Loss:0.249 | Acc:0.9520 | F1:0.7684\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:05:36,639 INFO: Epoch:[062/150]\n",
      "2022-05-08 06:05:36,639 INFO: Train Loss:0.098 | Acc:0.9719 | F1:0.8990\n",
      "2022-05-08 06:05:45,421 INFO: val Loss:0.219 | Acc:0.9579 | F1:0.7944\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:07:42,213 INFO: Epoch:[063/150]\n",
      "2022-05-08 06:07:42,214 INFO: Train Loss:0.104 | Acc:0.9731 | F1:0.8939\n",
      "2022-05-08 06:07:51,012 INFO: val Loss:0.236 | Acc:0.9532 | F1:0.7607\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:09:47,867 INFO: Epoch:[064/150]\n",
      "2022-05-08 06:09:47,867 INFO: Train Loss:0.091 | Acc:0.9760 | F1:0.9091\n",
      "2022-05-08 06:09:56,643 INFO: val Loss:0.261 | Acc:0.9415 | F1:0.7327\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:11:53,550 INFO: Epoch:[065/150]\n",
      "2022-05-08 06:11:53,551 INFO: Train Loss:0.096 | Acc:0.9719 | F1:0.8839\n",
      "2022-05-08 06:12:02,343 INFO: val Loss:0.186 | Acc:0.9626 | F1:0.7834\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-08 06:13:59,607 INFO: Epoch:[066/150]\n",
      "2022-05-08 06:13:59,607 INFO: Train Loss:0.081 | Acc:0.9801 | F1:0.9252\n",
      "2022-05-08 06:14:08,612 INFO: val Loss:0.187 | Acc:0.9684 | F1:0.8414\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:57<00:00,  1.83it/s]\n",
      "2022-05-08 06:16:05,717 INFO: Epoch:[067/150]\n",
      "2022-05-08 06:16:05,718 INFO: Train Loss:0.085 | Acc:0.9740 | F1:0.8986\n",
      "2022-05-08 06:16:14,524 INFO: val Loss:0.230 | Acc:0.9520 | F1:0.7644\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:18:11,483 INFO: Epoch:[068/150]\n",
      "2022-05-08 06:18:11,483 INFO: Train Loss:0.098 | Acc:0.9755 | F1:0.9102\n",
      "2022-05-08 06:18:20,291 INFO: val Loss:0.209 | Acc:0.9637 | F1:0.8120\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 214/214 [01:56<00:00,  1.83it/s]\n",
      "2022-05-08 06:20:17,036 INFO: Epoch:[069/150]\n",
      "2022-05-08 06:20:17,036 INFO: Train Loss:0.083 | Acc:0.9769 | F1:0.9206\n",
      "2022-05-08 06:20:25,800 INFO: val Loss:0.212 | Acc:0.9614 | F1:0.8155\n",
      "2022-05-08 06:20:25,801 INFO: \n",
      "Best Val Epoch:49 | Val Loss:0.1832 | Val Acc:0.9626 | Val F1:0.7868\n",
      "2022-05-08 06:20:25,801 INFO: Total Process time:146.857Minute\n",
      "2022-05-08 06:20:26,593 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:34<00:00,  1.02s/it]\n",
      "2022-05-08 06:21:10,791 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:21<00:00,  1.59it/s]\n",
      "2022-05-08 06:21:41,759 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:21<00:00,  1.59it/s]\n",
      "2022-05-08 06:22:04,948 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:21<00:00,  1.57it/s]\n",
      "2022-05-08 06:22:28,450 INFO: Loading pretrained weights from url (https://dl.fbaipublicfiles.com/deit/regnety_160-a5fe301d.pth)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [00:21<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# df_test['file_name'] = df_test['file_name'].apply(lambda x:x.replace('test_imgs', 'test_1024'))\n",
    "test_transform = get_train_augmentation(img_size=img_size, ver=1)\n",
    "test_dataset = Test_dataset(df_test, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)  # 고려사항\n",
    "\n",
    "start = 0 # first time : Only Trainset\n",
    "# steps = 6 # Number of pseudo labeling times \n",
    "models_path = []\n",
    "for s_fold in range(5): # 5fold\n",
    "    args.fold = s_fold\n",
    "    args.exp_num = str(s_fold)\n",
    "    save_path = main(args)\n",
    "    models_path.append(save_path)\n",
    "ensemble = ensemble_5fold(models_path, test_loader, device)\n",
    "    \n",
    "# pseudo labeling하는 경우\n",
    "# for step in range(start, steps+1): \n",
    "#     models_path = []\n",
    "#     args.step = step\n",
    "#     for s_fold in range(5): # 5fold\n",
    "#         args.fold = s_fold\n",
    "#         args.exp_num = str(s_fold)\n",
    "#         save_path = main(args)\n",
    "#         models_path.append(save_path)\n",
    "#     ensemble = ensemble_5fold(models_path, test_loader, device)\n",
    "#     make_pseudo_df(df_train, df_test, ensemble, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "224f82de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index             label\n",
       "0         0   tile-glue_strip\n",
       "1         1         grid-good\n",
       "2         2   transistor-good\n",
       "3         3  tile-gray_stroke\n",
       "4         4         tile-good\n",
       "...     ...               ...\n",
       "2149   2149  tile-gray_stroke\n",
       "2150   2150        screw-good\n",
       "2151   2151         grid-good\n",
       "2152   2152        cable-good\n",
       "2153   2153       zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For submission\n",
    "sub.iloc[:, 1] = ensemble.argmax(axis=1)\n",
    "labels = ['bottle-broken_large', 'bottle-broken_small', 'bottle-contamination', 'bottle-good', 'cable-bent_wire', 'cable-cable_swap', 'cable-combined', 'cable-cut_inner_insulation', 'cable-cut_outer_insulation', 'cable-good', 'cable-missing_cable', 'cable-missing_wire', 'cable-poke_insulation', 'capsule-crack', 'capsule-faulty_imprint', 'capsule-good', 'capsule-poke', 'capsule-scratch', 'capsule-squeeze', 'carpet-color', 'carpet-cut', 'carpet-good', 'carpet-hole', 'carpet-metal_contamination', 'carpet-thread', 'grid-bent', 'grid-broken', 'grid-glue', 'grid-good', 'grid-metal_contamination', 'grid-thread', 'hazelnut-crack', 'hazelnut-cut', 'hazelnut-good', 'hazelnut-hole', 'hazelnut-print', 'leather-color', 'leather-cut', 'leather-fold', 'leather-glue', 'leather-good', 'leather-poke', 'metal_nut-bent', 'metal_nut-color', 'metal_nut-flip', 'metal_nut-good', 'metal_nut-scratch', 'pill-color', 'pill-combined', 'pill-contamination', 'pill-crack', 'pill-faulty_imprint', 'pill-good', 'pill-pill_type', 'pill-scratch', 'screw-good', 'screw-manipulated_front', 'screw-scratch_head', 'screw-scratch_neck', 'screw-thread_side', 'screw-thread_top', 'tile-crack', 'tile-glue_strip', 'tile-good', 'tile-gray_stroke', 'tile-oil', 'tile-rough', 'toothbrush-defective', 'toothbrush-good', 'transistor-bent_lead', 'transistor-cut_lead', 'transistor-damaged_case', 'transistor-good', 'transistor-misplaced', 'wood-color', 'wood-combined', 'wood-good', 'wood-hole', 'wood-liquid', 'wood-scratch', 'zipper-broken_teeth', 'zipper-combined', 'zipper-fabric_border', 'zipper-fabric_interior', 'zipper-good', 'zipper-rough', 'zipper-split_teeth', 'zipper-squeezed_teeth']\n",
    "original_labels = dict(zip(range(len(labels)),labels))\n",
    "sub['label'] = sub['label'].replace(original_labels)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796ea827",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./data/0507_2_esb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a5c5880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116\n"
     ]
    }
   ],
   "source": [
    "# 정상 샘플 개수\n",
    "good_cnt = 0\n",
    "for i in range(len(sub)):\n",
    "    if sub['label'][i][-4:] == 'good':\n",
    "        good_cnt += 1\n",
    "print(good_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82f050c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size = 16\n",
      "epochs = 150\n",
      "img_size = 224\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용한 모델의 batch_size, epoch, img_size 기록\n",
    "print('batch_size =', args.batch_size)\n",
    "print('epochs =', args.epochs)\n",
    "print('img_size =', args.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28937c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = regnety_160\n"
     ]
    }
   ],
   "source": [
    "print('model =', args.encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd5b7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5d57ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ad5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_torch] *",
   "language": "python",
   "name": "conda-env-machine_torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
