{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628d66cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression의 Accuracy : 0.9851666666666666\n",
      "KNN의 Accuracy : 0.9985\n"
     ]
    }
   ],
   "source": [
    "# 간단하게 KNN 구현에 대해서 알아보아요!\n",
    "# BMI 예제(multinomial classification)를 대상으로 KNN의 결과와 \n",
    "# LogisticRegression의 결과를 비교해 보아요!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/bmi.csv', skiprows=3)\n",
    "\n",
    "# Data Split\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(df[['height', 'weight']],\n",
    "                 df['label'],\n",
    "                 test_size=0.3,\n",
    "                 random_state=1,\n",
    "                 stratify=df['label'])\n",
    "\n",
    "# 결측치 없구요. 이상치 없어요!\n",
    "# 정규화 진행해요!\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n",
    "\n",
    "# LogisticRegression 구현\n",
    "model = LogisticRegression()\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "acc = model.score(norm_test_x_data, test_t_data)\n",
    "print('LogisticRegression의 Accuracy : {}'.format(acc))  # 0.9851666666666666\n",
    "\n",
    "# KNN으로 구현\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_classifier.fit(norm_train_x_data, train_t_data)\n",
    "acc = knn_classifier.score(norm_test_x_data, test_t_data)\n",
    "print('KNN의 Accuracy : {}'.format(acc))  # 0.9985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069e3710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "# Ozone량 예측 Linear Regression 구현(Tensorflow 2.x)\n",
    "# 데이터 전처리 포함해요!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e1226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/ozone.csv')\n",
    "# display(df.head())\n",
    "\n",
    "x_data = df[['Solar.R', 'Wind', 'Temp']]  # DataFrame(2차원)\n",
    "t_data = df['Ozone']                      # Series(1차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "390babb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 먼저 독립변수에 대한 Missing Value를 찾아서 median으로 imputation\n",
    "\n",
    "for col in x_data.columns:\n",
    "    col_median = np.nanmedian(x_data[col])\n",
    "    x_data[col].loc[x_data[col].isnull()] = col_median\n",
    "    \n",
    "# 2. 독립변수에 대한 이상치를 검출한 후 이상치를 제외한 나머지값들의 mean으로\n",
    "#    이상치를 대체\n",
    "zscore_threshold = 2.0\n",
    "\n",
    "for col in x_data.columns:\n",
    "    outlier = x_data[col][np.abs(stats.zscore(x_data[col])) > zscore_threshold]\n",
    "    col_mean = np.mean(x_data.loc[~x_data[col].isin(outlier),col])\n",
    "    x_data.loc[x_data[col].isin(outlier), col] = col_mean\n",
    "    \n",
    "    \n",
    "# 3. 종속변수에 대한 이상치를 검출한 후 이상치를 제외한 나머지값들의 mean으로\n",
    "#   이상치를 대체\n",
    "outlier = t_data[np.abs(stats.zscore(t_data)) > zscore_threshold]\n",
    "col_mean = np.mean(~t_data.isin(outlier))\n",
    "t_data[t_data.isin(outlier)] = col_mean    \n",
    "\n",
    "# 4. 정규화 진행\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_t = MinMaxScaler()\n",
    "\n",
    "scaler_x.fit(x_data.values)               # scaler는 2차원 ndarray로 사용해야 해요!\n",
    "scaler_t.fit(t_data.values.reshape(-1,1))  \n",
    "\n",
    "norm_x_data = scaler_x.transform(x_data.values)\n",
    "norm_t_data = scaler_t.transform(t_data.values.reshape(-1,1)).ravel()\n",
    "\n",
    "# 5. 종속변수의 Missing Value는 KNN을 이용해서 예측값을 사용합니다.\n",
    "\n",
    "# 종속변수가 Missing Value가 아닌 \n",
    "# 독립변수들과 종속변수들을 추출(KNN을 학습하기 위해)\n",
    "norm_train_x_data = norm_x_data[~np.isnan(norm_t_data)]\n",
    "norm_train_t_data = norm_t_data[~np.isnan(norm_t_data)]\n",
    "\n",
    "# 모델 생성\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=2)\n",
    "knn_regressor.fit(norm_train_x_data, norm_train_t_data)\n",
    "\n",
    "# 종속변수가 Missing Value인 독립변수들을 입력으로 넣어서 값을 예측\n",
    "knn_predict = knn_regressor.predict(norm_x_data[np.isnan(norm_t_data)])\n",
    "norm_t_data[np.isnan(norm_t_data)] = knn_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2893face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 예측값 : [[30.12298524]]\n",
      "tensorflow 예측값 : [[30.074213]]\n"
     ]
    }
   ],
   "source": [
    "# 최종적인 우리 데이터는\n",
    "# norm_x_data\n",
    "# norm_t_data\n",
    "\n",
    "# 이제 데이터가 준비되었으니.. skearn 구현과 tensorflow 2.x으로 구현할꺼예요!\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "test_data = np.array([[330, 15, 80]])   # 태양광 330, 바람 15, 온도 80\n",
    "\n",
    "# sklearn 구현\n",
    "model = LinearRegression()\n",
    "model.fit(norm_x_data, norm_t_data)\n",
    "result = model.predict(scaler_x.transform(test_data))\n",
    "\n",
    "print('sklearn 예측값 : {}'.format(scaler_t.inverse_transform(result.reshape(-1,1))))\n",
    "# sklearn 예측값 : [[30.12298524]]\n",
    "\n",
    "# Tensorflow 2.x 구현(Linear Regression)\n",
    "keras_model = Sequential()\n",
    "\n",
    "keras_model.add(Flatten(input_shape=(3,)))  # Input Layer\n",
    "keras_model.add(Dense(units=1,\n",
    "                      activation='linear'))  # output Layer\n",
    "\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='mse')\n",
    "\n",
    "keras_model.fit(norm_x_data,\n",
    "                norm_t_data,\n",
    "                epochs=5000,\n",
    "                verbose=0)\n",
    "\n",
    "result = keras_model.predict(scaler_x.transform(test_data))\n",
    "print('tensorflow 예측값 : {}'.format(scaler_t.inverse_transform(result.reshape(-1,1))))\n",
    "# tensorflow 예측값 : [[30.074213]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "691f2784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "# Logistic Regression\n",
    "# binary classification을 skearn과 tensorflow 2.x로 구현해 보아요!\n",
    "# 사용할 데이터는 titanic 데이터(Kaggle에서 다운로드)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 결측치 처리는 해야 해요!, 단 실제 데이터이기 때문에 이상치가 계산으로\n",
    "# 검출된다 하다라도 해당 값을 그냥 사용할 꺼예요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6270eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Embarked  Family\n",
       "0         0       3    0    0         0       1\n",
       "1         1       1    1    1         1       1\n",
       "2         1       3    1    1         0       0\n",
       "3         1       1    1    1         0       1\n",
       "4         0       3    0    1         0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv('./data/titanic/train.csv')\n",
    "\n",
    "# 학습하기 좋은 데이터로 전처리해야해요!\n",
    "\n",
    "# 필요없는 column(feature)는 삭제처리\n",
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Fare', 'Cabin'], \n",
    "             axis=1,\n",
    "             inplace=False)\n",
    "\n",
    "# 컬럼을 보고 하나로 합칠 수 있는 컬럼은 하나로 합쳐줘요!\n",
    "df['Family'] = df['SibSp'] + df['Parch']\n",
    "df = df.drop(['SibSp', 'Parch'], axis=1, inplace=False)\n",
    "# display(df.head())\n",
    "\n",
    "# 결측치 처리부터 해 보아요!\n",
    "\n",
    "# `Embarked` column은 결측치가 2개예요. 최빈값을 이용해서 missing value를\n",
    "# 채워주는게 좋을 듯 보여요. 여기서는 그냥 Q로 넣었어요!\n",
    "df['Embarked'] = df['Embarked'].fillna('Q')\n",
    "\n",
    "# `Age` column의 결측치는 평균값으로 대체\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "\n",
    "#################################################\n",
    "\n",
    "# 문자로 되어 있는 값은 숫자로 변경\n",
    "gender_string = { 'male': 0, 'female': 1 }\n",
    "df['Sex'] = df['Sex'].map(gender_string)\n",
    "\n",
    "embarked_string = { 'S': 0, 'C': 1, 'Q': 2 }\n",
    "df['Embarked'] = df['Embarked'].map(embarked_string)\n",
    "\n",
    "def age_category(age):\n",
    "    if((age >= 0) & (age < 25)):\n",
    "        return 0\n",
    "    elif ((age >= 25) & (age < 50)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "df['Age'] = df['Age'].map(age_category)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e79667b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "train_x_data, test_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(df.drop('Survived', axis=1, inplace=False),\n",
    "                 df['Survived'],\n",
    "                 test_size=0.3,\n",
    "                 random_state=1,\n",
    "                 stratify=df['Survived'])\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_x_data)\n",
    "\n",
    "norm_train_x_data = scaler.transform(train_x_data)\n",
    "norm_test_x_data = scaler.transform(test_x_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb2394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn 정확도 : 0.7873134328358209\n"
     ]
    }
   ],
   "source": [
    "# sklearn 구현\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(norm_train_x_data, train_t_data)\n",
    "sklearn_result = model.score(norm_test_x_data, test_t_data)\n",
    "print('sklearn 정확도 : {}'.format(sklearn_result))   # 0.7873134328358209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c744638a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 778us/step - loss: 0.4653 - accuracy: 0.7948\n",
      "TF2.x 정확도 : [0.46533873677253723, 0.7947761416435242]\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 구현\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Flatten(input_shape=(5,)))\n",
    "keras_model.add(Dense(units=1,\n",
    "                      activation='sigmoid'))\n",
    "keras_model.compile(optimizer=SGD(learning_rate=1e-2),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "keras_model.fit(norm_train_x_data,\n",
    "                train_t_data,\n",
    "                epochs=1000,\n",
    "                verbose=0)\n",
    "\n",
    "keras_result = keras_model.evaluate(norm_test_x_data, test_t_data)\n",
    "print('TF2.x 정확도 : {}'.format(keras_result))   # 0.7873134328358209\n",
    "# TF2.x 정확도 : [0.46533873677253723, 0.7947761416435242]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
